{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
      "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.6/dist-packages (3.53.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from progressbar2) (1.14.0)\n",
      "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2) (2.4.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn progressbar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import gc\n",
    "from sys import getsizeof\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB = 1\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#The variable GB is the memory size you want to use.\n",
    "config = [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=(1024*GB))]\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1*X GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], config)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "np.set_printoptions(threshold=40*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(res, source_labels, dataset='train', size=1., verbosity = False, shuffle = True):\n",
    "    data = np.zeros((0, res, res, res), dtype=int)\n",
    "    labels = np.empty(0, int)\n",
    "    for i, label in enumerate(source_labels):\n",
    "        filename = './output/' + label + '/output-' + dataset + '-' + str(res) + '.h5'\n",
    "        file = h5py.File(filename, 'r')\n",
    "        tensor_len = len(file['tensor'])\n",
    "        picked_ids = range(math.ceil(tensor_len * size) - 1)\n",
    "        if verbosity:\n",
    "            print(filename)\n",
    "            print(picked_ids)\n",
    "            print('Picking ' + str(math.ceil(tensor_len * size)) + ' from ' + str(len(file['tensor'])) )\n",
    "        data = np.concatenate((data, [file['tensor'][index] for index in picked_ids]))\n",
    "        labels = np.concatenate((labels, np.full(len(picked_ids), i, dtype=int)))\n",
    "        file.close()\n",
    "        gc.collect()\n",
    "    if shuffle:\n",
    "        if verbosity:\n",
    "            print(\"Shuffling data\")\n",
    "        rng_state = np.random.get_state()\n",
    "        np.random.shuffle(data)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(labels)\n",
    "    return (data, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 13824)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 48)                663600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                588       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 40)                520       \n",
      "=================================================================\n",
      "Total params: 664,708\n",
      "Trainable params: 664,708\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f9bd210a080>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_model(res, num_classes, verbosity = 0):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(res, res, res)),\n",
    "        keras.layers.Dense(res*2, activation='relu'),\n",
    "        keras.layers.Dense(res/2, activation='sigmoid'),\n",
    "        keras.layers.Dropout(.2, input_shape=(2,)),\n",
    "        keras.layers.Dense(40, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    if (verbosity == 1):\n",
    "        print(model.summary())\n",
    "    return model\n",
    "def prepare_data(data, num_classes, res):\n",
    "    return data\n",
    "model_type = 'dense'\n",
    "prepare_model(24, 20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 10, 10, 10, 24)    5208      \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 3, 3, 3, 24)       72024     \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 2, 2, 2, 24)       4632      \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 1, 1, 1, 24)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                130       \n",
      "=================================================================\n",
      "Total params: 82,294\n",
      "Trainable params: 82,294\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f899a4e8b70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_model(res, num_classes, verbosity = 0):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv3D(\n",
    "                res, \n",
    "                kernel_size=(6),\n",
    "                strides=(2),\n",
    "                activation='relu', \n",
    "                kernel_initializer='he_uniform', \n",
    "                data_format=\"channels_last\",\n",
    "                input_shape=(res, res, res, 1)\n",
    "            ),        \n",
    "        keras.layers.Conv3D(\n",
    "                res, \n",
    "                kernel_size=(5),\n",
    "                strides=(2),\n",
    "                activation='relu', \n",
    "                kernel_initializer='he_uniform'\n",
    "            ),        \n",
    "        keras.layers.Conv3D(\n",
    "                res, \n",
    "                kernel_size=(2),\n",
    "                activation='relu', \n",
    "                kernel_initializer='he_uniform'\n",
    "            ),        \n",
    "   \n",
    "        keras.layers.MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(res/2, activation='relu'),\n",
    "        keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    if (verbosity == 1):\n",
    "        print(model.summary())\n",
    "    return model\n",
    "def prepare_data(data, num_classes, res):\n",
    "    return data.reshape(len(data), res, res, res, 1)\n",
    "model_type = 'conv3d'\n",
    "prepare_model(24, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, training, training_labels, res, num_classes, verbosity = 0):\n",
    "    log_dir = \"logs/fit/\" + str(res) + '-' + str(num_classes) + '-' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    if verbosity == 1:\n",
    "        print(\"Log file \" + log_dir)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    validation_split = 0.1\n",
    "    epochs = 10 * num_classes\n",
    "    \n",
    "#    model.fit(\n",
    "#        keras.utils.to_categorical(training, num_clases), \n",
    "#        training_labels, \n",
    "#        epochs=epochs)\n",
    "    \n",
    "    model.fit(\n",
    "        prepare_data(training, num_classes), \n",
    "        training_labels, \n",
    "        epochs=epochs,\n",
    "        verbose=verbosity,\n",
    "        callbacks=[tensorboard_callback],\n",
    "        validation_split=validation_split\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix and Classification Report\n",
    "def print_confusion_matrix(test, test_labels, base_labels):\n",
    "    Y_pred = model.predict_generator(prepare_data(test, len(base_labels)), len(test))\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(test_labels, y_pred))\n",
    "    print('Classification Report')\n",
    "    print(classification_report(test_labels, y_pred, target_names=base_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_labels = ['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor', 'night_stand', 'sofa', 'table', 'toilet']\n",
    "all_labels = ['airplane', 'bathtub', 'bed', 'bench', 'bookshelf', 'bottle', 'bowl', 'car', 'chair', 'cone', \n",
    "                 'cup', 'curtain', 'desk', 'door', 'dresser', 'flower_pot', 'glass_box', 'guitar','keyboard', 'lamp',\n",
    "                 'laptop', 'mantel', 'monitor', 'night_stand', 'person', 'piano', 'plant', \n",
    "                 'radio', 'range_hood', 'sink', 'sofa', 'stairs', 'stool', 'table', 'tent', 'toilet', 'tv_stand', \n",
    "                 'vase', 'wardrobe', 'xbox']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subclases = [10, 20, 30, 40]\n",
    "resolutions = [24]#, 32]#, 48]\n",
    "num_classes = 2\n",
    "\n",
    "for i in range(len(all_labels)):\n",
    "    for j in range(i + 1, len(all_labels)):\n",
    "        base_labels = [all_labels[i]] + [all_labels[j]]\n",
    "        print(i, j, base_labels)\n",
    "        for n, res in enumerate(resolutions):\n",
    "            training, training_labels = load_data(res, base_labels, 'train', 1, False)\n",
    "            model = prepare_model(res, num_classes, 0)\n",
    "            model_name = 'models/' + model_type + '-' + all_labels[i] + '-' + all_labels[j] + '.h5'\n",
    "            train(model, training, training_labels, res, num_classes, 0)\n",
    "            model.save(model_name)\n",
    "            test, test_labels = load_data(res, base_labels, 'test', 1.0, False)\n",
    "            test_loss, test_acc = model.evaluate(\n",
    "                prepare_data(test, num_classes),  \n",
    "                test_labels, \n",
    "                verbose=2\n",
    "            )\n",
    "            print('\\nTest accuracy for ' + all_labels[i] + '-' + all_labels[j] + ' classes width res ' + str(res) + ':', test_acc)\n",
    "            print_confusion_matrix(test, test_labels, all_labels)\n",
    "            gc.collect()          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 24\n",
    "#model_type = 'conv3d'\n",
    "test, test_labels = load_data(res, all_labels, 'test', 1.0, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_index(prediction, i, j):\n",
    "    return j if prediction else i\n",
    "\n",
    "def prediction_for(i, j, data):\n",
    "    model_name = 'models/' + model_type + '-' + all_labels[i] + '-' + all_labels[j] + '.h5'        \n",
    "    model = keras.models.load_model(model_name)\n",
    "    prediction = model.predict(prepare_data(data, 2, 24))\n",
    "    return [real_index(p, i, j) for p in list(map(np.argmax, prediction))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])\n",
    "test[0].shape\n",
    "to_test = np.expand_dims(test[0], axis=0)\n",
    "#model.predict(to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = [x[:] for x in [[-1] * 40] * 40]\n",
    "for i in range(len(all_labels)):\n",
    "    for j in range(i + 1, len(all_labels)):\n",
    "        prediction[i][j] = prediction_for(i, j, to_test)\n",
    "        print(prediction[i][j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.05517189, 0.9448281 ],\n",
       "       [0.8944631 , 0.10553686],\n",
       "       [0.29608425, 0.7039158 ],\n",
       "       ...,\n",
       "       [0.8268955 , 0.17310452],\n",
       "       [0.11346654, 0.88653344],\n",
       "       [0.15222752, 0.8477725 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "j = 5\n",
    "\n",
    "model_name = 'models/' + model_type + '-' + all_labels[i] + '-' + all_labels[j] + '.h5'        \n",
    "model = keras.models.load_model(model_name)\n",
    "#print(model.summary())\n",
    "prediction = model.predict(test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=40*40*40)\n",
    "\n",
    "def real_index(prediction, i, j):\n",
    "    return j if prediction else i\n",
    "\n",
    "def prediction_for(i, j, data):\n",
    "    model_name = 'models/' + model_type + '-' + all_labels[i] + '-' + all_labels[j] + '.h5'        \n",
    "    model = keras.models.load_model(model_name)\n",
    "    #print(model.summary())\n",
    "    prediction = model.predict(prepare_data(data, 2, 24))\n",
    "    return [real_index(p, i, j) for p in list(map(np.argmax, prediction))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate test prediction for each labels pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N/A% (0 of 1) |                          | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    }
   ],
   "source": [
    "prediction = [x[:] for x in [[-1] * 40] * 40]\n",
    "for i in range(len(all_labels)):\n",
    "    bar2 = progressbar.ProgressBar(max_value=len(all_labels) - (i + 1))\n",
    "    for j in range(i + 1, len(all_labels)):\n",
    "        bar2.update(j - (i + 1))\n",
    "        prediction[i][j] = prediction_for(i, j, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96% (2336 of 2428) |################### | Elapsed Time: 0:00:01 ETA:   0:00:00"
     ]
    }
   ],
   "source": [
    "p = [None] * len(test)\n",
    "bar = progressbar.ProgressBar(max_value=len(test))\n",
    "for e in range(len(test)):\n",
    "    bar.update(e) \n",
    "    p[e] = []\n",
    "    for i in range(40):\n",
    "        for j in range(40):\n",
    "            if prediction[i][j] == -1:\n",
    "                p[e].append(-1)\n",
    "            else:\n",
    "                p[e].append(prediction[i][j][e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1821"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def most_frequent(List): \n",
    "    return max(set(List), key = List.count) \n",
    "count = 0\n",
    "predicted = [None] * len(test)\n",
    "results = [None] * len(test)\n",
    "for index in range(len(test)):\n",
    "    real = test_labels[index]\n",
    "    predicted[index] = most_frequent(list(filter(lambda a: a > -1, p[index])))\n",
    "    results[index] = Counter(list(filter(lambda a: a > -1, p[index])))\n",
    "    if int(real) == predicted[index]: \n",
    "        count+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count / len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94  0  2  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 39  8  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 94  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0]\n",
      " [ 1  0  1 13  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  1  0  0  1  0  0  1  0  0  0]\n",
      " [ 0  0  0  0 87  2  0  0  1  0  0  1  0  3  0  0  0  0  0  0  0  0  0  1\n",
      "   0  0  1  0  0  0  0  0  0  0  0  0  2  1  0  0]\n",
      " [ 0  0  0  0  0 79  0  0  2  0  3  0  0  1  1  1  0  0  0  0  2  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0]\n",
      " [ 0  0  1  0  0  0  9  2  0  0  2  0  0  0  0  0  0  0  2  0  0  0  0  0\n",
      "   0  0  1  0  0  1  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  2  0  0  0  0 80  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0\n",
      "   0  2  0  0  0  1  0  0  0  0  4  0  8  0  0  0]\n",
      " [ 0  0  3  0  0  0  0  0 88  0  1  0  0  0  0  0  0  0  0  0  2  0  0  0\n",
      "   0  0  0  0  2  0  0  0  3  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  1  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  1  0  0  0  0  0  0  0  3  0  0  2  0  0]\n",
      " [ 0  0  0  0  0  1  1  0  0  0  6  0  0  0  0  1  0  0  0  1  0  0  0  1\n",
      "   0  0  1  0  0  0  0  0  0  0  0  0  0  7  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0 11  0  5  0  0  0  0  0  0  0  0  1  0\n",
      "   0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  1  0  0  0  0  0  0  1 58  0  0  0  0  0  0  0  0  0  0  1\n",
      "   0  1  1  0  0  0  5  0  0 14  0  0  2  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  4  0 14  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  1  0  0  0  0  0  0  2  0 64  1  0  0  0  0  0  0  1 12\n",
      "   0  0  0  0  0  0  0  0  0  1  0  0  0  0  1  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1\n",
      "   1  0  9  0  0  0  0  0  0  0  0  0  0  7  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0 90  0  0  0  0  0  4  1\n",
      "   0  1  0  0  0  0  0  0  0  0  0  0  2  0  0  0]\n",
      " [ 2  0  0  3  0  0  0  0  0  0  1  1  0  0  0  0  0 82  8  0  0  0  0  0\n",
      "   0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0 17  0  1  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  2  0  0  0 10  0  0  0  0\n",
      "   0  0  2  0  0  0  0  0  2  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  1  0  4  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  1 87  3  1\n",
      "   0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0  1  0 94  1\n",
      "   0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  2  0  0  0  1  0 10  0  1  0  0  0  0  0  0 55\n",
      "   0  1  0  0  0  0  0  0  1  9  0  1  1  2  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  1  0  1  0  0  0  0  0  1  1  0  0  0\n",
      "   6  0  7  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 1  0  2  4  7  0  0  1  3  0  3  0  0  0  1  0  1  1  0  0  2  1  4  1\n",
      "   0 53  2  1  1  1  0  1  0  2  2  0  3  1  0  0]\n",
      " [ 0  0  0  1  0  2  0  1  2  0  1  1  0  1  0  9  0  0  1  5  0  0  0  0\n",
      "   6  3 53  1  0  0  0  0  0  0  0  0  1 11  0  0]\n",
      " [ 0  0  2  0  5  0  0  1  1  0  0  0  0  0  0  0  3  0  0  1  1  1  1  2\n",
      "   0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  5  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  2  5  0  0\n",
      "   0  2  1  0 75  1  0  1  0  0  1  0  2  1  0  0]\n",
      " [ 3  0  1  0  0  0  0  0  2  0  0  0  0  0  2  0  1  0  0  0  0  1  0  1\n",
      "   0  1  0  0  0  6  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  1\n",
      "   0  0  0  0  0  0 95  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  4  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0\n",
      "   0  0  3  0  1  0  1  7  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  3  0  0  0  3  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  6  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 29  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0 70  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  2  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  1\n",
      "   0  1  0  1  0  0  0  0  0  0 11  0  1  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  4  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0\n",
      "   0  1  0  0  0  0  0  0  0  1  0 90  0  0  0  0]\n",
      " [ 1  0  0  3  6  1  0  0  0  0  2  0  0  0  3  0  2  0  0  0  0  0  1  2\n",
      "   0  3  2  2  1  0  1  0  0  2  0  0 66  1  0  0]\n",
      " [ 0  1  0  0  1  6  1  0  0  2  5  0  1  0  0  6  0  0  0  1  0  0  0  3\n",
      "   0  1  1  0  0  0  0  0  0  0  0  1  0 69  0  0]\n",
      " [ 0  0  0  0  7  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0  0  1\n",
      "   0  0  1  0  0  0  0  0  0  0  0  0  0  2  4  0]\n",
      " [ 0  0  0  0  1  1  0  0  0  0  0  0  0  0  1  1  0  0  0  0  0  0  3  0\n",
      "   0  1  1  0  0  0  0  0  0  0  0  0  1  0  1  8]]\n"
     ]
    }
   ],
   "source": [
    "matrix = np.array([[0] * 40] * 40)\n",
    "\n",
    "for index in range(len(test)):\n",
    "    matrix[test_labels[index]][predicted[index]] += 1\n",
    "    \n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.91      0.95      0.93        99\n",
      "     bathtub       0.97      0.80      0.88        49\n",
      "         bed       0.76      0.95      0.85        99\n",
      "       bench       0.54      0.68      0.60        19\n",
      "   bookshelf       0.66      0.88      0.76        99\n",
      "      bottle       0.81      0.80      0.81        99\n",
      "        bowl       0.75      0.47      0.58        19\n",
      "         car       0.91      0.81      0.86        99\n",
      "       chair       0.77      0.89      0.83        99\n",
      "        cone       0.79      0.58      0.67        19\n",
      "         cup       0.19      0.32      0.24        19\n",
      "     curtain       0.52      0.58      0.55        19\n",
      "        desk       0.62      0.68      0.65        85\n",
      "        door       0.54      0.74      0.62        19\n",
      "     dresser       0.74      0.75      0.75        85\n",
      "  flower_pot       0.04      0.05      0.05        19\n",
      "   glass_box       0.91      0.91      0.91        99\n",
      "      guitar       0.99      0.83      0.90        99\n",
      "    keyboard       0.53      0.89      0.67        19\n",
      "        lamp       0.50      0.53      0.51        19\n",
      "      laptop       0.58      0.95      0.72        19\n",
      "      mantel       0.92      0.88      0.90        99\n",
      "     monitor       0.84      0.95      0.89        99\n",
      " night_stand       0.64      0.65      0.64        85\n",
      "      person       0.46      0.32      0.37        19\n",
      "       piano       0.73      0.54      0.62        99\n",
      "       plant       0.61      0.54      0.57        99\n",
      "       radio       0.14      0.05      0.08        19\n",
      "  range_hood       0.94      0.76      0.84        99\n",
      "        sink       0.55      0.32      0.40        19\n",
      "        sofa       0.92      0.96      0.94        99\n",
      "      stairs       0.78      0.37      0.50        19\n",
      "       stool       0.50      0.32      0.39        19\n",
      "       table       0.68      0.71      0.69        99\n",
      "        tent       0.50      0.58      0.54        19\n",
      "      toilet       0.96      0.91      0.93        99\n",
      "    tv_stand       0.72      0.67      0.69        99\n",
      "        vase       0.57      0.70      0.62        99\n",
      "    wardrobe       0.67      0.21      0.32        19\n",
      "        xbox       0.89      0.42      0.57        19\n",
      "\n",
      "    accuracy                           0.75      2428\n",
      "   macro avg       0.68      0.65      0.65      2428\n",
      "weighted avg       0.76      0.75      0.75      2428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, predicted, target_names=all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('prediction-' + model_type + '.txt', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction2 = np.load('prediction-conv3d.txt.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_labels)):\n",
    "    for j in range(i + 1, len(all_labels)):\n",
    "        model_name = 'models/' + model_type + '-' + all_labels[i] + '-' + all_labels[j] + '.h5'        \n",
    "        model = keras.models.load_model(model_name)\n",
    "        print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('models/dense-20-24')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 20\n",
    "res = 24\n",
    "base_labels = all_labels[:num_classes]\n",
    "test, test_labels = load_data(res, base_labels, 'test', 1.0, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(\n",
    "            prepare_data(test, num_classes),  \n",
    "            test_labels, \n",
    "            verbose=2\n",
    "        )\n",
    "print('\\nTest accuracy for ' + str(num_classes) + ' classes width res ' + str(res) + ':', test_acc)\n",
    "print_confusion_matrix(test, test_labels, base_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(img, expected = '', predicted = ''):\n",
    "    fig = plt.figure(figsize=[10,10])\n",
    "    ax = fig.gca(projection='3d')\n",
    "    cube1 = (img[:,:,:] >= 1)\n",
    "    ax.voxels(cube1, facecolors=\"blue\")\n",
    "    plt.title('Expected: {}\\n Predicted: {}'.format(expected, predicted), y=-0.01)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not len(test):\n",
    "    test, test_labels = load_data(dim, base_labels, 'test', 100)\n",
    "test_loss, test_acc = model.evaluate(test,  test_labels, verbose=2)\n",
    "p = model.predict(test)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = random.randint(0, len(test))\n",
    "\n",
    "predicted_index = np.argmax(p[index])\n",
    "expected = base_labels[int(test_labels[index])]\n",
    "predicted = base_labels[predicted_index]\n",
    "draw(test[index], expected, predicted)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "base_labels = all_labels[:num_classes]\n",
    "num_classes = num_classes\n",
    "res = 24\n",
    "training, training_labels = load_data(res, base_labels, 'train', 1, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training))\n",
    "model = prepare_model(res, num_classes, 1)\n",
    "train(model, training, training_labels, res, num_classes, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base_labels)\n",
    "test, test_labels = load_data(res, base_labels, 'test', 1.0, True)\n",
    "print(len(test))\n",
    "test_loss, test_acc = model.evaluate(\n",
    "    test,  \n",
    "    test_labels, \n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(test)\n",
    "for index in range(len(p)):\n",
    "    predicted_index = np.argmax(p[index])\n",
    "    expected = base_labels[int(test_labels[index])]\n",
    "    predicted = base_labels[predicted_index]\n",
    "    if expected != predicted:\n",
    "        draw(test[index], expected, predicted)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
