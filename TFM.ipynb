{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import gc\n",
    "from sys import getsizeof\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(res, source_labels, dataset='train', size=100, verbosity = False):\n",
    "    data = np.zeros((0, res, res, res))\n",
    "    labels = []\n",
    "    for i, label in enumerate(source_labels):\n",
    "        filename = './output/' + label + '/output-' + dataset + '-' + str(res) + '.h5'\n",
    "        if verbosity:\n",
    "            print(filename)\n",
    "        file = h5py.File(filename, 'r')\n",
    "        data = np.concatenate((data, file['tensor']))\n",
    "        labels = np.concatenate((labels, np.full((len(file['tensor'])), i)))\n",
    "        file.close()\n",
    "        gc.collect()\n",
    "    return (data, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(res, num_classes, verbosity = 0):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(res, res, res)),\n",
    "        keras.layers.Dense(res*2, activation='relu'),\n",
    "        keras.layers.Dense(res, activation='relu'),\n",
    "        keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    if (verbosity == 1):\n",
    "        print(model.summary())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, training, training_labels, res, verbosity = 0):\n",
    "    log_dir = \"logs/fit/\" + str(res) + '-' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    validation_split = 0.1\n",
    "    epochs = 30\n",
    "    \n",
    "    model.fit(training, \n",
    "              training_labels, \n",
    "              epochs=epochs,\n",
    "              verbose=verbosity,\n",
    "              #validation_split=validation_split,\n",
    "              callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_labels = ['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor', 'night_stand', 'sofa', 'table', 'toilet']\n",
    "all_labels = ['airplane', 'bathtub', 'bed', 'bench', 'bookshelf', 'bottle', 'bowl', 'car', 'chair', 'cone', \n",
    "                 'cup', 'curtain', 'desk', 'door', 'dresser', 'flower_pot', 'glass_box', 'guitar','keyboard', 'lamp',\n",
    "                 'laptop', 'mantel', 'monitor', 'night_stand', 'person', 'piano', 'plant', \n",
    "                 'radio', 'range_hood', 'sink', 'sofa', 'stairs', 'stool', 'table', 'tent', 'toilet', 'tv_stand', \n",
    "                 'vase', 'wardrobe', 'xbox']\n",
    "#num_classes = len(base_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 0s - loss: 0.3989 - accuracy: 0.9113\n",
      "\n",
      "Test accuracy for 10 classes width res 24: 0.9112675786018372\n",
      "23/23 - 0s - loss: 0.3360 - accuracy: 0.9085\n",
      "\n",
      "Test accuracy for 10 classes width res 32: 0.908450722694397\n",
      "23/23 - 0s - loss: 0.5114 - accuracy: 0.9070\n",
      "\n",
      "Test accuracy for 10 classes width res 48: 0.9070422649383545\n",
      "38/38 - 0s - loss: 0.6279 - accuracy: 0.8527\n",
      "\n",
      "Test accuracy for 20 classes width res 24: 0.8527454137802124\n",
      "38/38 - 0s - loss: 0.6704 - accuracy: 0.8594\n",
      "\n",
      "Test accuracy for 20 classes width res 32: 0.8594009876251221\n",
      "38/38 - 0s - loss: 0.7966 - accuracy: 0.8511\n",
      "\n",
      "Test accuracy for 20 classes width res 48: 0.8510815501213074\n",
      "59/59 - 0s - loss: 1.0815 - accuracy: 0.7548\n",
      "\n",
      "Test accuracy for 30 classes width res 24: 0.7548179626464844\n",
      "59/59 - 0s - loss: 1.1833 - accuracy: 0.7741\n",
      "\n",
      "Test accuracy for 30 classes width res 32: 0.7740899324417114\n",
      "59/59 - 1s - loss: 1.2951 - accuracy: 0.7682\n",
      "\n",
      "Test accuracy for 30 classes width res 48: 0.7682012915611267\n",
      "78/78 - 0s - loss: 1.2599 - accuracy: 0.7115\n",
      "\n",
      "Test accuracy for 40 classes width res 24: 0.7115073204040527\n",
      "78/78 - 0s - loss: 1.5400 - accuracy: 0.7135\n",
      "\n",
      "Test accuracy for 40 classes width res 32: 0.7135332226753235\n",
      "78/78 - 1s - loss: 1.9055 - accuracy: 0.7030\n",
      "\n",
      "Test accuracy for 40 classes width res 48: 0.7029983997344971\n"
     ]
    }
   ],
   "source": [
    "subclases = [10, 20, 30, 40]\n",
    "resolutions = [24, 32, 48]\n",
    "\n",
    "for j, num_classes in enumerate(subclases):\n",
    "    base_labels = all_labels[:num_classes]\n",
    "    for i,res in enumerate(resolutions):\n",
    "        training, training_labels = load_data(res, base_labels, 'train', 100)\n",
    "        model = prepare_model(res, num_classes)\n",
    "        train(model, training, training_labels, res)\n",
    "        test, test_labels = load_data(res, base_labels, 'test', 100)\n",
    "        test_loss, test_acc = model.evaluate(test,  test_labels, verbose=2)\n",
    "        print('\\nTest accuracy for ' + str(num_classes) + ' classes width res ' + str(res) + ':', test_acc)\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(img, expected = '', predicted = ''):\n",
    "    fig = plt.figure(figsize=[10,10])\n",
    "    ax = fig.gca(projection='3d')\n",
    "    cube1 = (img[:,:,:] >= 1)\n",
    "    ax.voxels(cube1, facecolors=\"blue\")\n",
    "    plt.title('Expected: {}\\n Predicted: {}'.format(expected, predicted), y=-0.01)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not len(test):\n",
    "    test, test_labels = load_data(dim, base_labels, 'test', 100)\n",
    "test_loss, test_acc = model.evaluate(test,  test_labels, verbose=2)\n",
    "p = model.predict(test)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = random.randint(0, len(test))\n",
    "\n",
    "predicted_index = np.argmax(p[index])\n",
    "expected = base_labels[int(test_labels[index])]\n",
    "predicted = base_labels[predicted_index]\n",
    "draw(test[index], expected, predicted)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
