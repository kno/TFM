{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 5.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=0.11\n",
      "  Downloading joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "\u001b[K     |████████████████████████████████| 300 kB 5.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.2)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=2397 sha256=b3395cdcf9ad0808dfd719c1fef19326d38167589c6ef53e712fd5fc437d2b84\n",
      "  Stored in directory: /root/.cache/pip/wheels/23/9d/42/5ec745cbbb17517000a53cecc49d6a865450d1f5cb16dc8a9c\n",
      "Successfully built sklearn\n",
      "Installing collected packages: joblib, threadpoolctl, scikit-learn, sklearn\n",
      "Successfully installed joblib-0.16.0 scikit-learn-0.23.1 sklearn-0.0 threadpoolctl-2.1.0\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import gc\n",
    "from sys import getsizeof\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB = 1\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#The variable GB is the memory size you want to use.\n",
    "config = [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=(1500*GB))]\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1*X GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], config)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "np.set_printoptions(threshold=40*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(res, source_labels, dataset='train', size=1., verbosity = False):\n",
    "    data = np.zeros((0, res, res, res))\n",
    "    labels = []\n",
    "    for i, label in enumerate(source_labels):\n",
    "        filename = './output/' + label + '/output-' + dataset + '-' + str(res) + '.h5'\n",
    "        file = h5py.File(filename, 'r')\n",
    "        tensor_len = len(file['tensor'])\n",
    "        picked_ids = random.sample(range(tensor_len), math.ceil(tensor_len * size))\n",
    "        if verbosity:\n",
    "            print(filename)\n",
    "            print('Picking ' + str(math.ceil(tensor_len * size)) + ' from ' + str(len(file['tensor'])) )\n",
    "        data = np.concatenate((data, [file['tensor'][index] for index in picked_ids]))\n",
    "        labels = np.concatenate((labels, np.full(len(picked_ids), i)))\n",
    "        file.close()\n",
    "        gc.collect()\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(data)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(labels)\n",
    "    return (data, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 13824)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 48)                663600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                588       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                260       \n",
      "=================================================================\n",
      "Total params: 664,448\n",
      "Trainable params: 664,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f05b4bb1f60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_model(res, num_classes, verbosity = 0):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(res, res, res)),\n",
    "        keras.layers.Dense(res*2, activation='relu'),\n",
    "        keras.layers.Dense(res/2, activation='sigmoid'),\n",
    "        keras.layers.Dropout(.2, input_shape=(2,)),\n",
    "        keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    if (verbosity == 1):\n",
    "        print(model.summary())\n",
    "    return model\n",
    "def prepare_data(data, num_classes):\n",
    "    return data\n",
    "model_type = 'dense'\n",
    "prepare_model(24, 20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 10, 10, 10, 24)    5208      \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 3, 3, 3, 24)       72024     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 648)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                7788      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                130       \n",
      "=================================================================\n",
      "Total params: 85,150\n",
      "Trainable params: 85,150\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fe2fe57c3c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_model(res, num_classes, verbosity = 0):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv3D(\n",
    "                res, \n",
    "                kernel_size=(6),\n",
    "                strides=(2),\n",
    "                activation='relu', \n",
    "                kernel_initializer='he_uniform', \n",
    "                data_format=\"channels_last\",\n",
    "                input_shape=(res, res, res, 1)\n",
    "            ),        \n",
    "        keras.layers.Conv3D(\n",
    "                res, \n",
    "                kernel_size=(5),\n",
    "                strides=(2),\n",
    "                activation='relu', \n",
    "                kernel_initializer='he_uniform'\n",
    "            ),        \n",
    "        #keras.layers.Conv3D(\n",
    "        #        res, \n",
    "        #        kernel_size=(2),\n",
    "        #        activation='relu', \n",
    "        #        kernel_initializer='he_uniform'\n",
    "        #    ),        \n",
    "   \n",
    "        #keras.layers.MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(res/2, activation='relu'),\n",
    "        keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    if (verbosity == 1):\n",
    "        print(model.summary())\n",
    "    return model\n",
    "def prepare_data(data, num_classes, res):\n",
    "    return data.reshape(len(data), res, res, res, 1)\n",
    "model_type = 'conv3d'\n",
    "prepare_model(24, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, training, training_labels, res, num_classes, verbosity = 0):\n",
    "    log_dir = \"logs/fit/\" + str(res) + '-' + str(num_classes) + '-' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    if verbosity == 1:\n",
    "        print(\"Log file \" + log_dir)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    validation_split = 0.1\n",
    "    epochs = 2 * num_classes\n",
    "    \n",
    "#    model.fit(\n",
    "#        keras.utils.to_categorical(training, num_clases), \n",
    "#        training_labels, \n",
    "#        epochs=epochs)\n",
    "    \n",
    "    model.fit(\n",
    "        prepare_data(training, num_classes, res), \n",
    "        training_labels, \n",
    "        epochs=epochs,\n",
    "        verbose=verbosity,\n",
    "        callbacks=[tensorboard_callback],\n",
    "        validation_split=validation_split\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix and Classification Report\n",
    "def print_confusion_matrix(test, test_labels, base_labels, res):\n",
    "    Y_pred = model.predict_generator(prepare_data(test, len(base_labels), res), len(test))\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(test_labels, y_pred))\n",
    "    print('Classification Report')\n",
    "    print(classification_report(test_labels, y_pred, target_names=base_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_labels = ['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor', 'night_stand', 'sofa', 'table', 'toilet']\n",
    "all_labels = ['airplane', 'bathtub', 'bed', 'bench', 'bookshelf', 'bottle', 'bowl', 'car', 'chair', 'cone', \n",
    "                 'cup', 'curtain', 'desk', 'door', 'dresser', 'flower_pot', 'glass_box', 'guitar','keyboard', 'lamp',\n",
    "                 'laptop', 'mantel', 'monitor', 'night_stand', 'person', 'piano', 'plant', \n",
    "                 'radio', 'range_hood', 'sink', 'sofa', 'stairs', 'stool', 'table', 'tent', 'toilet', 'tv_stand', \n",
    "                 'vase', 'wardrobe', 'xbox']\n",
    "#num_classes = len(base_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_24 (Conv3D)           (None, 10, 10, 10, 24)    5208      \n",
      "_________________________________________________________________\n",
      "conv3d_25 (Conv3D)           (None, 3, 3, 3, 24)       72024     \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 648)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 12)                7788      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 40)                520       \n",
      "=================================================================\n",
      "Total params: 85,540\n",
      "Trainable params: 85,540\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "277/277 - 20s - loss: 3.1340 - accuracy: 0.2041 - val_loss: 2.6794 - val_accuracy: 0.4020\n",
      "Epoch 2/80\n",
      "277/277 - 20s - loss: 2.3464 - accuracy: 0.4600 - val_loss: 2.2165 - val_accuracy: 0.4690\n",
      "Epoch 3/80\n",
      "277/277 - 20s - loss: 1.9829 - accuracy: 0.5304 - val_loss: 1.9741 - val_accuracy: 0.5208\n",
      "Epoch 4/80\n",
      "277/277 - 20s - loss: 1.7487 - accuracy: 0.5798 - val_loss: 1.7805 - val_accuracy: 0.5868\n",
      "Epoch 5/80\n",
      "277/277 - 20s - loss: 1.5699 - accuracy: 0.6236 - val_loss: 1.6630 - val_accuracy: 0.6010\n",
      "Epoch 6/80\n",
      "277/277 - 20s - loss: 1.4410 - accuracy: 0.6447 - val_loss: 1.5622 - val_accuracy: 0.6081\n",
      "Epoch 7/80\n",
      "277/277 - 20s - loss: 1.3388 - accuracy: 0.6676 - val_loss: 1.4918 - val_accuracy: 0.6234\n",
      "Epoch 8/80\n",
      "277/277 - 20s - loss: 1.2574 - accuracy: 0.6844 - val_loss: 1.4270 - val_accuracy: 0.6284\n",
      "Epoch 9/80\n",
      "277/277 - 20s - loss: 1.1886 - accuracy: 0.6997 - val_loss: 1.3756 - val_accuracy: 0.6386\n",
      "Epoch 10/80\n",
      "277/277 - 20s - loss: 1.1307 - accuracy: 0.7093 - val_loss: 1.3440 - val_accuracy: 0.6447\n",
      "Epoch 11/80\n",
      "277/277 - 20s - loss: 1.0766 - accuracy: 0.7242 - val_loss: 1.3257 - val_accuracy: 0.6629\n",
      "Epoch 12/80\n",
      "277/277 - 20s - loss: 1.0341 - accuracy: 0.7347 - val_loss: 1.2947 - val_accuracy: 0.6670\n",
      "Epoch 13/80\n",
      "277/277 - 20s - loss: 0.9950 - accuracy: 0.7417 - val_loss: 1.2524 - val_accuracy: 0.6782\n",
      "Epoch 14/80\n",
      "277/277 - 20s - loss: 0.9560 - accuracy: 0.7533 - val_loss: 1.2259 - val_accuracy: 0.6772\n",
      "Epoch 15/80\n",
      "277/277 - 20s - loss: 0.9264 - accuracy: 0.7616 - val_loss: 1.2156 - val_accuracy: 0.6944\n",
      "Epoch 16/80\n",
      "277/277 - 20s - loss: 0.8951 - accuracy: 0.7685 - val_loss: 1.2078 - val_accuracy: 0.6832\n",
      "Epoch 17/80\n",
      "277/277 - 20s - loss: 0.8686 - accuracy: 0.7697 - val_loss: 1.1845 - val_accuracy: 0.6893\n",
      "Epoch 18/80\n",
      "277/277 - 20s - loss: 0.8393 - accuracy: 0.7805 - val_loss: 1.1686 - val_accuracy: 0.6914\n",
      "Epoch 19/80\n",
      "277/277 - 20s - loss: 0.8109 - accuracy: 0.7866 - val_loss: 1.1543 - val_accuracy: 0.6924\n",
      "Epoch 20/80\n",
      "277/277 - 20s - loss: 0.7886 - accuracy: 0.7959 - val_loss: 1.1505 - val_accuracy: 0.7015\n",
      "Epoch 21/80\n",
      "277/277 - 20s - loss: 0.7661 - accuracy: 0.7972 - val_loss: 1.1795 - val_accuracy: 0.6934\n",
      "Epoch 22/80\n",
      "277/277 - 20s - loss: 0.7487 - accuracy: 0.8010 - val_loss: 1.1148 - val_accuracy: 0.7046\n",
      "Epoch 23/80\n",
      "277/277 - 20s - loss: 0.7271 - accuracy: 0.8067 - val_loss: 1.1107 - val_accuracy: 0.7117\n",
      "Epoch 24/80\n",
      "277/277 - 20s - loss: 0.7043 - accuracy: 0.8126 - val_loss: 1.1214 - val_accuracy: 0.7025\n",
      "Epoch 25/80\n",
      "277/277 - 20s - loss: 0.6871 - accuracy: 0.8169 - val_loss: 1.0938 - val_accuracy: 0.7056\n",
      "Epoch 26/80\n",
      "277/277 - 20s - loss: 0.6688 - accuracy: 0.8215 - val_loss: 1.0961 - val_accuracy: 0.7147\n",
      "Epoch 27/80\n",
      "277/277 - 20s - loss: 0.6508 - accuracy: 0.8248 - val_loss: 1.0995 - val_accuracy: 0.7076\n",
      "Epoch 28/80\n",
      "277/277 - 20s - loss: 0.6338 - accuracy: 0.8310 - val_loss: 1.1219 - val_accuracy: 0.7086\n",
      "Epoch 29/80\n",
      "277/277 - 20s - loss: 0.6159 - accuracy: 0.8348 - val_loss: 1.1050 - val_accuracy: 0.7046\n",
      "Epoch 30/80\n",
      "277/277 - 20s - loss: 0.5985 - accuracy: 0.8365 - val_loss: 1.0980 - val_accuracy: 0.7147\n",
      "Epoch 31/80\n",
      "277/277 - 20s - loss: 0.5829 - accuracy: 0.8421 - val_loss: 1.0642 - val_accuracy: 0.7279\n",
      "Epoch 32/80\n",
      "277/277 - 20s - loss: 0.5733 - accuracy: 0.8436 - val_loss: 1.0868 - val_accuracy: 0.7107\n",
      "Epoch 33/80\n",
      "277/277 - 20s - loss: 0.5571 - accuracy: 0.8493 - val_loss: 1.0814 - val_accuracy: 0.7137\n",
      "Epoch 34/80\n",
      "277/277 - 20s - loss: 0.5392 - accuracy: 0.8534 - val_loss: 1.1168 - val_accuracy: 0.7168\n",
      "Epoch 35/80\n",
      "277/277 - 20s - loss: 0.5266 - accuracy: 0.8592 - val_loss: 1.1000 - val_accuracy: 0.7107\n",
      "Epoch 36/80\n",
      "277/277 - 20s - loss: 0.5127 - accuracy: 0.8606 - val_loss: 1.0738 - val_accuracy: 0.7208\n",
      "Epoch 37/80\n",
      "277/277 - 20s - loss: 0.5021 - accuracy: 0.8651 - val_loss: 1.0970 - val_accuracy: 0.7096\n",
      "Epoch 38/80\n",
      "277/277 - 20s - loss: 0.4904 - accuracy: 0.8681 - val_loss: 1.0920 - val_accuracy: 0.7178\n",
      "Epoch 39/80\n",
      "277/277 - 20s - loss: 0.4818 - accuracy: 0.8696 - val_loss: 1.0598 - val_accuracy: 0.7330\n",
      "Epoch 40/80\n",
      "277/277 - 20s - loss: 0.4667 - accuracy: 0.8738 - val_loss: 1.0741 - val_accuracy: 0.7299\n",
      "Epoch 41/80\n",
      "277/277 - 20s - loss: 0.4530 - accuracy: 0.8810 - val_loss: 1.0860 - val_accuracy: 0.7239\n",
      "Epoch 42/80\n",
      "277/277 - 20s - loss: 0.4446 - accuracy: 0.8815 - val_loss: 1.0935 - val_accuracy: 0.7208\n",
      "Epoch 43/80\n",
      "277/277 - 20s - loss: 0.4352 - accuracy: 0.8832 - val_loss: 1.1344 - val_accuracy: 0.7168\n",
      "Epoch 44/80\n",
      "277/277 - 20s - loss: 0.4248 - accuracy: 0.8862 - val_loss: 1.0921 - val_accuracy: 0.7299\n",
      "Epoch 45/80\n",
      "277/277 - 20s - loss: 0.4146 - accuracy: 0.8904 - val_loss: 1.0881 - val_accuracy: 0.7320\n",
      "Epoch 46/80\n",
      "277/277 - 20s - loss: 0.4079 - accuracy: 0.8906 - val_loss: 1.1008 - val_accuracy: 0.7259\n",
      "Epoch 47/80\n",
      "277/277 - 20s - loss: 0.3965 - accuracy: 0.8938 - val_loss: 1.0813 - val_accuracy: 0.7360\n",
      "Epoch 48/80\n",
      "277/277 - 20s - loss: 0.3857 - accuracy: 0.8973 - val_loss: 1.1190 - val_accuracy: 0.7310\n",
      "Epoch 49/80\n",
      "277/277 - 20s - loss: 0.3796 - accuracy: 0.8982 - val_loss: 1.0911 - val_accuracy: 0.7381\n",
      "Epoch 50/80\n",
      "277/277 - 20s - loss: 0.3689 - accuracy: 0.9035 - val_loss: 1.1105 - val_accuracy: 0.7279\n",
      "Epoch 51/80\n",
      "277/277 - 20s - loss: 0.3641 - accuracy: 0.9062 - val_loss: 1.0911 - val_accuracy: 0.7371\n",
      "Epoch 52/80\n",
      "277/277 - 20s - loss: 0.3541 - accuracy: 0.9065 - val_loss: 1.0914 - val_accuracy: 0.7401\n",
      "Epoch 53/80\n",
      "277/277 - 20s - loss: 0.3454 - accuracy: 0.9115 - val_loss: 1.1103 - val_accuracy: 0.7350\n",
      "Epoch 54/80\n",
      "277/277 - 20s - loss: 0.3403 - accuracy: 0.9113 - val_loss: 1.1265 - val_accuracy: 0.7330\n",
      "Epoch 55/80\n",
      "277/277 - 20s - loss: 0.3326 - accuracy: 0.9116 - val_loss: 1.1277 - val_accuracy: 0.7411\n",
      "Epoch 56/80\n",
      "277/277 - 20s - loss: 0.3249 - accuracy: 0.9130 - val_loss: 1.1294 - val_accuracy: 0.7381\n",
      "Epoch 57/80\n",
      "277/277 - 20s - loss: 0.3188 - accuracy: 0.9209 - val_loss: 1.1705 - val_accuracy: 0.7350\n",
      "Epoch 58/80\n",
      "277/277 - 20s - loss: 0.3150 - accuracy: 0.9168 - val_loss: 1.1472 - val_accuracy: 0.7340\n",
      "Epoch 59/80\n",
      "277/277 - 20s - loss: 0.3049 - accuracy: 0.9206 - val_loss: 1.1535 - val_accuracy: 0.7421\n",
      "Epoch 60/80\n",
      "277/277 - 20s - loss: 0.2987 - accuracy: 0.9232 - val_loss: 1.1762 - val_accuracy: 0.7310\n",
      "Epoch 61/80\n",
      "277/277 - 20s - loss: 0.2916 - accuracy: 0.9256 - val_loss: 1.1763 - val_accuracy: 0.7279\n",
      "Epoch 62/80\n",
      "277/277 - 20s - loss: 0.2852 - accuracy: 0.9267 - val_loss: 1.1576 - val_accuracy: 0.7452\n",
      "Epoch 63/80\n",
      "277/277 - 20s - loss: 0.2834 - accuracy: 0.9277 - val_loss: 1.1712 - val_accuracy: 0.7381\n",
      "Epoch 64/80\n",
      "277/277 - 20s - loss: 0.2759 - accuracy: 0.9306 - val_loss: 1.2071 - val_accuracy: 0.7208\n",
      "Epoch 65/80\n",
      "277/277 - 20s - loss: 0.2726 - accuracy: 0.9318 - val_loss: 1.1836 - val_accuracy: 0.7411\n",
      "Epoch 66/80\n",
      "277/277 - 20s - loss: 0.2633 - accuracy: 0.9350 - val_loss: 1.2028 - val_accuracy: 0.7411\n",
      "Epoch 67/80\n",
      "277/277 - 20s - loss: 0.2603 - accuracy: 0.9349 - val_loss: 1.1909 - val_accuracy: 0.7421\n",
      "Epoch 68/80\n",
      "277/277 - 20s - loss: 0.2544 - accuracy: 0.9350 - val_loss: 1.2319 - val_accuracy: 0.7411\n",
      "Epoch 69/80\n",
      "277/277 - 20s - loss: 0.2515 - accuracy: 0.9370 - val_loss: 1.2411 - val_accuracy: 0.7239\n",
      "Epoch 70/80\n",
      "277/277 - 20s - loss: 0.2461 - accuracy: 0.9384 - val_loss: 1.2207 - val_accuracy: 0.7492\n",
      "Epoch 71/80\n",
      "277/277 - 20s - loss: 0.2435 - accuracy: 0.9404 - val_loss: 1.2460 - val_accuracy: 0.7381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/80\n",
      "277/277 - 20s - loss: 0.2368 - accuracy: 0.9419 - val_loss: 1.2261 - val_accuracy: 0.7462\n",
      "Epoch 73/80\n",
      "277/277 - 20s - loss: 0.2343 - accuracy: 0.9397 - val_loss: 1.2413 - val_accuracy: 0.7482\n",
      "Epoch 74/80\n",
      "277/277 - 20s - loss: 0.2295 - accuracy: 0.9436 - val_loss: 1.2553 - val_accuracy: 0.7431\n",
      "Epoch 75/80\n",
      "277/277 - 20s - loss: 0.2248 - accuracy: 0.9456 - val_loss: 1.2869 - val_accuracy: 0.7503\n",
      "Epoch 76/80\n",
      "277/277 - 20s - loss: 0.2221 - accuracy: 0.9434 - val_loss: 1.2575 - val_accuracy: 0.7523\n",
      "Epoch 77/80\n",
      "277/277 - 20s - loss: 0.2209 - accuracy: 0.9454 - val_loss: 1.2918 - val_accuracy: 0.7360\n",
      "Epoch 78/80\n",
      "277/277 - 20s - loss: 0.2161 - accuracy: 0.9468 - val_loss: 1.2962 - val_accuracy: 0.7350\n",
      "Epoch 79/80\n",
      "277/277 - 20s - loss: 0.2078 - accuracy: 0.9482 - val_loss: 1.3268 - val_accuracy: 0.7320\n",
      "Epoch 80/80\n",
      "277/277 - 20s - loss: 0.2068 - accuracy: 0.9487 - val_loss: 1.3618 - val_accuracy: 0.7310\n",
      "78/78 - 2s - loss: 1.4455 - accuracy: 0.7164\n",
      "\n",
      "Test accuracy for 40 classes width res 24: 0.7163695096969604\n",
      "Confusion Matrix\n",
      "[[95  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0]\n",
      " [ 0 34  2  1  0  0  2  1  0  0  0  0  0  0  1  1  1  0  0  0  0  0  0  1\n",
      "   0  0  0  0  0  1  2  0  0  0  1  1  0  0  0  1]\n",
      " [ 0  0 88  0  0  0  0  0  0  0  0  0  1  0  0  0  2  0  3  0  0  0  0  0\n",
      "   0  0  0  1  0  1  1  0  0  2  0  0  1  0  0  0]\n",
      " [ 0  0  0  9  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  2  0  0\n",
      "   0  1  0  0  0  0  1  0  0  2  0  0  2  0  0  0]\n",
      " [ 0  0  0  0 83  1  0  0  2  0  0  2  0  2  0  0  0  0  0  0  0  2  0  0\n",
      "   2  0  0  0  0  0  0  0  0  0  0  0  1  0  2  3]\n",
      " [ 0  1  0  1  1 79  0  0  0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n",
      "   1  0  0  0  0  1  0  1  0  0  0  0  4  9  0  0]\n",
      " [ 0  1  0  2  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  2  0  1  0  0  0  0  2  2  0  0]\n",
      " [ 1  0  0  0  0  0  0 75  0  0  0  0  0  0  0  0  2  1  1  0  1  0  0  0\n",
      "   0  0  0  5  0  1  1  0  0  0 11  0  1  0  0  0]\n",
      " [ 0  0  0  0  1  1  1  0 88  1  0  0  0  0  0  0  0  0  0  0  0  0  0  1\n",
      "   0  0  1  1  0  0  0  1  0  0  0  2  1  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  1  0  0  0  0  0  0  1  0  0  2  0  0]\n",
      " [ 0  0  0  0  1  1  1  0  0  0  4  0  0  0  0  1  0  0  0  0  0  0  0  0\n",
      "   0  1  0  0  0  0  0  0  0  0  0  0  1  9  0  1]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0 11  0  5  0  0  0  0  0  0  0  0  1  0\n",
      "   0  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 1  0  2  1  0  0  0  0  0  0  0  0 49  0  5  0  0  1  1  2  1  0  1  3\n",
      "   0  1  0  0  0  0  5  0  0 11  0  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  4  0 15  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  2  0  0  0  0  0  0  0  0 62  0  1  0  0  0  1  0  2 15\n",
      "   0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0\n",
      "   2  0  6  0  0  1  0  2  0  0  0  0  0  7  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  1  1  0 89  0  0  0  0  0  0  2\n",
      "   0  1  0  1  1  1  0  0  0  0  0  1  0  1  0  0]\n",
      " [ 2  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 80 11  0  2  0  0  0\n",
      "   0  1  0  0  0  1  0  0  0  0  0  0  2  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0\n",
      "   0  0  0  1  0  0  0  0  0  0  1  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  2  0  0  0  8  0  0  0  0\n",
      "   1  0  2  0  0  0  0  1  0  0  0  0  0  2  1  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 15  0  0  0\n",
      "   0  0  0  1  1  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  3  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0  0 89  2  0\n",
      "   1  0  0  0  0  0  0  0  0  0  0  1  0  0  1  1]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  2  0  0  0  0  0  2  0 90  0\n",
      "   0  0  0  0  0  0  0  0  0  0  1  0  0  0  3  1]\n",
      " [ 0  0  1  0  2  0  0  0  3  0  2  0  2  0 15  1  0  0  0  0  0  0  0 49\n",
      "   0  0  0  0  0  0  0  1  1  6  2  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  1  0  0  0\n",
      "  10  0  3  0  0  0  0  1  0  0  0  0  0  3  0  0]\n",
      " [ 2  0  3  1  5  0  0  3  1  1  0  1  0  0  0  0  1  0  0  0  4  3  3  0\n",
      "   0 41  4  3  4  2  0  2  0  1  3  1  8  0  2  1]\n",
      " [ 0  0  0  0  2  4  0  1  1  1  2  2  0  0  0  5  0  0  1  5  0  0  0  0\n",
      "   7  3 46  1  0  0  0  4  1  0  0  1  2 11  0  0]\n",
      " [ 0  0  0  0  4  0  0  1  0  0  1  0  0  0  0  0  3  0  0  1  0  0  0  1\n",
      "   0  2  0  4  1  0  0  0  0  0  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0  1  0  0  0  4  9  0  1\n",
      "   0  0  0  3 71  0  0  0  0  0  0  0  1  0  6  2]\n",
      " [ 0  1  0  0  1  0  0  1  1  0  0  0  0  0  1  1  0  0  0  0  0  0  1  0\n",
      "   0  1  0  1  1  8  0  0  0  0  0  0  1  0  1  0]\n",
      " [ 0  0  2  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  1  0  0  0  0  1\n",
      "   0  0  0  1  0  0 93  0  0  0  1  0  0  0  0  0]\n",
      " [ 1  0  0  2  1  0  0  1  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0\n",
      "   0  0  4  0  0  2  0  7  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  2  0  0  1  0  0  0  0  2  0  0  0  0  0  1  0  0  0  0\n",
      "   0  0  1  0  0  0  0  0  8  0  0  0  0  4  1  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0 25  0  0  0  0  0  1  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0 72  0  0  1  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  2  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0\n",
      "   0  0  0  0  1  0  0  0  0  0 14  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1\n",
      "   0  0  0  0  0  0  0  0  0  0  0 94  0  1  0  1]\n",
      " [ 2  0  0  3 10  0  0  3  0  0  1  0  0  0  2  0  4  0  1  0  1  1  0  0\n",
      "   0  5  1  1  0  0  1  0  0  1  0  0 61  2  0  0]\n",
      " [ 0  0  0  0  1  8  1  0  1  2  6  0  1  0  0  3  0  0  0  0  0  0  1  1\n",
      "   0  0  1  1  0  1  0  0  0  0  1  0  1 68  1  1]\n",
      " [ 0  0  0  0  3  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  1  0  0  0  0  0  0  4  2  8  1]\n",
      " [ 0  0  0  0  2  1  0  0  0  0  0  0  0  0  1  0  0  0  0  1  1  1  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  2  4  7]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.90      0.95      0.92       100\n",
      "     bathtub       0.89      0.68      0.77        50\n",
      "         bed       0.86      0.88      0.87       100\n",
      "       bench       0.45      0.45      0.45        20\n",
      "   bookshelf       0.67      0.83      0.74       100\n",
      "      bottle       0.77      0.79      0.78       100\n",
      "        bowl       0.67      0.50      0.57        20\n",
      "         car       0.84      0.75      0.79       100\n",
      "       chair       0.85      0.88      0.87       100\n",
      "        cone       0.73      0.80      0.76        20\n",
      "         cup       0.25      0.20      0.22        20\n",
      "     curtain       0.52      0.55      0.54        20\n",
      "        desk       0.63      0.57      0.60        86\n",
      "        door       0.56      0.75      0.64        20\n",
      "     dresser       0.67      0.72      0.70        86\n",
      "  flower_pot       0.12      0.10      0.11        20\n",
      "   glass_box       0.84      0.89      0.86       100\n",
      "      guitar       0.98      0.80      0.88       100\n",
      "    keyboard       0.43      0.80      0.56        20\n",
      "        lamp       0.40      0.40      0.40        20\n",
      "      laptop       0.44      0.75      0.56        20\n",
      "      mantel       0.83      0.89      0.86       100\n",
      "     monitor       0.89      0.90      0.90       100\n",
      " night_stand       0.64      0.57      0.60        86\n",
      "      person       0.42      0.50      0.45        20\n",
      "       piano       0.71      0.41      0.52       100\n",
      "       plant       0.67      0.46      0.54       100\n",
      "       radio       0.15      0.20      0.17        20\n",
      "  range_hood       0.89      0.71      0.79       100\n",
      "        sink       0.35      0.40      0.37        20\n",
      "        sofa       0.89      0.93      0.91       100\n",
      "      stairs       0.32      0.35      0.33        20\n",
      "       stool       0.73      0.40      0.52        20\n",
      "       table       0.76      0.72      0.74       100\n",
      "        tent       0.36      0.70      0.47        20\n",
      "      toilet       0.92      0.94      0.93       100\n",
      "    tv_stand       0.61      0.61      0.61       100\n",
      "        vase       0.54      0.68      0.60       100\n",
      "    wardrobe       0.26      0.40      0.31        20\n",
      "        xbox       0.35      0.35      0.35        20\n",
      "\n",
      "    accuracy                           0.72      2468\n",
      "   macro avg       0.62      0.63      0.61      2468\n",
      "weighted avg       0.73      0.72      0.72      2468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subclases = [40]\n",
    "resolutions = [24]#, 32]#, 48]\n",
    "\n",
    "for j, num_classes in enumerate(subclases):\n",
    "    base_labels = all_labels[:num_classes]\n",
    "    for i,res in enumerate(resolutions):\n",
    "        training, training_labels = load_data(res, base_labels, 'train', 1, False)\n",
    "        model = prepare_model(res, num_classes, 1)\n",
    "        model_name = 'models/' + model_type + '-' + str(num_classes) + '-' + str(res) + '.h5'\n",
    "        train(model, training, training_labels, res, num_classes, 2)\n",
    "        model.save(model_name)\n",
    "        test, test_labels = load_data(res, base_labels, 'test', 1.0, False)\n",
    "        test_loss, test_acc = model.evaluate(\n",
    "            prepare_data(test, num_classes, res),  \n",
    "            test_labels, \n",
    "            verbose=2\n",
    "        )\n",
    "        print('\\nTest accuracy for ' + str(num_classes) + ' classes width res ' + str(res) + ':', test_acc)\n",
    "        print_confusion_matrix(test, test_labels, base_labels, res)\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_labels = all_labels\n",
    "res=24\n",
    "training, training_labels = load_data(res, base_labels, 'train', 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:626\n",
      "1:106\n",
      "2:515\n",
      "3:173\n",
      "4:572\n",
      "5:335\n",
      "6:64\n",
      "7:197\n",
      "8:889\n",
      "9:167\n",
      "10:79\n",
      "11:138\n",
      "12:200\n",
      "13:109\n",
      "14:200\n",
      "15:149\n",
      "16:171\n",
      "17:155\n",
      "18:145\n",
      "19:124\n",
      "20:149\n",
      "21:284\n",
      "22:465\n",
      "23:200\n",
      "24:88\n",
      "25:231\n",
      "26:240\n",
      "27:104\n",
      "28:115\n",
      "29:128\n",
      "30:680\n",
      "31:124\n",
      "32:90\n",
      "33:392\n",
      "34:163\n",
      "35:344\n",
      "36:267\n",
      "37:475\n",
      "38:87\n",
      "39:103\n"
     ]
    }
   ],
   "source": [
    "for i in range(40):\n",
    "    print(str(i) + ':' + str(len(training_labels[training_labels == i])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('models/dense-20-24')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 20\n",
    "res = 24\n",
    "base_labels = all_labels[:num_classes]\n",
    "test, test_labels = load_data(res, base_labels, 'test', 1.0, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(\n",
    "            prepare_data(test, num_classes),  \n",
    "            test_labels, \n",
    "            verbose=2\n",
    "        )\n",
    "print('\\nTest accuracy for ' + str(num_classes) + ' classes width res ' + str(res) + ':', test_acc)\n",
    "print_confusion_matrix(test, test_labels, base_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(img, expected = '', predicted = ''):\n",
    "    fig = plt.figure(figsize=[10,10])\n",
    "    ax = fig.gca(projection='3d')\n",
    "    cube1 = (img[:,:,:] >= 1)\n",
    "    ax.voxels(cube1, facecolors=\"blue\")\n",
    "    plt.title('Expected: {}\\n Predicted: {}'.format(expected, predicted), y=-0.01)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not len(test):\n",
    "    test, test_labels = load_data(dim, base_labels, 'test', 100)\n",
    "test_loss, test_acc = model.evaluate(test,  test_labels, verbose=2)\n",
    "p = model.predict(test)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = random.randint(0, len(test))\n",
    "\n",
    "predicted_index = np.argmax(p[index])\n",
    "expected = base_labels[int(test_labels[index])]\n",
    "predicted = base_labels[predicted_index]\n",
    "draw(test[index], expected, predicted)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "base_labels = all_labels[:num_classes]\n",
    "num_classes = num_classes\n",
    "res = 24\n",
    "training, training_labels = load_data(res, base_labels, 'train', 1, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training))\n",
    "model = prepare_model(res, num_classes, 1)\n",
    "train(model, training, training_labels, res, num_classes, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base_labels)\n",
    "test, test_labels = load_data(res, base_labels, 'test', 1.0, True)\n",
    "print(len(test))\n",
    "test_loss, test_acc = model.evaluate(\n",
    "    test,  \n",
    "    test_labels, \n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(test)\n",
    "for index in range(len(p)):\n",
    "    predicted_index = np.argmax(p[index])\n",
    "    expected = base_labels[int(test_labels[index])]\n",
    "    predicted = base_labels[predicted_index]\n",
    "    if expected != predicted:\n",
    "        draw(test[index], expected, predicted)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
