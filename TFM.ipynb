{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.2)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-0.15.1-py3-none-any.whl (298 kB)\n",
      "\u001b[K     |████████████████████████████████| 298 kB 20.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=2397 sha256=ff9b1ed56a543244f19936712a0d461a4cee70ecfc6bdf4c4b84bb3817d62975\n",
      "  Stored in directory: /root/.cache/pip/wheels/23/9d/42/5ec745cbbb17517000a53cecc49d6a865450d1f5cb16dc8a9c\n",
      "Successfully built sklearn\n",
      "Installing collected packages: joblib, threadpoolctl, scikit-learn, sklearn\n",
      "Successfully installed joblib-0.15.1 scikit-learn-0.23.1 sklearn-0.0 threadpoolctl-2.1.0\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import gc\n",
    "from sys import getsizeof\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB = 1\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#The variable GB is the memory size you want to use.\n",
    "config = [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=(1024*GB))]\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1*X GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], config)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "np.set_printoptions(threshold=40*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(res, source_labels, dataset='train', size=1., verbosity = False):\n",
    "    data = np.zeros((0, res, res, res))\n",
    "    labels = []\n",
    "    for i, label in enumerate(source_labels):\n",
    "        filename = './output/' + label + '/output-' + dataset + '-' + str(res) + '.h5'\n",
    "        file = h5py.File(filename, 'r')\n",
    "        tensor_len = len(file['tensor'])\n",
    "        picked_ids = random.sample(range(tensor_len), math.ceil(tensor_len * size))\n",
    "        if verbosity:\n",
    "            print(filename)\n",
    "            print('Picking ' + str(math.ceil(tensor_len * size)) + ' from ' + str(len(file['tensor'])) )\n",
    "        data = np.concatenate((data, [file['tensor'][index] for index in picked_ids]))\n",
    "        labels = np.concatenate((labels, np.full(len(picked_ids), i)))\n",
    "        file.close()\n",
    "        gc.collect()\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(data)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(labels)\n",
    "    return (data, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_16 (Flatten)         (None, 13824)             0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 48)                663600    \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 12)                588       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 20)                260       \n",
      "=================================================================\n",
      "Total params: 664,448\n",
      "Trainable params: 664,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f0fd0c46cc0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_model(res, num_classes, verbosity = 0):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(res, res, res)),\n",
    "        keras.layers.Dense(res*2, activation='relu'),\n",
    "        keras.layers.Dense(res/2, activation='sigmoid'),\n",
    "        keras.layers.Dropout(.2, input_shape=(2,)),\n",
    "        keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    if (verbosity == 1):\n",
    "        print(model.summary())\n",
    "    return model\n",
    "def prepare_data(data, num_classes):\n",
    "    return data\n",
    "model_type = 'dense'\n",
    "prepare_model(24, 20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 22, 22, 22, 24)    6504      \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 11, 11, 11, 24)    0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 31944)             0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 12)                383340    \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 10)                130       \n",
      "=================================================================\n",
      "Total params: 389,974\n",
      "Trainable params: 389,974\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f22c661a2b0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_model(res, num_classes, verbosity = 0):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv3D(\n",
    "                res, \n",
    "                kernel_size=(3), \n",
    "                activation='relu', \n",
    "                kernel_initializer='he_uniform', \n",
    "                data_format=\"channels_last\",\n",
    "                input_shape=(res, res, res, num_classes)\n",
    "            ),        \n",
    "        keras.layers.MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(res/2, activation='relu'),\n",
    "        keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    if (verbosity == 1):\n",
    "        print(model.summary())\n",
    "    return model\n",
    "def prepare_data(data, num_classes):\n",
    "    return keras.utils.to_categorical(data, num_classes)\n",
    "model_type = 'conv3d'\n",
    "prepare_model(24, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, training, training_labels, res, num_classes, verbosity = 0):\n",
    "    log_dir = \"logs/fit/\" + str(res) + '-' + str(num_classes) + '-' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    if verbosity == 1:\n",
    "        print(\"Log file \" + log_dir)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    validation_split = 0.1\n",
    "    epochs = 10 * num_classes\n",
    "    \n",
    "#    model.fit(\n",
    "#        keras.utils.to_categorical(training, num_clases), \n",
    "#        training_labels, \n",
    "#        epochs=epochs)\n",
    "    \n",
    "    model.fit(\n",
    "        prepare_data(training, num_classes), \n",
    "        training_labels, \n",
    "        epochs=epochs,\n",
    "        verbose=verbosity,\n",
    "        callbacks=[tensorboard_callback],\n",
    "        validation_split=validation_split\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix and Classification Report\n",
    "def print_confusion_matrix(test, test_labels, base_labels):\n",
    "    Y_pred = model.predict_generator(prepare_data(test, len(base_labels)), len(test))\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(test_labels, y_pred))\n",
    "    print('Classification Report')\n",
    "    print(classification_report(test_labels, y_pred, target_names=base_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_labels = ['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor', 'night_stand', 'sofa', 'table', 'toilet']\n",
    "all_labels = ['airplane', 'bathtub', 'bed', 'bench', 'bookshelf', 'bottle', 'bowl', 'car', 'chair', 'cone', \n",
    "                 'cup', 'curtain', 'desk', 'door', 'dresser', 'flower_pot', 'glass_box', 'guitar','keyboard', 'lamp',\n",
    "                 'laptop', 'mantel', 'monitor', 'night_stand', 'person', 'piano', 'plant', \n",
    "                 'radio', 'range_hood', 'sink', 'sofa', 'stairs', 'stool', 'table', 'tent', 'toilet', 'tv_stand', \n",
    "                 'vase', 'wardrobe', 'xbox']\n",
    "#num_classes = len(base_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_23 (Flatten)         (None, 13824)             0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 48)                663600    \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 12)                588       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 20)                260       \n",
      "=================================================================\n",
      "Total params: 664,448\n",
      "Trainable params: 664,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "144/144 - 1s - loss: 2.7847 - accuracy: 0.2030 - val_loss: 2.5597 - val_accuracy: 0.4473\n",
      "Epoch 2/200\n",
      "144/144 - 1s - loss: 2.5169 - accuracy: 0.3605 - val_loss: 2.3971 - val_accuracy: 0.5352\n",
      "Epoch 3/200\n",
      "144/144 - 1s - loss: 2.3819 - accuracy: 0.4474 - val_loss: 2.2926 - val_accuracy: 0.6113\n",
      "Epoch 4/200\n",
      "144/144 - 1s - loss: 2.2827 - accuracy: 0.5109 - val_loss: 2.2048 - val_accuracy: 0.6680\n",
      "Epoch 5/200\n",
      "144/144 - 1s - loss: 2.2095 - accuracy: 0.5393 - val_loss: 2.1264 - val_accuracy: 0.6934\n",
      "Epoch 6/200\n",
      "144/144 - 1s - loss: 2.1340 - accuracy: 0.5748 - val_loss: 2.0561 - val_accuracy: 0.7051\n",
      "Epoch 7/200\n",
      "144/144 - 1s - loss: 2.0726 - accuracy: 0.6015 - val_loss: 1.9925 - val_accuracy: 0.7148\n",
      "Epoch 8/200\n",
      "144/144 - 1s - loss: 2.0055 - accuracy: 0.6228 - val_loss: 1.9378 - val_accuracy: 0.7188\n",
      "Epoch 9/200\n",
      "144/144 - 1s - loss: 1.9520 - accuracy: 0.6378 - val_loss: 1.8842 - val_accuracy: 0.7285\n",
      "Epoch 10/200\n",
      "144/144 - 1s - loss: 1.8985 - accuracy: 0.6532 - val_loss: 1.8322 - val_accuracy: 0.7266\n",
      "Epoch 11/200\n",
      "144/144 - 1s - loss: 1.8484 - accuracy: 0.6556 - val_loss: 1.7859 - val_accuracy: 0.7266\n",
      "Epoch 12/200\n",
      "144/144 - 1s - loss: 1.7984 - accuracy: 0.6643 - val_loss: 1.7418 - val_accuracy: 0.7285\n",
      "Epoch 13/200\n",
      "144/144 - 1s - loss: 1.7654 - accuracy: 0.6654 - val_loss: 1.6969 - val_accuracy: 0.7266\n",
      "Epoch 14/200\n",
      "144/144 - 1s - loss: 1.7209 - accuracy: 0.6708 - val_loss: 1.6584 - val_accuracy: 0.7324\n",
      "Epoch 15/200\n",
      "144/144 - 1s - loss: 1.6751 - accuracy: 0.6836 - val_loss: 1.6178 - val_accuracy: 0.7363\n",
      "Epoch 16/200\n",
      "144/144 - 1s - loss: 1.6435 - accuracy: 0.6791 - val_loss: 1.5825 - val_accuracy: 0.7344\n",
      "Epoch 17/200\n",
      "144/144 - 1s - loss: 1.6095 - accuracy: 0.6801 - val_loss: 1.5488 - val_accuracy: 0.7441\n",
      "Epoch 18/200\n",
      "144/144 - 1s - loss: 1.5718 - accuracy: 0.6919 - val_loss: 1.5145 - val_accuracy: 0.7402\n",
      "Epoch 19/200\n",
      "144/144 - 1s - loss: 1.5396 - accuracy: 0.6906 - val_loss: 1.4835 - val_accuracy: 0.7441\n",
      "Epoch 20/200\n",
      "144/144 - 1s - loss: 1.5184 - accuracy: 0.6949 - val_loss: 1.4547 - val_accuracy: 0.7480\n",
      "Epoch 21/200\n",
      "144/144 - 1s - loss: 1.4882 - accuracy: 0.6951 - val_loss: 1.4271 - val_accuracy: 0.7520\n",
      "Epoch 22/200\n",
      "144/144 - 1s - loss: 1.4514 - accuracy: 0.6986 - val_loss: 1.4017 - val_accuracy: 0.7500\n",
      "Epoch 23/200\n",
      "144/144 - 1s - loss: 1.4237 - accuracy: 0.7043 - val_loss: 1.3776 - val_accuracy: 0.7500\n",
      "Epoch 24/200\n",
      "144/144 - 1s - loss: 1.4055 - accuracy: 0.7045 - val_loss: 1.3538 - val_accuracy: 0.7539\n",
      "Epoch 25/200\n",
      "144/144 - 1s - loss: 1.3841 - accuracy: 0.7051 - val_loss: 1.3290 - val_accuracy: 0.7539\n",
      "Epoch 26/200\n",
      "144/144 - 1s - loss: 1.3482 - accuracy: 0.7166 - val_loss: 1.3071 - val_accuracy: 0.7539\n",
      "Epoch 27/200\n",
      "144/144 - 1s - loss: 1.3379 - accuracy: 0.7095 - val_loss: 1.2865 - val_accuracy: 0.7578\n",
      "Epoch 28/200\n",
      "144/144 - 1s - loss: 1.3218 - accuracy: 0.7147 - val_loss: 1.2670 - val_accuracy: 0.7598\n",
      "Epoch 29/200\n",
      "144/144 - 1s - loss: 1.2886 - accuracy: 0.7251 - val_loss: 1.2498 - val_accuracy: 0.7598\n",
      "Epoch 30/200\n",
      "144/144 - 1s - loss: 1.2655 - accuracy: 0.7282 - val_loss: 1.2296 - val_accuracy: 0.7676\n",
      "Epoch 31/200\n",
      "144/144 - 1s - loss: 1.2441 - accuracy: 0.7364 - val_loss: 1.2118 - val_accuracy: 0.7734\n",
      "Epoch 32/200\n",
      "144/144 - 1s - loss: 1.2335 - accuracy: 0.7423 - val_loss: 1.1954 - val_accuracy: 0.7754\n",
      "Epoch 33/200\n",
      "144/144 - 1s - loss: 1.2124 - accuracy: 0.7366 - val_loss: 1.1787 - val_accuracy: 0.7754\n",
      "Epoch 34/200\n",
      "144/144 - 1s - loss: 1.1923 - accuracy: 0.7395 - val_loss: 1.1622 - val_accuracy: 0.7754\n",
      "Epoch 35/200\n",
      "144/144 - 1s - loss: 1.1735 - accuracy: 0.7462 - val_loss: 1.1460 - val_accuracy: 0.7715\n",
      "Epoch 36/200\n",
      "144/144 - 1s - loss: 1.1621 - accuracy: 0.7514 - val_loss: 1.1314 - val_accuracy: 0.7734\n",
      "Epoch 37/200\n",
      "144/144 - 1s - loss: 1.1405 - accuracy: 0.7497 - val_loss: 1.1160 - val_accuracy: 0.7754\n",
      "Epoch 38/200\n",
      "144/144 - 1s - loss: 1.1166 - accuracy: 0.7623 - val_loss: 1.1019 - val_accuracy: 0.7773\n",
      "Epoch 39/200\n",
      "144/144 - 1s - loss: 1.1148 - accuracy: 0.7621 - val_loss: 1.0895 - val_accuracy: 0.7852\n",
      "Epoch 40/200\n",
      "144/144 - 1s - loss: 1.1083 - accuracy: 0.7581 - val_loss: 1.0753 - val_accuracy: 0.7852\n",
      "Epoch 41/200\n",
      "144/144 - 1s - loss: 1.0877 - accuracy: 0.7655 - val_loss: 1.0606 - val_accuracy: 0.7832\n",
      "Epoch 42/200\n",
      "144/144 - 1s - loss: 1.0639 - accuracy: 0.7692 - val_loss: 1.0488 - val_accuracy: 0.7891\n",
      "Epoch 43/200\n",
      "144/144 - 1s - loss: 1.0410 - accuracy: 0.7749 - val_loss: 1.0342 - val_accuracy: 0.7891\n",
      "Epoch 44/200\n",
      "144/144 - 1s - loss: 1.0408 - accuracy: 0.7771 - val_loss: 1.0229 - val_accuracy: 0.7891\n",
      "Epoch 45/200\n",
      "144/144 - 1s - loss: 1.0288 - accuracy: 0.7742 - val_loss: 1.0118 - val_accuracy: 0.7949\n",
      "Epoch 46/200\n",
      "144/144 - 1s - loss: 1.0085 - accuracy: 0.7799 - val_loss: 1.0036 - val_accuracy: 0.8027\n",
      "Epoch 47/200\n",
      "144/144 - 1s - loss: 1.0006 - accuracy: 0.7834 - val_loss: 0.9905 - val_accuracy: 0.8066\n",
      "Epoch 48/200\n",
      "144/144 - 1s - loss: 0.9812 - accuracy: 0.7860 - val_loss: 0.9771 - val_accuracy: 0.8047\n",
      "Epoch 49/200\n",
      "144/144 - 1s - loss: 0.9692 - accuracy: 0.7912 - val_loss: 0.9694 - val_accuracy: 0.8086\n",
      "Epoch 50/200\n",
      "144/144 - 1s - loss: 0.9581 - accuracy: 0.7938 - val_loss: 0.9577 - val_accuracy: 0.8105\n",
      "Epoch 51/200\n",
      "144/144 - 1s - loss: 0.9535 - accuracy: 0.7925 - val_loss: 0.9458 - val_accuracy: 0.8125\n",
      "Epoch 52/200\n",
      "144/144 - 1s - loss: 0.9409 - accuracy: 0.7977 - val_loss: 0.9363 - val_accuracy: 0.8125\n",
      "Epoch 53/200\n",
      "144/144 - 1s - loss: 0.9200 - accuracy: 0.7990 - val_loss: 0.9270 - val_accuracy: 0.8125\n",
      "Epoch 54/200\n",
      "144/144 - 1s - loss: 0.9064 - accuracy: 0.8077 - val_loss: 0.9159 - val_accuracy: 0.8223\n",
      "Epoch 55/200\n",
      "144/144 - 1s - loss: 0.9112 - accuracy: 0.8020 - val_loss: 0.9095 - val_accuracy: 0.8203\n",
      "Epoch 56/200\n",
      "144/144 - 1s - loss: 0.8947 - accuracy: 0.8055 - val_loss: 0.9012 - val_accuracy: 0.8242\n",
      "Epoch 57/200\n",
      "144/144 - 1s - loss: 0.8807 - accuracy: 0.8112 - val_loss: 0.8926 - val_accuracy: 0.8281\n",
      "Epoch 58/200\n",
      "144/144 - 1s - loss: 0.8665 - accuracy: 0.8142 - val_loss: 0.8802 - val_accuracy: 0.8320\n",
      "Epoch 59/200\n",
      "144/144 - 1s - loss: 0.8522 - accuracy: 0.8203 - val_loss: 0.8730 - val_accuracy: 0.8320\n",
      "Epoch 60/200\n",
      "144/144 - 1s - loss: 0.8486 - accuracy: 0.8103 - val_loss: 0.8658 - val_accuracy: 0.8301\n",
      "Epoch 61/200\n",
      "144/144 - 1s - loss: 0.8393 - accuracy: 0.8188 - val_loss: 0.8587 - val_accuracy: 0.8340\n",
      "Epoch 62/200\n",
      "144/144 - 1s - loss: 0.8356 - accuracy: 0.8227 - val_loss: 0.8539 - val_accuracy: 0.8320\n",
      "Epoch 63/200\n",
      "144/144 - 1s - loss: 0.8361 - accuracy: 0.8138 - val_loss: 0.8450 - val_accuracy: 0.8320\n",
      "Epoch 64/200\n",
      "144/144 - 1s - loss: 0.8037 - accuracy: 0.8225 - val_loss: 0.8354 - val_accuracy: 0.8340\n",
      "Epoch 65/200\n",
      "144/144 - 1s - loss: 0.8069 - accuracy: 0.8249 - val_loss: 0.8288 - val_accuracy: 0.8320\n",
      "Epoch 66/200\n",
      "144/144 - 1s - loss: 0.7997 - accuracy: 0.8253 - val_loss: 0.8235 - val_accuracy: 0.8340\n",
      "Epoch 67/200\n",
      "144/144 - 1s - loss: 0.7828 - accuracy: 0.8301 - val_loss: 0.8171 - val_accuracy: 0.8301\n",
      "Epoch 68/200\n",
      "144/144 - 1s - loss: 0.7891 - accuracy: 0.8272 - val_loss: 0.8107 - val_accuracy: 0.8379\n",
      "Epoch 69/200\n",
      "144/144 - 1s - loss: 0.7712 - accuracy: 0.8290 - val_loss: 0.8047 - val_accuracy: 0.8320\n",
      "Epoch 70/200\n",
      "144/144 - 1s - loss: 0.7709 - accuracy: 0.8344 - val_loss: 0.7953 - val_accuracy: 0.8418\n",
      "Epoch 71/200\n",
      "144/144 - 1s - loss: 0.7471 - accuracy: 0.8372 - val_loss: 0.7910 - val_accuracy: 0.8418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/200\n",
      "144/144 - 1s - loss: 0.7502 - accuracy: 0.8381 - val_loss: 0.7826 - val_accuracy: 0.8418\n",
      "Epoch 73/200\n",
      "144/144 - 1s - loss: 0.7357 - accuracy: 0.8477 - val_loss: 0.7797 - val_accuracy: 0.8418\n",
      "Epoch 74/200\n",
      "144/144 - 1s - loss: 0.7247 - accuracy: 0.8403 - val_loss: 0.7760 - val_accuracy: 0.8359\n",
      "Epoch 75/200\n",
      "144/144 - 1s - loss: 0.7310 - accuracy: 0.8362 - val_loss: 0.7701 - val_accuracy: 0.8398\n",
      "Epoch 76/200\n",
      "144/144 - 1s - loss: 0.7167 - accuracy: 0.8416 - val_loss: 0.7663 - val_accuracy: 0.8398\n",
      "Epoch 77/200\n",
      "144/144 - 1s - loss: 0.7009 - accuracy: 0.8468 - val_loss: 0.7590 - val_accuracy: 0.8418\n",
      "Epoch 78/200\n",
      "144/144 - 1s - loss: 0.6874 - accuracy: 0.8531 - val_loss: 0.7530 - val_accuracy: 0.8398\n",
      "Epoch 79/200\n",
      "144/144 - 1s - loss: 0.6982 - accuracy: 0.8462 - val_loss: 0.7489 - val_accuracy: 0.8457\n",
      "Epoch 80/200\n",
      "144/144 - 1s - loss: 0.6853 - accuracy: 0.8529 - val_loss: 0.7489 - val_accuracy: 0.8438\n",
      "Epoch 81/200\n",
      "144/144 - 1s - loss: 0.6825 - accuracy: 0.8446 - val_loss: 0.7443 - val_accuracy: 0.8418\n",
      "Epoch 82/200\n",
      "144/144 - 1s - loss: 0.6748 - accuracy: 0.8496 - val_loss: 0.7392 - val_accuracy: 0.8418\n",
      "Epoch 83/200\n",
      "144/144 - 1s - loss: 0.6597 - accuracy: 0.8585 - val_loss: 0.7351 - val_accuracy: 0.8438\n",
      "Epoch 84/200\n",
      "144/144 - 1s - loss: 0.6658 - accuracy: 0.8488 - val_loss: 0.7333 - val_accuracy: 0.8438\n",
      "Epoch 85/200\n",
      "144/144 - 1s - loss: 0.6581 - accuracy: 0.8525 - val_loss: 0.7321 - val_accuracy: 0.8418\n",
      "Epoch 86/200\n",
      "144/144 - 1s - loss: 0.6483 - accuracy: 0.8564 - val_loss: 0.7233 - val_accuracy: 0.8457\n",
      "Epoch 87/200\n",
      "144/144 - 1s - loss: 0.6471 - accuracy: 0.8588 - val_loss: 0.7190 - val_accuracy: 0.8418\n",
      "Epoch 88/200\n",
      "144/144 - 1s - loss: 0.6374 - accuracy: 0.8572 - val_loss: 0.7125 - val_accuracy: 0.8438\n",
      "Epoch 89/200\n",
      "144/144 - 1s - loss: 0.6321 - accuracy: 0.8568 - val_loss: 0.7122 - val_accuracy: 0.8359\n",
      "Epoch 90/200\n",
      "144/144 - 1s - loss: 0.6403 - accuracy: 0.8518 - val_loss: 0.7028 - val_accuracy: 0.8457\n",
      "Epoch 91/200\n",
      "144/144 - 1s - loss: 0.6187 - accuracy: 0.8609 - val_loss: 0.7024 - val_accuracy: 0.8418\n",
      "Epoch 92/200\n",
      "144/144 - 1s - loss: 0.6223 - accuracy: 0.8583 - val_loss: 0.7020 - val_accuracy: 0.8418\n",
      "Epoch 93/200\n",
      "144/144 - 1s - loss: 0.6121 - accuracy: 0.8590 - val_loss: 0.6972 - val_accuracy: 0.8398\n",
      "Epoch 94/200\n",
      "144/144 - 1s - loss: 0.6071 - accuracy: 0.8598 - val_loss: 0.6963 - val_accuracy: 0.8398\n",
      "Epoch 95/200\n",
      "144/144 - 1s - loss: 0.5939 - accuracy: 0.8644 - val_loss: 0.6914 - val_accuracy: 0.8398\n",
      "Epoch 96/200\n",
      "144/144 - 1s - loss: 0.5977 - accuracy: 0.8618 - val_loss: 0.6868 - val_accuracy: 0.8438\n",
      "Epoch 97/200\n",
      "144/144 - 1s - loss: 0.5945 - accuracy: 0.8646 - val_loss: 0.6855 - val_accuracy: 0.8438\n",
      "Epoch 98/200\n",
      "144/144 - 1s - loss: 0.5762 - accuracy: 0.8679 - val_loss: 0.6825 - val_accuracy: 0.8496\n",
      "Epoch 99/200\n",
      "144/144 - 1s - loss: 0.5785 - accuracy: 0.8642 - val_loss: 0.6828 - val_accuracy: 0.8438\n",
      "Epoch 100/200\n",
      "144/144 - 1s - loss: 0.5760 - accuracy: 0.8633 - val_loss: 0.6798 - val_accuracy: 0.8438\n",
      "Epoch 101/200\n",
      "144/144 - 1s - loss: 0.5742 - accuracy: 0.8653 - val_loss: 0.6748 - val_accuracy: 0.8438\n",
      "Epoch 102/200\n",
      "144/144 - 1s - loss: 0.5585 - accuracy: 0.8709 - val_loss: 0.6715 - val_accuracy: 0.8438\n",
      "Epoch 103/200\n",
      "144/144 - 1s - loss: 0.5641 - accuracy: 0.8661 - val_loss: 0.6710 - val_accuracy: 0.8418\n",
      "Epoch 104/200\n",
      "144/144 - 1s - loss: 0.5603 - accuracy: 0.8696 - val_loss: 0.6666 - val_accuracy: 0.8438\n",
      "Epoch 105/200\n",
      "144/144 - 1s - loss: 0.5499 - accuracy: 0.8672 - val_loss: 0.6626 - val_accuracy: 0.8496\n",
      "Epoch 106/200\n",
      "144/144 - 1s - loss: 0.5467 - accuracy: 0.8731 - val_loss: 0.6589 - val_accuracy: 0.8457\n",
      "Epoch 107/200\n",
      "144/144 - 1s - loss: 0.5473 - accuracy: 0.8688 - val_loss: 0.6577 - val_accuracy: 0.8457\n",
      "Epoch 108/200\n",
      "144/144 - 1s - loss: 0.5506 - accuracy: 0.8746 - val_loss: 0.6549 - val_accuracy: 0.8457\n",
      "Epoch 109/200\n",
      "144/144 - 1s - loss: 0.5310 - accuracy: 0.8751 - val_loss: 0.6598 - val_accuracy: 0.8477\n",
      "Epoch 110/200\n",
      "144/144 - 1s - loss: 0.5444 - accuracy: 0.8731 - val_loss: 0.6547 - val_accuracy: 0.8477\n",
      "Epoch 111/200\n",
      "144/144 - 1s - loss: 0.5341 - accuracy: 0.8755 - val_loss: 0.6541 - val_accuracy: 0.8477\n",
      "Epoch 112/200\n",
      "144/144 - 1s - loss: 0.5273 - accuracy: 0.8785 - val_loss: 0.6541 - val_accuracy: 0.8457\n",
      "Epoch 113/200\n",
      "144/144 - 1s - loss: 0.5306 - accuracy: 0.8753 - val_loss: 0.6510 - val_accuracy: 0.8457\n",
      "Epoch 114/200\n",
      "144/144 - 1s - loss: 0.5198 - accuracy: 0.8751 - val_loss: 0.6457 - val_accuracy: 0.8477\n",
      "Epoch 115/200\n",
      "144/144 - 1s - loss: 0.5159 - accuracy: 0.8794 - val_loss: 0.6491 - val_accuracy: 0.8438\n",
      "Epoch 116/200\n",
      "144/144 - 1s - loss: 0.5202 - accuracy: 0.8783 - val_loss: 0.6436 - val_accuracy: 0.8438\n",
      "Epoch 117/200\n",
      "144/144 - 1s - loss: 0.5132 - accuracy: 0.8818 - val_loss: 0.6417 - val_accuracy: 0.8516\n",
      "Epoch 118/200\n",
      "144/144 - 1s - loss: 0.5138 - accuracy: 0.8774 - val_loss: 0.6441 - val_accuracy: 0.8418\n",
      "Epoch 119/200\n",
      "144/144 - 1s - loss: 0.5084 - accuracy: 0.8801 - val_loss: 0.6425 - val_accuracy: 0.8457\n",
      "Epoch 120/200\n",
      "144/144 - 1s - loss: 0.4966 - accuracy: 0.8848 - val_loss: 0.6371 - val_accuracy: 0.8477\n",
      "Epoch 121/200\n",
      "144/144 - 1s - loss: 0.4970 - accuracy: 0.8822 - val_loss: 0.6330 - val_accuracy: 0.8516\n",
      "Epoch 122/200\n",
      "144/144 - 1s - loss: 0.4960 - accuracy: 0.8805 - val_loss: 0.6359 - val_accuracy: 0.8438\n",
      "Epoch 123/200\n",
      "144/144 - 1s - loss: 0.4962 - accuracy: 0.8803 - val_loss: 0.6362 - val_accuracy: 0.8457\n",
      "Epoch 124/200\n",
      "144/144 - 1s - loss: 0.4934 - accuracy: 0.8829 - val_loss: 0.6337 - val_accuracy: 0.8516\n",
      "Epoch 125/200\n",
      "144/144 - 1s - loss: 0.4794 - accuracy: 0.8879 - val_loss: 0.6307 - val_accuracy: 0.8496\n",
      "Epoch 126/200\n",
      "144/144 - 1s - loss: 0.4903 - accuracy: 0.8820 - val_loss: 0.6275 - val_accuracy: 0.8477\n",
      "Epoch 127/200\n",
      "144/144 - 1s - loss: 0.4785 - accuracy: 0.8907 - val_loss: 0.6293 - val_accuracy: 0.8457\n",
      "Epoch 128/200\n",
      "144/144 - 1s - loss: 0.4749 - accuracy: 0.8870 - val_loss: 0.6259 - val_accuracy: 0.8496\n",
      "Epoch 129/200\n",
      "144/144 - 1s - loss: 0.4724 - accuracy: 0.8859 - val_loss: 0.6232 - val_accuracy: 0.8496\n",
      "Epoch 130/200\n",
      "144/144 - 1s - loss: 0.4816 - accuracy: 0.8803 - val_loss: 0.6231 - val_accuracy: 0.8535\n",
      "Epoch 131/200\n",
      "144/144 - 1s - loss: 0.4731 - accuracy: 0.8840 - val_loss: 0.6276 - val_accuracy: 0.8535\n",
      "Epoch 132/200\n",
      "144/144 - 1s - loss: 0.4742 - accuracy: 0.8820 - val_loss: 0.6174 - val_accuracy: 0.8555\n",
      "Epoch 133/200\n",
      "144/144 - 1s - loss: 0.4691 - accuracy: 0.8892 - val_loss: 0.6227 - val_accuracy: 0.8516\n",
      "Epoch 134/200\n",
      "144/144 - 1s - loss: 0.4569 - accuracy: 0.8887 - val_loss: 0.6185 - val_accuracy: 0.8555\n",
      "Epoch 135/200\n",
      "144/144 - 1s - loss: 0.4629 - accuracy: 0.8894 - val_loss: 0.6127 - val_accuracy: 0.8574\n",
      "Epoch 136/200\n",
      "144/144 - 1s - loss: 0.4624 - accuracy: 0.8855 - val_loss: 0.6192 - val_accuracy: 0.8516\n",
      "Epoch 137/200\n",
      "144/144 - 1s - loss: 0.4521 - accuracy: 0.8944 - val_loss: 0.6157 - val_accuracy: 0.8555\n",
      "Epoch 138/200\n",
      "144/144 - 1s - loss: 0.4630 - accuracy: 0.8798 - val_loss: 0.6162 - val_accuracy: 0.8535\n",
      "Epoch 139/200\n",
      "144/144 - 1s - loss: 0.4467 - accuracy: 0.8933 - val_loss: 0.6179 - val_accuracy: 0.8574\n",
      "Epoch 140/200\n",
      "144/144 - 1s - loss: 0.4440 - accuracy: 0.8909 - val_loss: 0.6152 - val_accuracy: 0.8516\n",
      "Epoch 141/200\n",
      "144/144 - 1s - loss: 0.4403 - accuracy: 0.8968 - val_loss: 0.6115 - val_accuracy: 0.8496\n",
      "Epoch 142/200\n",
      "144/144 - 1s - loss: 0.4433 - accuracy: 0.8898 - val_loss: 0.6091 - val_accuracy: 0.8555\n",
      "Epoch 143/200\n",
      "144/144 - 1s - loss: 0.4433 - accuracy: 0.8887 - val_loss: 0.6113 - val_accuracy: 0.8496\n",
      "Epoch 144/200\n",
      "144/144 - 1s - loss: 0.4440 - accuracy: 0.8903 - val_loss: 0.6181 - val_accuracy: 0.8496\n",
      "Epoch 145/200\n",
      "144/144 - 1s - loss: 0.4308 - accuracy: 0.8914 - val_loss: 0.6121 - val_accuracy: 0.8496\n",
      "Epoch 146/200\n",
      "144/144 - 1s - loss: 0.4379 - accuracy: 0.8850 - val_loss: 0.6112 - val_accuracy: 0.8516\n",
      "Epoch 147/200\n",
      "144/144 - 1s - loss: 0.4356 - accuracy: 0.8874 - val_loss: 0.6124 - val_accuracy: 0.8496\n",
      "Epoch 148/200\n",
      "144/144 - 1s - loss: 0.4283 - accuracy: 0.8950 - val_loss: 0.6061 - val_accuracy: 0.8438\n",
      "Epoch 149/200\n",
      "144/144 - 1s - loss: 0.4229 - accuracy: 0.8940 - val_loss: 0.6029 - val_accuracy: 0.8496\n",
      "Epoch 150/200\n",
      "144/144 - 1s - loss: 0.4270 - accuracy: 0.8985 - val_loss: 0.6060 - val_accuracy: 0.8516\n",
      "Epoch 151/200\n",
      "144/144 - 1s - loss: 0.4386 - accuracy: 0.8872 - val_loss: 0.6049 - val_accuracy: 0.8477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/200\n",
      "144/144 - 1s - loss: 0.4166 - accuracy: 0.8953 - val_loss: 0.6020 - val_accuracy: 0.8496\n",
      "Epoch 153/200\n",
      "144/144 - 1s - loss: 0.4193 - accuracy: 0.8948 - val_loss: 0.6062 - val_accuracy: 0.8438\n",
      "Epoch 154/200\n",
      "144/144 - 1s - loss: 0.4241 - accuracy: 0.8957 - val_loss: 0.6043 - val_accuracy: 0.8496\n",
      "Epoch 155/200\n",
      "144/144 - 1s - loss: 0.4175 - accuracy: 0.8927 - val_loss: 0.6030 - val_accuracy: 0.8457\n",
      "Epoch 156/200\n",
      "144/144 - 1s - loss: 0.4162 - accuracy: 0.8972 - val_loss: 0.6004 - val_accuracy: 0.8535\n",
      "Epoch 157/200\n",
      "144/144 - 1s - loss: 0.4095 - accuracy: 0.8963 - val_loss: 0.6019 - val_accuracy: 0.8555\n",
      "Epoch 158/200\n",
      "144/144 - 1s - loss: 0.4182 - accuracy: 0.8953 - val_loss: 0.6005 - val_accuracy: 0.8574\n",
      "Epoch 159/200\n",
      "144/144 - 1s - loss: 0.4050 - accuracy: 0.9016 - val_loss: 0.5984 - val_accuracy: 0.8535\n",
      "Epoch 160/200\n",
      "144/144 - 1s - loss: 0.4120 - accuracy: 0.8992 - val_loss: 0.6038 - val_accuracy: 0.8496\n",
      "Epoch 161/200\n",
      "144/144 - 1s - loss: 0.4139 - accuracy: 0.8933 - val_loss: 0.5955 - val_accuracy: 0.8535\n",
      "Epoch 162/200\n",
      "144/144 - 1s - loss: 0.4064 - accuracy: 0.8950 - val_loss: 0.6014 - val_accuracy: 0.8516\n",
      "Epoch 163/200\n",
      "144/144 - 1s - loss: 0.4094 - accuracy: 0.8922 - val_loss: 0.6031 - val_accuracy: 0.8496\n",
      "Epoch 164/200\n",
      "144/144 - 1s - loss: 0.3993 - accuracy: 0.8979 - val_loss: 0.5992 - val_accuracy: 0.8535\n",
      "Epoch 165/200\n",
      "144/144 - 1s - loss: 0.4138 - accuracy: 0.8929 - val_loss: 0.6034 - val_accuracy: 0.8555\n",
      "Epoch 166/200\n",
      "144/144 - 1s - loss: 0.3978 - accuracy: 0.8966 - val_loss: 0.6021 - val_accuracy: 0.8535\n",
      "Epoch 167/200\n",
      "144/144 - 1s - loss: 0.3923 - accuracy: 0.9022 - val_loss: 0.6062 - val_accuracy: 0.8516\n",
      "Epoch 168/200\n",
      "144/144 - 1s - loss: 0.3877 - accuracy: 0.8985 - val_loss: 0.6064 - val_accuracy: 0.8535\n",
      "Epoch 169/200\n",
      "144/144 - 1s - loss: 0.3843 - accuracy: 0.9037 - val_loss: 0.5954 - val_accuracy: 0.8555\n",
      "Epoch 170/200\n",
      "144/144 - 1s - loss: 0.3959 - accuracy: 0.9024 - val_loss: 0.5952 - val_accuracy: 0.8516\n",
      "Epoch 171/200\n",
      "144/144 - 1s - loss: 0.4023 - accuracy: 0.8937 - val_loss: 0.5996 - val_accuracy: 0.8574\n",
      "Epoch 172/200\n",
      "144/144 - 1s - loss: 0.3827 - accuracy: 0.9066 - val_loss: 0.5962 - val_accuracy: 0.8555\n",
      "Epoch 173/200\n",
      "144/144 - 1s - loss: 0.3984 - accuracy: 0.8898 - val_loss: 0.6007 - val_accuracy: 0.8496\n",
      "Epoch 174/200\n",
      "144/144 - 1s - loss: 0.3875 - accuracy: 0.9003 - val_loss: 0.6011 - val_accuracy: 0.8516\n",
      "Epoch 175/200\n",
      "144/144 - 1s - loss: 0.3886 - accuracy: 0.8987 - val_loss: 0.6027 - val_accuracy: 0.8516\n",
      "Epoch 176/200\n",
      "144/144 - 1s - loss: 0.3869 - accuracy: 0.8994 - val_loss: 0.5994 - val_accuracy: 0.8574\n",
      "Epoch 177/200\n",
      "144/144 - 1s - loss: 0.3851 - accuracy: 0.8981 - val_loss: 0.5958 - val_accuracy: 0.8574\n",
      "Epoch 178/200\n",
      "144/144 - 1s - loss: 0.3919 - accuracy: 0.8977 - val_loss: 0.5961 - val_accuracy: 0.8555\n",
      "Epoch 179/200\n",
      "144/144 - 1s - loss: 0.3792 - accuracy: 0.8977 - val_loss: 0.6055 - val_accuracy: 0.8516\n",
      "Epoch 180/200\n",
      "144/144 - 1s - loss: 0.3846 - accuracy: 0.8979 - val_loss: 0.6028 - val_accuracy: 0.8535\n",
      "Epoch 181/200\n",
      "144/144 - 1s - loss: 0.3827 - accuracy: 0.8977 - val_loss: 0.6049 - val_accuracy: 0.8555\n",
      "Epoch 182/200\n",
      "144/144 - 1s - loss: 0.3665 - accuracy: 0.9040 - val_loss: 0.5956 - val_accuracy: 0.8574\n",
      "Epoch 183/200\n",
      "144/144 - 1s - loss: 0.3750 - accuracy: 0.9016 - val_loss: 0.5913 - val_accuracy: 0.8535\n",
      "Epoch 184/200\n",
      "144/144 - 1s - loss: 0.3740 - accuracy: 0.9040 - val_loss: 0.5951 - val_accuracy: 0.8555\n",
      "Epoch 185/200\n",
      "144/144 - 1s - loss: 0.3786 - accuracy: 0.8981 - val_loss: 0.5998 - val_accuracy: 0.8574\n",
      "Epoch 186/200\n",
      "144/144 - 1s - loss: 0.3838 - accuracy: 0.8972 - val_loss: 0.6008 - val_accuracy: 0.8594\n",
      "Epoch 187/200\n",
      "144/144 - 1s - loss: 0.3832 - accuracy: 0.8953 - val_loss: 0.5969 - val_accuracy: 0.8574\n",
      "Epoch 188/200\n",
      "144/144 - 1s - loss: 0.3656 - accuracy: 0.9053 - val_loss: 0.5943 - val_accuracy: 0.8535\n",
      "Epoch 189/200\n",
      "144/144 - 1s - loss: 0.3818 - accuracy: 0.9020 - val_loss: 0.5900 - val_accuracy: 0.8594\n",
      "Epoch 190/200\n",
      "144/144 - 1s - loss: 0.3694 - accuracy: 0.9037 - val_loss: 0.5934 - val_accuracy: 0.8574\n",
      "Epoch 191/200\n",
      "144/144 - 1s - loss: 0.3668 - accuracy: 0.9007 - val_loss: 0.5947 - val_accuracy: 0.8574\n",
      "Epoch 192/200\n",
      "144/144 - 1s - loss: 0.3619 - accuracy: 0.9024 - val_loss: 0.5914 - val_accuracy: 0.8633\n",
      "Epoch 193/200\n",
      "144/144 - 1s - loss: 0.3589 - accuracy: 0.9072 - val_loss: 0.5947 - val_accuracy: 0.8574\n",
      "Epoch 194/200\n",
      "144/144 - 1s - loss: 0.3621 - accuracy: 0.9016 - val_loss: 0.5973 - val_accuracy: 0.8613\n",
      "Epoch 195/200\n",
      "144/144 - 1s - loss: 0.3682 - accuracy: 0.8992 - val_loss: 0.5936 - val_accuracy: 0.8594\n",
      "Epoch 196/200\n",
      "144/144 - 1s - loss: 0.3646 - accuracy: 0.8961 - val_loss: 0.5924 - val_accuracy: 0.8613\n",
      "Epoch 197/200\n",
      "144/144 - 1s - loss: 0.3650 - accuracy: 0.8998 - val_loss: 0.5945 - val_accuracy: 0.8594\n",
      "Epoch 198/200\n",
      "144/144 - 1s - loss: 0.3488 - accuracy: 0.9057 - val_loss: 0.6011 - val_accuracy: 0.8574\n",
      "Epoch 199/200\n",
      "144/144 - 1s - loss: 0.3586 - accuracy: 0.9042 - val_loss: 0.6099 - val_accuracy: 0.8555\n",
      "Epoch 200/200\n",
      "144/144 - 1s - loss: 0.3636 - accuracy: 0.9057 - val_loss: 0.6050 - val_accuracy: 0.8613\n",
      "38/38 - 0s - loss: 0.7266 - accuracy: 0.8203\n",
      "\n",
      "Test accuracy for 20 classes width res 24: 0.820299506187439\n",
      "Confusion Matrix\n",
      "[[91  0  2  0  0  0  1  0  0  0  3  0  0  0  0  0  0  1  2  0]\n",
      " [ 0 35  7  0  0  0  1  1  0  0  1  0  1  0  0  1  2  0  1  0]\n",
      " [ 0  2 96  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 1  0  1 12  0  0  0  0  1  0  0  0  0  0  2  1  1  0  1  0]\n",
      " [ 0  0  0  0 88  4  0  0  1  0  0  4  0  2  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  2 89  0  0  1  2  4  0  0  0  1  1  0  0  0  0]\n",
      " [ 0  0  2  2  0  0  7  0  1  0  2  0  0  0  0  1  5  0  0  0]\n",
      " [ 2  0  7  1  0  2  0 79  2  0  0  0  0  0  0  2  1  0  2  2]\n",
      " [ 1  0  1  0  0  1  1  0 91  0  1  0  0  0  1  2  0  0  0  1]\n",
      " [ 0  0  2  1  0  1  0  0  0 14  0  1  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  1  0  0  2  1  0  1  0  3  0  0  0  0 10  1  0  0  1]\n",
      " [ 0  0  0  1  0  0  0  0  1  0  0 12  0  6  0  0  0  0  0  0]\n",
      " [ 1  1  2  0  1  0  0  2  0  0  0  0 67  0  5  1  1  3  0  2]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  4  0 15  0  1  0  0  0  0]\n",
      " [ 1  0  0  1  0  1  0  0  0  0  0  0  5  0 77  1  0  0  0  0]\n",
      " [ 0  0  1  0  3  5  0  0  0  1  0  0  0  0  0  7  1  1  0  1]\n",
      " [ 0  0  1  0  2  0  0  0  0  0  0  0  0  0  1  0 96  0  0  0]\n",
      " [ 2  0  5  0  0  0  0  0  1  0  1  1  0  0  0  0  0 81  9  0]\n",
      " [ 0  0  1  0  0  0  0  0  1  0  1  0  0  0  0  0  0  0 17  0]\n",
      " [ 0  0  0  0  2  6  0  0  0  0  0  0  0  0  0  3  0  0  0  9]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.92      0.91      0.91       100\n",
      "     bathtub       0.92      0.70      0.80        50\n",
      "         bed       0.74      0.96      0.84       100\n",
      "       bench       0.67      0.60      0.63        20\n",
      "   bookshelf       0.90      0.88      0.89       100\n",
      "      bottle       0.80      0.89      0.84       100\n",
      "        bowl       0.58      0.35      0.44        20\n",
      "         car       0.96      0.79      0.87       100\n",
      "       chair       0.90      0.91      0.91       100\n",
      "        cone       0.82      0.70      0.76        20\n",
      "         cup       0.19      0.15      0.17        20\n",
      "     curtain       0.55      0.60      0.57        20\n",
      "        desk       0.92      0.78      0.84        86\n",
      "        door       0.65      0.75      0.70        20\n",
      "     dresser       0.89      0.90      0.89        86\n",
      "  flower_pot       0.23      0.35      0.27        20\n",
      "   glass_box       0.86      0.96      0.91       100\n",
      "      guitar       0.94      0.81      0.87       100\n",
      "    keyboard       0.53      0.85      0.65        20\n",
      "        lamp       0.56      0.45      0.50        20\n",
      "\n",
      "    accuracy                           0.82      1202\n",
      "   macro avg       0.73      0.71      0.71      1202\n",
      "weighted avg       0.83      0.82      0.82      1202\n",
      "\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_24 (Flatten)         (None, 13824)             0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 48)                663600    \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 12)                588       \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 30)                390       \n",
      "=================================================================\n",
      "Total params: 664,578\n",
      "Trainable params: 664,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "201/201 - 1s - loss: 3.2588 - accuracy: 0.1357 - val_loss: 3.0880 - val_accuracy: 0.2879\n",
      "Epoch 2/300\n",
      "201/201 - 1s - loss: 3.0232 - accuracy: 0.2654 - val_loss: 2.9428 - val_accuracy: 0.3610\n",
      "Epoch 3/300\n",
      "201/201 - 1s - loss: 2.8987 - accuracy: 0.3238 - val_loss: 2.8404 - val_accuracy: 0.4073\n",
      "Epoch 4/300\n",
      "201/201 - 1s - loss: 2.8067 - accuracy: 0.3626 - val_loss: 2.7533 - val_accuracy: 0.4494\n",
      "Epoch 5/300\n",
      "201/201 - 1s - loss: 2.7251 - accuracy: 0.4193 - val_loss: 2.6758 - val_accuracy: 0.5098\n",
      "Epoch 6/300\n",
      "201/201 - 1s - loss: 2.6472 - accuracy: 0.4532 - val_loss: 2.6038 - val_accuracy: 0.5379\n",
      "Epoch 7/300\n",
      "201/201 - 1s - loss: 2.5675 - accuracy: 0.4811 - val_loss: 2.5345 - val_accuracy: 0.5435\n",
      "Epoch 8/300\n",
      "201/201 - 1s - loss: 2.4992 - accuracy: 0.4934 - val_loss: 2.4692 - val_accuracy: 0.5506\n",
      "Epoch 9/300\n",
      "201/201 - 1s - loss: 2.4365 - accuracy: 0.4998 - val_loss: 2.4063 - val_accuracy: 0.5548\n",
      "Epoch 10/300\n",
      "201/201 - 1s - loss: 2.3824 - accuracy: 0.5045 - val_loss: 2.3503 - val_accuracy: 0.5520\n",
      "Epoch 11/300\n",
      "201/201 - 1s - loss: 2.3235 - accuracy: 0.5145 - val_loss: 2.2961 - val_accuracy: 0.5506\n",
      "Epoch 12/300\n",
      "201/201 - 1s - loss: 2.2624 - accuracy: 0.5223 - val_loss: 2.2477 - val_accuracy: 0.5590\n",
      "Epoch 13/300\n",
      "201/201 - 1s - loss: 2.2193 - accuracy: 0.5272 - val_loss: 2.2036 - val_accuracy: 0.5618\n",
      "Epoch 14/300\n",
      "201/201 - 1s - loss: 2.1728 - accuracy: 0.5292 - val_loss: 2.1586 - val_accuracy: 0.5632\n",
      "Epoch 15/300\n",
      "201/201 - 1s - loss: 2.1395 - accuracy: 0.5336 - val_loss: 2.1202 - val_accuracy: 0.5660\n",
      "Epoch 16/300\n",
      "201/201 - 1s - loss: 2.0849 - accuracy: 0.5345 - val_loss: 2.0827 - val_accuracy: 0.5674\n",
      "Epoch 17/300\n",
      "201/201 - 1s - loss: 2.0555 - accuracy: 0.5451 - val_loss: 2.0476 - val_accuracy: 0.5744\n",
      "Epoch 18/300\n",
      "201/201 - 1s - loss: 2.0172 - accuracy: 0.5451 - val_loss: 2.0121 - val_accuracy: 0.5744\n",
      "Epoch 19/300\n",
      "201/201 - 1s - loss: 1.9849 - accuracy: 0.5523 - val_loss: 1.9783 - val_accuracy: 0.5899\n",
      "Epoch 20/300\n",
      "201/201 - 1s - loss: 1.9502 - accuracy: 0.5574 - val_loss: 1.9478 - val_accuracy: 0.5871\n",
      "Epoch 21/300\n",
      "201/201 - 1s - loss: 1.9124 - accuracy: 0.5759 - val_loss: 1.9167 - val_accuracy: 0.6011\n",
      "Epoch 22/300\n",
      "201/201 - 1s - loss: 1.8821 - accuracy: 0.5818 - val_loss: 1.8869 - val_accuracy: 0.6039\n",
      "Epoch 23/300\n",
      "201/201 - 1s - loss: 1.8468 - accuracy: 0.5841 - val_loss: 1.8592 - val_accuracy: 0.6124\n",
      "Epoch 24/300\n",
      "201/201 - 1s - loss: 1.8081 - accuracy: 0.5933 - val_loss: 1.8330 - val_accuracy: 0.6124\n",
      "Epoch 25/300\n",
      "201/201 - 1s - loss: 1.7875 - accuracy: 0.5979 - val_loss: 1.8062 - val_accuracy: 0.6152\n",
      "Epoch 26/300\n",
      "201/201 - 1s - loss: 1.7692 - accuracy: 0.5999 - val_loss: 1.7797 - val_accuracy: 0.6208\n",
      "Epoch 27/300\n",
      "201/201 - 1s - loss: 1.7345 - accuracy: 0.6107 - val_loss: 1.7566 - val_accuracy: 0.6278\n",
      "Epoch 28/300\n",
      "201/201 - 1s - loss: 1.7072 - accuracy: 0.6165 - val_loss: 1.7332 - val_accuracy: 0.6236\n",
      "Epoch 29/300\n",
      "201/201 - 1s - loss: 1.6824 - accuracy: 0.6149 - val_loss: 1.7082 - val_accuracy: 0.6362\n",
      "Epoch 30/300\n",
      "201/201 - 1s - loss: 1.6571 - accuracy: 0.6272 - val_loss: 1.6875 - val_accuracy: 0.6404\n",
      "Epoch 31/300\n",
      "201/201 - 1s - loss: 1.6386 - accuracy: 0.6263 - val_loss: 1.6661 - val_accuracy: 0.6545\n",
      "Epoch 32/300\n",
      "201/201 - 1s - loss: 1.6132 - accuracy: 0.6366 - val_loss: 1.6429 - val_accuracy: 0.6489\n",
      "Epoch 33/300\n",
      "201/201 - 1s - loss: 1.5807 - accuracy: 0.6441 - val_loss: 1.6238 - val_accuracy: 0.6601\n",
      "Epoch 34/300\n",
      "201/201 - 1s - loss: 1.5576 - accuracy: 0.6474 - val_loss: 1.6029 - val_accuracy: 0.6573\n",
      "Epoch 35/300\n",
      "201/201 - 1s - loss: 1.5426 - accuracy: 0.6511 - val_loss: 1.5841 - val_accuracy: 0.6671\n",
      "Epoch 36/300\n",
      "201/201 - 1s - loss: 1.5193 - accuracy: 0.6503 - val_loss: 1.5659 - val_accuracy: 0.6671\n",
      "Epoch 37/300\n",
      "201/201 - 1s - loss: 1.4939 - accuracy: 0.6570 - val_loss: 1.5482 - val_accuracy: 0.6784\n",
      "Epoch 38/300\n",
      "201/201 - 1s - loss: 1.4809 - accuracy: 0.6689 - val_loss: 1.5294 - val_accuracy: 0.6798\n",
      "Epoch 39/300\n",
      "201/201 - 1s - loss: 1.4571 - accuracy: 0.6647 - val_loss: 1.5143 - val_accuracy: 0.6826\n",
      "Epoch 40/300\n",
      "201/201 - 1s - loss: 1.4349 - accuracy: 0.6697 - val_loss: 1.4973 - val_accuracy: 0.6812\n",
      "Epoch 41/300\n",
      "201/201 - 1s - loss: 1.4205 - accuracy: 0.6748 - val_loss: 1.4833 - val_accuracy: 0.6798\n",
      "Epoch 42/300\n",
      "201/201 - 1s - loss: 1.4056 - accuracy: 0.6759 - val_loss: 1.4672 - val_accuracy: 0.6868\n",
      "Epoch 43/300\n",
      "201/201 - 1s - loss: 1.3875 - accuracy: 0.6830 - val_loss: 1.4513 - val_accuracy: 0.6896\n",
      "Epoch 44/300\n",
      "201/201 - 1s - loss: 1.3689 - accuracy: 0.6839 - val_loss: 1.4390 - val_accuracy: 0.6910\n",
      "Epoch 45/300\n",
      "201/201 - 1s - loss: 1.3386 - accuracy: 0.6890 - val_loss: 1.4206 - val_accuracy: 0.6910\n",
      "Epoch 46/300\n",
      "201/201 - 1s - loss: 1.3378 - accuracy: 0.6867 - val_loss: 1.4082 - val_accuracy: 0.6910\n",
      "Epoch 47/300\n",
      "201/201 - 1s - loss: 1.3148 - accuracy: 0.6953 - val_loss: 1.3960 - val_accuracy: 0.6938\n",
      "Epoch 48/300\n",
      "201/201 - 1s - loss: 1.3005 - accuracy: 0.6962 - val_loss: 1.3799 - val_accuracy: 0.6952\n",
      "Epoch 49/300\n",
      "201/201 - 1s - loss: 1.2847 - accuracy: 0.6970 - val_loss: 1.3659 - val_accuracy: 0.7079\n",
      "Epoch 50/300\n",
      "201/201 - 1s - loss: 1.2822 - accuracy: 0.7022 - val_loss: 1.3531 - val_accuracy: 0.7121\n",
      "Epoch 51/300\n",
      "201/201 - 1s - loss: 1.2498 - accuracy: 0.7037 - val_loss: 1.3404 - val_accuracy: 0.7135\n",
      "Epoch 52/300\n",
      "201/201 - 1s - loss: 1.2402 - accuracy: 0.7121 - val_loss: 1.3255 - val_accuracy: 0.7135\n",
      "Epoch 53/300\n",
      "201/201 - 1s - loss: 1.2258 - accuracy: 0.7125 - val_loss: 1.3167 - val_accuracy: 0.7149\n",
      "Epoch 54/300\n",
      "201/201 - 1s - loss: 1.2039 - accuracy: 0.7214 - val_loss: 1.3030 - val_accuracy: 0.7163\n",
      "Epoch 55/300\n",
      "201/201 - 1s - loss: 1.2062 - accuracy: 0.7193 - val_loss: 1.2903 - val_accuracy: 0.7163\n",
      "Epoch 56/300\n",
      "201/201 - 1s - loss: 1.1656 - accuracy: 0.7276 - val_loss: 1.2808 - val_accuracy: 0.7233\n",
      "Epoch 57/300\n",
      "201/201 - 1s - loss: 1.1712 - accuracy: 0.7253 - val_loss: 1.2675 - val_accuracy: 0.7275\n",
      "Epoch 58/300\n",
      "201/201 - 1s - loss: 1.1481 - accuracy: 0.7287 - val_loss: 1.2584 - val_accuracy: 0.7303\n",
      "Epoch 59/300\n",
      "201/201 - 1s - loss: 1.1467 - accuracy: 0.7348 - val_loss: 1.2490 - val_accuracy: 0.7303\n",
      "Epoch 60/300\n",
      "201/201 - 1s - loss: 1.1332 - accuracy: 0.7331 - val_loss: 1.2354 - val_accuracy: 0.7317\n",
      "Epoch 61/300\n",
      "201/201 - 1s - loss: 1.1138 - accuracy: 0.7388 - val_loss: 1.2273 - val_accuracy: 0.7303\n",
      "Epoch 62/300\n",
      "201/201 - 1s - loss: 1.1018 - accuracy: 0.7418 - val_loss: 1.2131 - val_accuracy: 0.7331\n",
      "Epoch 63/300\n",
      "201/201 - 1s - loss: 1.0874 - accuracy: 0.7402 - val_loss: 1.2076 - val_accuracy: 0.7346\n",
      "Epoch 64/300\n",
      "201/201 - 1s - loss: 1.0852 - accuracy: 0.7435 - val_loss: 1.1972 - val_accuracy: 0.7388\n",
      "Epoch 65/300\n",
      "201/201 - 1s - loss: 1.0759 - accuracy: 0.7452 - val_loss: 1.1920 - val_accuracy: 0.7360\n",
      "Epoch 66/300\n",
      "201/201 - 1s - loss: 1.0591 - accuracy: 0.7426 - val_loss: 1.1820 - val_accuracy: 0.7360\n",
      "Epoch 67/300\n",
      "201/201 - 1s - loss: 1.0449 - accuracy: 0.7491 - val_loss: 1.1793 - val_accuracy: 0.7360\n",
      "Epoch 68/300\n",
      "201/201 - 1s - loss: 1.0406 - accuracy: 0.7502 - val_loss: 1.1663 - val_accuracy: 0.7331\n",
      "Epoch 69/300\n",
      "201/201 - 1s - loss: 1.0394 - accuracy: 0.7495 - val_loss: 1.1609 - val_accuracy: 0.7374\n",
      "Epoch 70/300\n",
      "201/201 - 1s - loss: 1.0202 - accuracy: 0.7546 - val_loss: 1.1516 - val_accuracy: 0.7416\n",
      "Epoch 71/300\n",
      "201/201 - 1s - loss: 1.0027 - accuracy: 0.7587 - val_loss: 1.1474 - val_accuracy: 0.7486\n",
      "Epoch 72/300\n",
      "201/201 - 1s - loss: 0.9944 - accuracy: 0.7668 - val_loss: 1.1413 - val_accuracy: 0.7500\n",
      "Epoch 73/300\n",
      "201/201 - 1s - loss: 0.9966 - accuracy: 0.7577 - val_loss: 1.1336 - val_accuracy: 0.7486\n",
      "Epoch 74/300\n",
      "201/201 - 1s - loss: 0.9751 - accuracy: 0.7601 - val_loss: 1.1264 - val_accuracy: 0.7444\n",
      "Epoch 75/300\n",
      "201/201 - 1s - loss: 0.9658 - accuracy: 0.7654 - val_loss: 1.1216 - val_accuracy: 0.7514\n",
      "Epoch 76/300\n",
      "201/201 - 1s - loss: 0.9466 - accuracy: 0.7749 - val_loss: 1.1156 - val_accuracy: 0.7514\n",
      "Epoch 77/300\n",
      "201/201 - 1s - loss: 0.9514 - accuracy: 0.7682 - val_loss: 1.1140 - val_accuracy: 0.7430\n",
      "Epoch 78/300\n",
      "201/201 - 1s - loss: 0.9498 - accuracy: 0.7702 - val_loss: 1.1066 - val_accuracy: 0.7486\n",
      "Epoch 79/300\n",
      "201/201 - 1s - loss: 0.9422 - accuracy: 0.7733 - val_loss: 1.1034 - val_accuracy: 0.7514\n",
      "Epoch 80/300\n",
      "201/201 - 1s - loss: 0.9286 - accuracy: 0.7747 - val_loss: 1.0992 - val_accuracy: 0.7500\n",
      "Epoch 81/300\n",
      "201/201 - 1s - loss: 0.9202 - accuracy: 0.7768 - val_loss: 1.0915 - val_accuracy: 0.7514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/300\n",
      "201/201 - 1s - loss: 0.9157 - accuracy: 0.7752 - val_loss: 1.0868 - val_accuracy: 0.7514\n",
      "Epoch 83/300\n",
      "201/201 - 1s - loss: 0.9135 - accuracy: 0.7783 - val_loss: 1.0863 - val_accuracy: 0.7486\n",
      "Epoch 84/300\n",
      "201/201 - 1s - loss: 0.8984 - accuracy: 0.7810 - val_loss: 1.0743 - val_accuracy: 0.7570\n",
      "Epoch 85/300\n",
      "201/201 - 1s - loss: 0.8921 - accuracy: 0.7835 - val_loss: 1.0729 - val_accuracy: 0.7542\n",
      "Epoch 86/300\n",
      "201/201 - 1s - loss: 0.8764 - accuracy: 0.7932 - val_loss: 1.0635 - val_accuracy: 0.7542\n",
      "Epoch 87/300\n",
      "201/201 - 1s - loss: 0.8796 - accuracy: 0.7854 - val_loss: 1.0604 - val_accuracy: 0.7584\n",
      "Epoch 88/300\n",
      "201/201 - 1s - loss: 0.8663 - accuracy: 0.7882 - val_loss: 1.0608 - val_accuracy: 0.7514\n",
      "Epoch 89/300\n",
      "201/201 - 1s - loss: 0.8730 - accuracy: 0.7872 - val_loss: 1.0544 - val_accuracy: 0.7528\n",
      "Epoch 90/300\n",
      "201/201 - 1s - loss: 0.8651 - accuracy: 0.7897 - val_loss: 1.0502 - val_accuracy: 0.7570\n",
      "Epoch 91/300\n",
      "201/201 - 1s - loss: 0.8519 - accuracy: 0.7930 - val_loss: 1.0463 - val_accuracy: 0.7570\n",
      "Epoch 92/300\n",
      "201/201 - 1s - loss: 0.8470 - accuracy: 0.7938 - val_loss: 1.0393 - val_accuracy: 0.7626\n",
      "Epoch 93/300\n",
      "201/201 - 1s - loss: 0.8299 - accuracy: 0.7991 - val_loss: 1.0394 - val_accuracy: 0.7612\n",
      "Epoch 94/300\n",
      "201/201 - 1s - loss: 0.8365 - accuracy: 0.7975 - val_loss: 1.0345 - val_accuracy: 0.7612\n",
      "Epoch 95/300\n",
      "201/201 - 1s - loss: 0.8236 - accuracy: 0.7975 - val_loss: 1.0280 - val_accuracy: 0.7584\n",
      "Epoch 96/300\n",
      "201/201 - 1s - loss: 0.8333 - accuracy: 0.7933 - val_loss: 1.0316 - val_accuracy: 0.7584\n",
      "Epoch 97/300\n",
      "201/201 - 1s - loss: 0.8158 - accuracy: 0.8008 - val_loss: 1.0224 - val_accuracy: 0.7612\n",
      "Epoch 98/300\n",
      "201/201 - 1s - loss: 0.7986 - accuracy: 0.8013 - val_loss: 1.0138 - val_accuracy: 0.7654\n",
      "Epoch 99/300\n",
      "201/201 - 1s - loss: 0.8102 - accuracy: 0.8027 - val_loss: 1.0077 - val_accuracy: 0.7654\n",
      "Epoch 100/300\n",
      "201/201 - 1s - loss: 0.7879 - accuracy: 0.8085 - val_loss: 1.0105 - val_accuracy: 0.7612\n",
      "Epoch 101/300\n",
      "201/201 - 1s - loss: 0.7890 - accuracy: 0.8130 - val_loss: 1.0043 - val_accuracy: 0.7612\n",
      "Epoch 102/300\n",
      "201/201 - 1s - loss: 0.7838 - accuracy: 0.8111 - val_loss: 1.0041 - val_accuracy: 0.7654\n",
      "Epoch 103/300\n",
      "201/201 - 1s - loss: 0.7836 - accuracy: 0.8117 - val_loss: 0.9944 - val_accuracy: 0.7640\n",
      "Epoch 104/300\n",
      "201/201 - 1s - loss: 0.7794 - accuracy: 0.8105 - val_loss: 0.9951 - val_accuracy: 0.7654\n",
      "Epoch 105/300\n",
      "201/201 - 1s - loss: 0.7714 - accuracy: 0.8145 - val_loss: 0.9933 - val_accuracy: 0.7669\n",
      "Epoch 106/300\n",
      "201/201 - 1s - loss: 0.7510 - accuracy: 0.8208 - val_loss: 0.9925 - val_accuracy: 0.7626\n",
      "Epoch 107/300\n",
      "201/201 - 1s - loss: 0.7646 - accuracy: 0.8185 - val_loss: 0.9882 - val_accuracy: 0.7711\n",
      "Epoch 108/300\n",
      "201/201 - 1s - loss: 0.7539 - accuracy: 0.8160 - val_loss: 0.9879 - val_accuracy: 0.7654\n",
      "Epoch 109/300\n",
      "201/201 - 1s - loss: 0.7416 - accuracy: 0.8219 - val_loss: 0.9819 - val_accuracy: 0.7711\n",
      "Epoch 110/300\n",
      "201/201 - 1s - loss: 0.7540 - accuracy: 0.8186 - val_loss: 0.9826 - val_accuracy: 0.7640\n",
      "Epoch 111/300\n",
      "201/201 - 1s - loss: 0.7408 - accuracy: 0.8185 - val_loss: 0.9816 - val_accuracy: 0.7640\n",
      "Epoch 112/300\n",
      "201/201 - 1s - loss: 0.7371 - accuracy: 0.8261 - val_loss: 0.9792 - val_accuracy: 0.7640\n",
      "Epoch 113/300\n",
      "201/201 - 1s - loss: 0.7289 - accuracy: 0.8180 - val_loss: 0.9783 - val_accuracy: 0.7640\n",
      "Epoch 114/300\n",
      "201/201 - 1s - loss: 0.7302 - accuracy: 0.8197 - val_loss: 0.9743 - val_accuracy: 0.7654\n",
      "Epoch 115/300\n",
      "201/201 - 1s - loss: 0.7184 - accuracy: 0.8245 - val_loss: 0.9716 - val_accuracy: 0.7654\n",
      "Epoch 116/300\n",
      "201/201 - 1s - loss: 0.7213 - accuracy: 0.8280 - val_loss: 0.9704 - val_accuracy: 0.7654\n",
      "Epoch 117/300\n",
      "201/201 - 1s - loss: 0.7170 - accuracy: 0.8273 - val_loss: 0.9688 - val_accuracy: 0.7640\n",
      "Epoch 118/300\n",
      "201/201 - 1s - loss: 0.7170 - accuracy: 0.8233 - val_loss: 0.9682 - val_accuracy: 0.7669\n",
      "Epoch 119/300\n",
      "201/201 - 1s - loss: 0.7038 - accuracy: 0.8270 - val_loss: 0.9682 - val_accuracy: 0.7626\n",
      "Epoch 120/300\n",
      "201/201 - 1s - loss: 0.6961 - accuracy: 0.8322 - val_loss: 0.9649 - val_accuracy: 0.7683\n",
      "Epoch 121/300\n",
      "201/201 - 1s - loss: 0.6926 - accuracy: 0.8286 - val_loss: 0.9669 - val_accuracy: 0.7626\n",
      "Epoch 122/300\n",
      "201/201 - 1s - loss: 0.6879 - accuracy: 0.8344 - val_loss: 0.9601 - val_accuracy: 0.7654\n",
      "Epoch 123/300\n",
      "201/201 - 1s - loss: 0.6882 - accuracy: 0.8314 - val_loss: 0.9565 - val_accuracy: 0.7669\n",
      "Epoch 124/300\n",
      "201/201 - 1s - loss: 0.6832 - accuracy: 0.8352 - val_loss: 0.9565 - val_accuracy: 0.7584\n",
      "Epoch 125/300\n",
      "201/201 - 1s - loss: 0.6841 - accuracy: 0.8319 - val_loss: 0.9542 - val_accuracy: 0.7654\n",
      "Epoch 126/300\n",
      "201/201 - 1s - loss: 0.6745 - accuracy: 0.8341 - val_loss: 0.9555 - val_accuracy: 0.7626\n",
      "Epoch 127/300\n",
      "201/201 - 1s - loss: 0.6701 - accuracy: 0.8325 - val_loss: 0.9526 - val_accuracy: 0.7669\n",
      "Epoch 128/300\n",
      "201/201 - 1s - loss: 0.6781 - accuracy: 0.8339 - val_loss: 0.9487 - val_accuracy: 0.7683\n",
      "Epoch 129/300\n",
      "201/201 - 1s - loss: 0.6711 - accuracy: 0.8328 - val_loss: 0.9446 - val_accuracy: 0.7697\n",
      "Epoch 130/300\n",
      "201/201 - 1s - loss: 0.6728 - accuracy: 0.8334 - val_loss: 0.9455 - val_accuracy: 0.7669\n",
      "Epoch 131/300\n",
      "201/201 - 1s - loss: 0.6607 - accuracy: 0.8387 - val_loss: 0.9423 - val_accuracy: 0.7683\n",
      "Epoch 132/300\n",
      "201/201 - 1s - loss: 0.6564 - accuracy: 0.8386 - val_loss: 0.9464 - val_accuracy: 0.7711\n",
      "Epoch 133/300\n",
      "201/201 - 1s - loss: 0.6433 - accuracy: 0.8384 - val_loss: 0.9464 - val_accuracy: 0.7711\n",
      "Epoch 134/300\n",
      "201/201 - 1s - loss: 0.6441 - accuracy: 0.8391 - val_loss: 0.9475 - val_accuracy: 0.7683\n",
      "Epoch 135/300\n",
      "201/201 - 1s - loss: 0.6487 - accuracy: 0.8405 - val_loss: 0.9430 - val_accuracy: 0.7669\n",
      "Epoch 136/300\n",
      "201/201 - 1s - loss: 0.6502 - accuracy: 0.8400 - val_loss: 0.9401 - val_accuracy: 0.7697\n",
      "Epoch 137/300\n",
      "201/201 - 1s - loss: 0.6443 - accuracy: 0.8406 - val_loss: 0.9450 - val_accuracy: 0.7654\n",
      "Epoch 138/300\n",
      "201/201 - 1s - loss: 0.6454 - accuracy: 0.8370 - val_loss: 0.9411 - val_accuracy: 0.7626\n",
      "Epoch 139/300\n",
      "201/201 - 1s - loss: 0.6420 - accuracy: 0.8389 - val_loss: 0.9379 - val_accuracy: 0.7683\n",
      "Epoch 140/300\n",
      "201/201 - 1s - loss: 0.6342 - accuracy: 0.8436 - val_loss: 0.9403 - val_accuracy: 0.7683\n",
      "Epoch 141/300\n",
      "201/201 - 1s - loss: 0.6329 - accuracy: 0.8430 - val_loss: 0.9346 - val_accuracy: 0.7697\n",
      "Epoch 142/300\n",
      "201/201 - 1s - loss: 0.6296 - accuracy: 0.8422 - val_loss: 0.9395 - val_accuracy: 0.7725\n",
      "Epoch 143/300\n",
      "201/201 - 1s - loss: 0.6199 - accuracy: 0.8467 - val_loss: 0.9324 - val_accuracy: 0.7683\n",
      "Epoch 144/300\n",
      "201/201 - 1s - loss: 0.6221 - accuracy: 0.8405 - val_loss: 0.9385 - val_accuracy: 0.7640\n",
      "Epoch 145/300\n",
      "201/201 - 1s - loss: 0.6200 - accuracy: 0.8473 - val_loss: 0.9398 - val_accuracy: 0.7697\n",
      "Epoch 146/300\n",
      "201/201 - 1s - loss: 0.6187 - accuracy: 0.8406 - val_loss: 0.9391 - val_accuracy: 0.7669\n",
      "Epoch 147/300\n",
      "201/201 - 1s - loss: 0.6234 - accuracy: 0.8419 - val_loss: 0.9427 - val_accuracy: 0.7697\n",
      "Epoch 148/300\n",
      "201/201 - 1s - loss: 0.6176 - accuracy: 0.8401 - val_loss: 0.9378 - val_accuracy: 0.7711\n",
      "Epoch 149/300\n",
      "201/201 - 1s - loss: 0.6022 - accuracy: 0.8508 - val_loss: 0.9413 - val_accuracy: 0.7697\n",
      "Epoch 150/300\n",
      "201/201 - 1s - loss: 0.5998 - accuracy: 0.8487 - val_loss: 0.9377 - val_accuracy: 0.7725\n",
      "Epoch 151/300\n",
      "201/201 - 1s - loss: 0.6004 - accuracy: 0.8505 - val_loss: 0.9371 - val_accuracy: 0.7654\n",
      "Epoch 152/300\n",
      "201/201 - 1s - loss: 0.5956 - accuracy: 0.8525 - val_loss: 0.9406 - val_accuracy: 0.7654\n",
      "Epoch 153/300\n",
      "201/201 - 1s - loss: 0.6034 - accuracy: 0.8453 - val_loss: 0.9330 - val_accuracy: 0.7711\n",
      "Epoch 154/300\n",
      "201/201 - 1s - loss: 0.6041 - accuracy: 0.8453 - val_loss: 0.9371 - val_accuracy: 0.7626\n",
      "Epoch 155/300\n",
      "201/201 - 1s - loss: 0.5925 - accuracy: 0.8519 - val_loss: 0.9285 - val_accuracy: 0.7711\n",
      "Epoch 156/300\n",
      "201/201 - 1s - loss: 0.5905 - accuracy: 0.8478 - val_loss: 0.9373 - val_accuracy: 0.7683\n",
      "Epoch 157/300\n",
      "201/201 - 1s - loss: 0.5963 - accuracy: 0.8492 - val_loss: 0.9332 - val_accuracy: 0.7669\n",
      "Epoch 158/300\n",
      "201/201 - 1s - loss: 0.5942 - accuracy: 0.8458 - val_loss: 0.9348 - val_accuracy: 0.7640\n",
      "Epoch 159/300\n",
      "201/201 - 1s - loss: 0.5902 - accuracy: 0.8522 - val_loss: 0.9359 - val_accuracy: 0.7725\n",
      "Epoch 160/300\n",
      "201/201 - 1s - loss: 0.5782 - accuracy: 0.8548 - val_loss: 0.9365 - val_accuracy: 0.7654\n",
      "Epoch 161/300\n",
      "201/201 - 1s - loss: 0.5772 - accuracy: 0.8556 - val_loss: 0.9347 - val_accuracy: 0.7725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/300\n",
      "201/201 - 1s - loss: 0.5774 - accuracy: 0.8506 - val_loss: 0.9398 - val_accuracy: 0.7725\n",
      "Epoch 163/300\n",
      "201/201 - 1s - loss: 0.5793 - accuracy: 0.8522 - val_loss: 0.9372 - val_accuracy: 0.7725\n",
      "Epoch 164/300\n",
      "201/201 - 1s - loss: 0.5743 - accuracy: 0.8526 - val_loss: 0.9407 - val_accuracy: 0.7640\n",
      "Epoch 165/300\n",
      "201/201 - 1s - loss: 0.5857 - accuracy: 0.8492 - val_loss: 0.9426 - val_accuracy: 0.7697\n",
      "Epoch 166/300\n",
      "201/201 - 1s - loss: 0.5806 - accuracy: 0.8494 - val_loss: 0.9421 - val_accuracy: 0.7753\n",
      "Epoch 167/300\n",
      "201/201 - 1s - loss: 0.5850 - accuracy: 0.8515 - val_loss: 0.9374 - val_accuracy: 0.7781\n",
      "Epoch 168/300\n",
      "201/201 - 1s - loss: 0.5767 - accuracy: 0.8494 - val_loss: 0.9320 - val_accuracy: 0.7725\n",
      "Epoch 169/300\n",
      "201/201 - 1s - loss: 0.5762 - accuracy: 0.8519 - val_loss: 0.9346 - val_accuracy: 0.7669\n",
      "Epoch 170/300\n",
      "201/201 - 1s - loss: 0.5618 - accuracy: 0.8547 - val_loss: 0.9384 - val_accuracy: 0.7683\n",
      "Epoch 171/300\n",
      "201/201 - 1s - loss: 0.5588 - accuracy: 0.8542 - val_loss: 0.9375 - val_accuracy: 0.7753\n",
      "Epoch 172/300\n",
      "201/201 - 1s - loss: 0.5743 - accuracy: 0.8456 - val_loss: 0.9343 - val_accuracy: 0.7654\n",
      "Epoch 173/300\n",
      "201/201 - 1s - loss: 0.5544 - accuracy: 0.8589 - val_loss: 0.9433 - val_accuracy: 0.7725\n",
      "Epoch 174/300\n",
      "201/201 - 1s - loss: 0.5592 - accuracy: 0.8587 - val_loss: 0.9458 - val_accuracy: 0.7725\n",
      "Epoch 175/300\n",
      "201/201 - 1s - loss: 0.5565 - accuracy: 0.8565 - val_loss: 0.9382 - val_accuracy: 0.7753\n",
      "Epoch 176/300\n",
      "201/201 - 1s - loss: 0.5661 - accuracy: 0.8512 - val_loss: 0.9427 - val_accuracy: 0.7711\n",
      "Epoch 177/300\n",
      "201/201 - 1s - loss: 0.5611 - accuracy: 0.8558 - val_loss: 0.9477 - val_accuracy: 0.7711\n",
      "Epoch 178/300\n",
      "201/201 - 1s - loss: 0.5528 - accuracy: 0.8520 - val_loss: 0.9451 - val_accuracy: 0.7753\n",
      "Epoch 179/300\n",
      "201/201 - 1s - loss: 0.5478 - accuracy: 0.8525 - val_loss: 0.9412 - val_accuracy: 0.7669\n",
      "Epoch 180/300\n",
      "201/201 - 1s - loss: 0.5467 - accuracy: 0.8554 - val_loss: 0.9418 - val_accuracy: 0.7640\n",
      "Epoch 181/300\n",
      "201/201 - 1s - loss: 0.5470 - accuracy: 0.8562 - val_loss: 0.9442 - val_accuracy: 0.7683\n",
      "Epoch 182/300\n",
      "201/201 - 1s - loss: 0.5544 - accuracy: 0.8561 - val_loss: 0.9413 - val_accuracy: 0.7697\n",
      "Epoch 183/300\n",
      "201/201 - 1s - loss: 0.5485 - accuracy: 0.8559 - val_loss: 0.9450 - val_accuracy: 0.7654\n",
      "Epoch 184/300\n",
      "201/201 - 1s - loss: 0.5474 - accuracy: 0.8564 - val_loss: 0.9479 - val_accuracy: 0.7654\n",
      "Epoch 185/300\n",
      "201/201 - 1s - loss: 0.5384 - accuracy: 0.8590 - val_loss: 0.9448 - val_accuracy: 0.7669\n",
      "Epoch 186/300\n",
      "201/201 - 1s - loss: 0.5343 - accuracy: 0.8581 - val_loss: 0.9431 - val_accuracy: 0.7683\n",
      "Epoch 187/300\n",
      "201/201 - 1s - loss: 0.5361 - accuracy: 0.8565 - val_loss: 0.9404 - val_accuracy: 0.7683\n",
      "Epoch 188/300\n",
      "201/201 - 1s - loss: 0.5342 - accuracy: 0.8550 - val_loss: 0.9436 - val_accuracy: 0.7683\n",
      "Epoch 189/300\n",
      "201/201 - 1s - loss: 0.5387 - accuracy: 0.8519 - val_loss: 0.9435 - val_accuracy: 0.7654\n",
      "Epoch 190/300\n",
      "201/201 - 1s - loss: 0.5392 - accuracy: 0.8584 - val_loss: 0.9426 - val_accuracy: 0.7669\n",
      "Epoch 191/300\n",
      "201/201 - 1s - loss: 0.5174 - accuracy: 0.8626 - val_loss: 0.9421 - val_accuracy: 0.7612\n",
      "Epoch 192/300\n",
      "201/201 - 1s - loss: 0.5418 - accuracy: 0.8542 - val_loss: 0.9404 - val_accuracy: 0.7669\n",
      "Epoch 193/300\n",
      "201/201 - 1s - loss: 0.5289 - accuracy: 0.8598 - val_loss: 0.9445 - val_accuracy: 0.7640\n",
      "Epoch 194/300\n",
      "201/201 - 1s - loss: 0.5207 - accuracy: 0.8592 - val_loss: 0.9395 - val_accuracy: 0.7640\n",
      "Epoch 195/300\n",
      "201/201 - 1s - loss: 0.5311 - accuracy: 0.8564 - val_loss: 0.9359 - val_accuracy: 0.7654\n",
      "Epoch 196/300\n",
      "201/201 - 1s - loss: 0.5171 - accuracy: 0.8631 - val_loss: 0.9463 - val_accuracy: 0.7612\n",
      "Epoch 197/300\n",
      "201/201 - 1s - loss: 0.5255 - accuracy: 0.8598 - val_loss: 0.9442 - val_accuracy: 0.7626\n",
      "Epoch 198/300\n",
      "201/201 - 1s - loss: 0.5247 - accuracy: 0.8561 - val_loss: 0.9431 - val_accuracy: 0.7640\n",
      "Epoch 199/300\n",
      "201/201 - 1s - loss: 0.5203 - accuracy: 0.8620 - val_loss: 0.9479 - val_accuracy: 0.7612\n",
      "Epoch 200/300\n",
      "201/201 - 1s - loss: 0.5255 - accuracy: 0.8598 - val_loss: 0.9403 - val_accuracy: 0.7669\n",
      "Epoch 201/300\n",
      "201/201 - 1s - loss: 0.5168 - accuracy: 0.8609 - val_loss: 0.9521 - val_accuracy: 0.7626\n",
      "Epoch 202/300\n",
      "201/201 - 1s - loss: 0.5168 - accuracy: 0.8650 - val_loss: 0.9523 - val_accuracy: 0.7626\n",
      "Epoch 203/300\n",
      "201/201 - 1s - loss: 0.5184 - accuracy: 0.8601 - val_loss: 0.9497 - val_accuracy: 0.7669\n",
      "Epoch 204/300\n",
      "201/201 - 1s - loss: 0.5062 - accuracy: 0.8609 - val_loss: 0.9483 - val_accuracy: 0.7598\n",
      "Epoch 205/300\n",
      "201/201 - 1s - loss: 0.5123 - accuracy: 0.8589 - val_loss: 0.9541 - val_accuracy: 0.7570\n",
      "Epoch 206/300\n",
      "201/201 - 1s - loss: 0.5172 - accuracy: 0.8570 - val_loss: 0.9489 - val_accuracy: 0.7654\n",
      "Epoch 207/300\n",
      "201/201 - 1s - loss: 0.5171 - accuracy: 0.8601 - val_loss: 0.9505 - val_accuracy: 0.7669\n",
      "Epoch 208/300\n",
      "201/201 - 1s - loss: 0.5118 - accuracy: 0.8598 - val_loss: 0.9553 - val_accuracy: 0.7598\n",
      "Epoch 209/300\n",
      "201/201 - 1s - loss: 0.5153 - accuracy: 0.8542 - val_loss: 0.9513 - val_accuracy: 0.7626\n",
      "Epoch 210/300\n",
      "201/201 - 1s - loss: 0.5030 - accuracy: 0.8634 - val_loss: 0.9517 - val_accuracy: 0.7570\n",
      "Epoch 211/300\n",
      "201/201 - 1s - loss: 0.5025 - accuracy: 0.8656 - val_loss: 0.9526 - val_accuracy: 0.7626\n",
      "Epoch 212/300\n",
      "201/201 - 1s - loss: 0.5053 - accuracy: 0.8611 - val_loss: 0.9540 - val_accuracy: 0.7584\n",
      "Epoch 213/300\n",
      "201/201 - 1s - loss: 0.5057 - accuracy: 0.8626 - val_loss: 0.9538 - val_accuracy: 0.7612\n",
      "Epoch 214/300\n",
      "201/201 - 1s - loss: 0.5008 - accuracy: 0.8676 - val_loss: 0.9539 - val_accuracy: 0.7654\n",
      "Epoch 215/300\n",
      "201/201 - 1s - loss: 0.5017 - accuracy: 0.8612 - val_loss: 0.9574 - val_accuracy: 0.7598\n",
      "Epoch 216/300\n",
      "201/201 - 1s - loss: 0.5001 - accuracy: 0.8654 - val_loss: 0.9593 - val_accuracy: 0.7640\n",
      "Epoch 217/300\n",
      "201/201 - 1s - loss: 0.4841 - accuracy: 0.8712 - val_loss: 0.9605 - val_accuracy: 0.7626\n",
      "Epoch 218/300\n",
      "201/201 - 1s - loss: 0.5000 - accuracy: 0.8647 - val_loss: 0.9638 - val_accuracy: 0.7598\n",
      "Epoch 219/300\n",
      "201/201 - 1s - loss: 0.4948 - accuracy: 0.8642 - val_loss: 0.9593 - val_accuracy: 0.7570\n",
      "Epoch 220/300\n",
      "201/201 - 1s - loss: 0.4876 - accuracy: 0.8679 - val_loss: 0.9493 - val_accuracy: 0.7640\n",
      "Epoch 221/300\n",
      "201/201 - 1s - loss: 0.5034 - accuracy: 0.8608 - val_loss: 0.9569 - val_accuracy: 0.7584\n",
      "Epoch 222/300\n",
      "201/201 - 1s - loss: 0.5019 - accuracy: 0.8604 - val_loss: 0.9562 - val_accuracy: 0.7669\n",
      "Epoch 223/300\n",
      "201/201 - 1s - loss: 0.4982 - accuracy: 0.8664 - val_loss: 0.9643 - val_accuracy: 0.7542\n",
      "Epoch 224/300\n",
      "201/201 - 1s - loss: 0.4764 - accuracy: 0.8698 - val_loss: 0.9709 - val_accuracy: 0.7570\n",
      "Epoch 225/300\n",
      "201/201 - 1s - loss: 0.4919 - accuracy: 0.8639 - val_loss: 0.9646 - val_accuracy: 0.7626\n",
      "Epoch 226/300\n",
      "201/201 - 1s - loss: 0.4946 - accuracy: 0.8636 - val_loss: 0.9580 - val_accuracy: 0.7556\n",
      "Epoch 227/300\n",
      "201/201 - 1s - loss: 0.5012 - accuracy: 0.8637 - val_loss: 0.9659 - val_accuracy: 0.7570\n",
      "Epoch 228/300\n",
      "201/201 - 1s - loss: 0.4844 - accuracy: 0.8681 - val_loss: 0.9695 - val_accuracy: 0.7584\n",
      "Epoch 229/300\n",
      "201/201 - 1s - loss: 0.4859 - accuracy: 0.8651 - val_loss: 0.9762 - val_accuracy: 0.7598\n",
      "Epoch 230/300\n",
      "201/201 - 1s - loss: 0.4740 - accuracy: 0.8742 - val_loss: 0.9774 - val_accuracy: 0.7626\n",
      "Epoch 231/300\n",
      "201/201 - 1s - loss: 0.4836 - accuracy: 0.8697 - val_loss: 0.9833 - val_accuracy: 0.7584\n",
      "Epoch 232/300\n",
      "201/201 - 1s - loss: 0.4918 - accuracy: 0.8643 - val_loss: 0.9704 - val_accuracy: 0.7612\n",
      "Epoch 233/300\n",
      "201/201 - 1s - loss: 0.4941 - accuracy: 0.8629 - val_loss: 0.9730 - val_accuracy: 0.7542\n",
      "Epoch 234/300\n",
      "201/201 - 1s - loss: 0.4802 - accuracy: 0.8711 - val_loss: 0.9654 - val_accuracy: 0.7556\n",
      "Epoch 235/300\n",
      "201/201 - 1s - loss: 0.4848 - accuracy: 0.8668 - val_loss: 0.9647 - val_accuracy: 0.7626\n",
      "Epoch 236/300\n",
      "201/201 - 1s - loss: 0.4775 - accuracy: 0.8698 - val_loss: 0.9735 - val_accuracy: 0.7570\n",
      "Epoch 237/300\n",
      "201/201 - 1s - loss: 0.4738 - accuracy: 0.8678 - val_loss: 0.9750 - val_accuracy: 0.7612\n",
      "Epoch 238/300\n",
      "201/201 - 1s - loss: 0.4731 - accuracy: 0.8697 - val_loss: 0.9718 - val_accuracy: 0.7612\n",
      "Epoch 239/300\n",
      "201/201 - 1s - loss: 0.4835 - accuracy: 0.8626 - val_loss: 0.9824 - val_accuracy: 0.7500\n",
      "Epoch 240/300\n",
      "201/201 - 1s - loss: 0.4580 - accuracy: 0.8746 - val_loss: 0.9772 - val_accuracy: 0.7542\n",
      "Epoch 241/300\n",
      "201/201 - 1s - loss: 0.4706 - accuracy: 0.8697 - val_loss: 0.9753 - val_accuracy: 0.7570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242/300\n",
      "201/201 - 1s - loss: 0.4762 - accuracy: 0.8676 - val_loss: 0.9876 - val_accuracy: 0.7584\n",
      "Epoch 243/300\n",
      "201/201 - 1s - loss: 0.4692 - accuracy: 0.8707 - val_loss: 0.9800 - val_accuracy: 0.7542\n",
      "Epoch 244/300\n",
      "201/201 - 1s - loss: 0.4788 - accuracy: 0.8697 - val_loss: 0.9766 - val_accuracy: 0.7612\n",
      "Epoch 245/300\n",
      "201/201 - 1s - loss: 0.4808 - accuracy: 0.8629 - val_loss: 0.9800 - val_accuracy: 0.7584\n",
      "Epoch 246/300\n",
      "201/201 - 1s - loss: 0.4735 - accuracy: 0.8695 - val_loss: 0.9795 - val_accuracy: 0.7570\n",
      "Epoch 247/300\n",
      "201/201 - 1s - loss: 0.4733 - accuracy: 0.8722 - val_loss: 0.9861 - val_accuracy: 0.7584\n",
      "Epoch 248/300\n",
      "201/201 - 1s - loss: 0.4748 - accuracy: 0.8667 - val_loss: 0.9938 - val_accuracy: 0.7542\n",
      "Epoch 249/300\n",
      "201/201 - 1s - loss: 0.4824 - accuracy: 0.8617 - val_loss: 0.9866 - val_accuracy: 0.7584\n",
      "Epoch 250/300\n",
      "201/201 - 1s - loss: 0.4796 - accuracy: 0.8687 - val_loss: 0.9857 - val_accuracy: 0.7584\n",
      "Epoch 251/300\n",
      "201/201 - 1s - loss: 0.4675 - accuracy: 0.8712 - val_loss: 0.9850 - val_accuracy: 0.7542\n",
      "Epoch 252/300\n",
      "201/201 - 1s - loss: 0.4750 - accuracy: 0.8642 - val_loss: 0.9880 - val_accuracy: 0.7514\n",
      "Epoch 253/300\n",
      "201/201 - 1s - loss: 0.4751 - accuracy: 0.8726 - val_loss: 0.9907 - val_accuracy: 0.7500\n",
      "Epoch 254/300\n",
      "201/201 - 1s - loss: 0.4842 - accuracy: 0.8636 - val_loss: 0.9938 - val_accuracy: 0.7528\n",
      "Epoch 255/300\n",
      "201/201 - 1s - loss: 0.4713 - accuracy: 0.8672 - val_loss: 0.9975 - val_accuracy: 0.7514\n",
      "Epoch 256/300\n",
      "201/201 - 1s - loss: 0.4668 - accuracy: 0.8690 - val_loss: 1.0022 - val_accuracy: 0.7500\n",
      "Epoch 257/300\n",
      "201/201 - 1s - loss: 0.4590 - accuracy: 0.8682 - val_loss: 0.9925 - val_accuracy: 0.7542\n",
      "Epoch 258/300\n",
      "201/201 - 1s - loss: 0.4633 - accuracy: 0.8745 - val_loss: 0.9894 - val_accuracy: 0.7486\n",
      "Epoch 259/300\n",
      "201/201 - 1s - loss: 0.4570 - accuracy: 0.8753 - val_loss: 0.9905 - val_accuracy: 0.7556\n",
      "Epoch 260/300\n",
      "201/201 - 1s - loss: 0.4683 - accuracy: 0.8706 - val_loss: 0.9943 - val_accuracy: 0.7514\n",
      "Epoch 261/300\n",
      "201/201 - 1s - loss: 0.4631 - accuracy: 0.8697 - val_loss: 0.9896 - val_accuracy: 0.7528\n",
      "Epoch 262/300\n",
      "201/201 - 1s - loss: 0.4775 - accuracy: 0.8634 - val_loss: 1.0061 - val_accuracy: 0.7486\n",
      "Epoch 263/300\n",
      "201/201 - 1s - loss: 0.4602 - accuracy: 0.8712 - val_loss: 1.0035 - val_accuracy: 0.7500\n",
      "Epoch 264/300\n",
      "201/201 - 1s - loss: 0.4650 - accuracy: 0.8703 - val_loss: 1.0012 - val_accuracy: 0.7486\n",
      "Epoch 265/300\n",
      "201/201 - 1s - loss: 0.4649 - accuracy: 0.8684 - val_loss: 0.9891 - val_accuracy: 0.7570\n",
      "Epoch 266/300\n",
      "201/201 - 1s - loss: 0.4668 - accuracy: 0.8665 - val_loss: 0.9959 - val_accuracy: 0.7528\n",
      "Epoch 267/300\n",
      "201/201 - 1s - loss: 0.4480 - accuracy: 0.8748 - val_loss: 0.9914 - val_accuracy: 0.7514\n",
      "Epoch 268/300\n",
      "201/201 - 1s - loss: 0.4574 - accuracy: 0.8726 - val_loss: 1.0008 - val_accuracy: 0.7444\n",
      "Epoch 269/300\n",
      "201/201 - 1s - loss: 0.4617 - accuracy: 0.8722 - val_loss: 0.9962 - val_accuracy: 0.7486\n",
      "Epoch 270/300\n",
      "201/201 - 1s - loss: 0.4599 - accuracy: 0.8684 - val_loss: 0.9920 - val_accuracy: 0.7528\n",
      "Epoch 271/300\n",
      "201/201 - 1s - loss: 0.4531 - accuracy: 0.8717 - val_loss: 0.9918 - val_accuracy: 0.7500\n",
      "Epoch 272/300\n",
      "201/201 - 1s - loss: 0.4580 - accuracy: 0.8703 - val_loss: 1.0023 - val_accuracy: 0.7486\n",
      "Epoch 273/300\n",
      "201/201 - 1s - loss: 0.4487 - accuracy: 0.8753 - val_loss: 0.9981 - val_accuracy: 0.7584\n",
      "Epoch 274/300\n",
      "201/201 - 1s - loss: 0.4394 - accuracy: 0.8779 - val_loss: 0.9979 - val_accuracy: 0.7486\n",
      "Epoch 275/300\n",
      "201/201 - 1s - loss: 0.4505 - accuracy: 0.8745 - val_loss: 1.0106 - val_accuracy: 0.7514\n",
      "Epoch 276/300\n",
      "201/201 - 1s - loss: 0.4378 - accuracy: 0.8776 - val_loss: 1.0117 - val_accuracy: 0.7584\n",
      "Epoch 277/300\n",
      "201/201 - 1s - loss: 0.4611 - accuracy: 0.8658 - val_loss: 1.0163 - val_accuracy: 0.7472\n",
      "Epoch 278/300\n",
      "201/201 - 1s - loss: 0.4465 - accuracy: 0.8745 - val_loss: 1.0117 - val_accuracy: 0.7556\n",
      "Epoch 279/300\n",
      "201/201 - 1s - loss: 0.4486 - accuracy: 0.8734 - val_loss: 0.9922 - val_accuracy: 0.7486\n",
      "Epoch 280/300\n",
      "201/201 - 1s - loss: 0.4622 - accuracy: 0.8678 - val_loss: 0.9983 - val_accuracy: 0.7542\n",
      "Epoch 281/300\n",
      "201/201 - 1s - loss: 0.4512 - accuracy: 0.8787 - val_loss: 1.0194 - val_accuracy: 0.7458\n",
      "Epoch 282/300\n",
      "201/201 - 1s - loss: 0.4575 - accuracy: 0.8715 - val_loss: 1.0106 - val_accuracy: 0.7542\n",
      "Epoch 283/300\n",
      "201/201 - 1s - loss: 0.4574 - accuracy: 0.8731 - val_loss: 1.0194 - val_accuracy: 0.7514\n",
      "Epoch 284/300\n",
      "201/201 - 1s - loss: 0.4398 - accuracy: 0.8751 - val_loss: 1.0213 - val_accuracy: 0.7556\n",
      "Epoch 285/300\n",
      "201/201 - 1s - loss: 0.4481 - accuracy: 0.8690 - val_loss: 1.0159 - val_accuracy: 0.7500\n",
      "Epoch 286/300\n",
      "201/201 - 1s - loss: 0.4418 - accuracy: 0.8761 - val_loss: 1.0271 - val_accuracy: 0.7500\n",
      "Epoch 287/300\n",
      "201/201 - 1s - loss: 0.4457 - accuracy: 0.8784 - val_loss: 1.0279 - val_accuracy: 0.7472\n",
      "Epoch 288/300\n",
      "201/201 - 1s - loss: 0.4492 - accuracy: 0.8732 - val_loss: 1.0122 - val_accuracy: 0.7584\n",
      "Epoch 289/300\n",
      "201/201 - 1s - loss: 0.4500 - accuracy: 0.8737 - val_loss: 1.0229 - val_accuracy: 0.7556\n",
      "Epoch 290/300\n",
      "201/201 - 1s - loss: 0.4569 - accuracy: 0.8722 - val_loss: 1.0143 - val_accuracy: 0.7514\n",
      "Epoch 291/300\n",
      "201/201 - 1s - loss: 0.4298 - accuracy: 0.8764 - val_loss: 1.0214 - val_accuracy: 0.7542\n",
      "Epoch 292/300\n",
      "201/201 - 1s - loss: 0.4476 - accuracy: 0.8736 - val_loss: 1.0216 - val_accuracy: 0.7570\n",
      "Epoch 293/300\n",
      "201/201 - 1s - loss: 0.4307 - accuracy: 0.8795 - val_loss: 1.0298 - val_accuracy: 0.7542\n",
      "Epoch 294/300\n",
      "201/201 - 1s - loss: 0.4322 - accuracy: 0.8793 - val_loss: 1.0449 - val_accuracy: 0.7486\n",
      "Epoch 295/300\n",
      "201/201 - 1s - loss: 0.4470 - accuracy: 0.8746 - val_loss: 1.0350 - val_accuracy: 0.7472\n",
      "Epoch 296/300\n",
      "201/201 - 1s - loss: 0.4356 - accuracy: 0.8759 - val_loss: 1.0414 - val_accuracy: 0.7528\n",
      "Epoch 297/300\n",
      "201/201 - 1s - loss: 0.4452 - accuracy: 0.8707 - val_loss: 1.0359 - val_accuracy: 0.7472\n",
      "Epoch 298/300\n",
      "201/201 - 1s - loss: 0.4486 - accuracy: 0.8757 - val_loss: 1.0514 - val_accuracy: 0.7500\n",
      "Epoch 299/300\n",
      "201/201 - 1s - loss: 0.4360 - accuracy: 0.8782 - val_loss: 1.0419 - val_accuracy: 0.7444\n",
      "Epoch 300/300\n",
      "201/201 - 1s - loss: 0.4381 - accuracy: 0.8745 - val_loss: 1.0385 - val_accuracy: 0.7486\n",
      "59/59 - 0s - loss: 1.1445 - accuracy: 0.7281\n",
      "\n",
      "Test accuracy for 30 classes width res 24: 0.7280513644218445\n",
      "Confusion Matrix\n",
      "[[94  0  3  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0\n",
      "   0  0  0  0  0  1]\n",
      " [ 0 31 12  1  0  0  0  0  0  0  0  0  2  0  1  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  2  0  1]\n",
      " [ 0  2 93  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0\n",
      "   0  0  0  1  0  2]\n",
      " [ 1  0  1 15  0  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  1]\n",
      " [ 1  0  0  0 85  2  0  0  1  0  1  2  0  3  0  0  0  0  0  0  0  0  0  0\n",
      "   1  2  1  1  0  0]\n",
      " [ 3  0  0  0  1 85  0  0  1  0  0  1  0  0  0  4  0  0  0  1  1  0  2  0\n",
      "   0  0  0  1  0  0]\n",
      " [ 2  0  2  0  0  0  5  0  0  0  0  0  0  0  0  0  0  2  0  0  1  0  0  0\n",
      "   0  1  0  0  0  7]\n",
      " [ 1  1  1  3  0  0  0 81  2  1  1  0  0  0  0  3  0  0  2  0  0  0  0  0\n",
      "   0  2  0  2  0  0]\n",
      " [ 1  0  1  1  0  0  0  0 91  0  0  0  0  2  0  0  0  0  0  0  1  0  0  0\n",
      "   0  1  1  0  0  1]\n",
      " [ 0  0  1  0  0  1  0  1  0 13  0  0  0  0  0  1  0  0  0  0  1  0  0  1\n",
      "   0  0  1  0  0  0]\n",
      " [ 1  0  0  1  0  0  1  0  0  0  5  0  0  0  0  7  0  0  0  1  0  0  0  0\n",
      "   0  0  2  1  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  9  0  4  0  0  0  0  0  1  0  0  2  0\n",
      "   2  1  0  0  0  0]\n",
      " [ 0  8  3  0  0  0  0  0  0  0  0  0 58  0  6  0  0  0  0  0  0  0  1  8\n",
      "   0  2  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  3  0 15  0  1  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  1  0  0  1  2  0  0  0  1  0  0  2  0 67  0  0  0  0  0  0  0  0 10\n",
      "   0  1  0  1  0  0]\n",
      " [ 0  0  0  0  0  3  0  0  0  1  1  0  0  0  0  6  1  0  0  0  0  0  0  0\n",
      "   1  0  7  0  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  1  0  0  0  0  0  0  0 92  0  0  0  1  0  0  2\n",
      "   0  1  0  1  0  0]\n",
      " [ 5  0  3  1  0  0  0  0  0  0  0  1  0  0  0  1  0 79  7  0  1  0  0  0\n",
      "   0  0  0  1  0  1]\n",
      " [ 1  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0\n",
      "   0  0  0  1  0  0]\n",
      " [ 0  0  0  0  1  2  0  0  0  0  1  1  0  1  0  0  0  0  0  8  0  0  0  0\n",
      "   0  0  5  0  0  1]\n",
      " [ 0  0  0  0  0  0  2  0  3  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0\n",
      "   0  0  0  0  0  1]\n",
      " [ 0  0  1  0  5  0  0  0  0  0  0  0  0  0  0  1  1  0  0  0  0 86  2  0\n",
      "   0  3  0  1  0  0]\n",
      " [ 0  0  1  0  1  0  0  0  0  0  6  0  1  0  1  0  0  0  0  2  0  0 85  1\n",
      "   0  1  0  0  0  1]\n",
      " [ 0  0  0  0  1  0  0  0  0  1  0  0  4  0 22  0  0  0  0  0  0  0  1 57\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  1  2  1  0  0  0  0  1  0  0  1  0  0  0  0  0  2  0  0  0  0\n",
      "   3  0  9  0  0  0]\n",
      " [ 3  0  4  2  7  0  0  0  7  1  0  2  2  0  0  2  0  1  0  0  4  3  1  0\n",
      "   1 52  2  3  0  3]\n",
      " [ 2  0  0  1  5  5  1  1  2  1  1  1  0  2  0 11  0  0  2  7  1  0  0  1\n",
      "   8  9 37  2  0  0]\n",
      " [ 0  0  1  1  1  2  0  0  1  0  0  0  0  0  1  0  1  0  0  0  1  0  0  0\n",
      "   0  3  0  5  0  3]\n",
      " [ 0  0  0  0  8  0  0  1  3  4  0  0  0  0  0  4  1  0  0  0  2  2  0  3\n",
      "   0  0  1  0 67  4]\n",
      " [ 1  0  4  0  0  0  2  1  3  0  0  0  0  0  0  0  1  0  0  0  0  1  0  0\n",
      "   0  0  0  0  1  6]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.81      0.94      0.87       100\n",
      "     bathtub       0.72      0.62      0.67        50\n",
      "         bed       0.70      0.93      0.80       100\n",
      "       bench       0.56      0.75      0.64        20\n",
      "   bookshelf       0.71      0.85      0.77       100\n",
      "      bottle       0.82      0.85      0.83       100\n",
      "        bowl       0.45      0.25      0.32        20\n",
      "         car       0.95      0.81      0.88       100\n",
      "       chair       0.77      0.91      0.83       100\n",
      "        cone       0.57      0.65      0.60        20\n",
      "         cup       0.29      0.25      0.27        20\n",
      "     curtain       0.43      0.45      0.44        20\n",
      "        desk       0.83      0.67      0.74        86\n",
      "        door       0.54      0.75      0.63        20\n",
      "     dresser       0.68      0.78      0.73        86\n",
      "  flower_pot       0.15      0.30      0.20        20\n",
      "   glass_box       0.95      0.92      0.93       100\n",
      "      guitar       0.96      0.79      0.87       100\n",
      "    keyboard       0.57      0.80      0.67        20\n",
      "        lamp       0.36      0.40      0.38        20\n",
      "      laptop       0.48      0.70      0.57        20\n",
      "      mantel       0.93      0.86      0.90       100\n",
      "     monitor       0.90      0.85      0.88       100\n",
      " night_stand       0.69      0.66      0.67        86\n",
      "      person       0.19      0.15      0.17        20\n",
      "       piano       0.66      0.52      0.58       100\n",
      "       plant       0.56      0.37      0.45       100\n",
      "       radio       0.22      0.25      0.23        20\n",
      "  range_hood       0.99      0.67      0.80       100\n",
      "        sink       0.18      0.30      0.22        20\n",
      "\n",
      "    accuracy                           0.73      1868\n",
      "   macro avg       0.62      0.63      0.62      1868\n",
      "weighted avg       0.75      0.73      0.73      1868\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_25 (Flatten)         (None, 13824)             0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 48)                663600    \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 12)                588       \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 40)                520       \n",
      "=================================================================\n",
      "Total params: 664,708\n",
      "Trainable params: 664,708\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/400\n",
      "277/277 - 2s - loss: 3.4980 - accuracy: 0.1184 - val_loss: 3.3395 - val_accuracy: 0.2173\n",
      "Epoch 2/400\n",
      "277/277 - 2s - loss: 3.2626 - accuracy: 0.2490 - val_loss: 3.1974 - val_accuracy: 0.3360\n",
      "Epoch 3/400\n",
      "277/277 - 2s - loss: 3.1385 - accuracy: 0.3189 - val_loss: 3.0970 - val_accuracy: 0.4061\n",
      "Epoch 4/400\n",
      "277/277 - 2s - loss: 3.0392 - accuracy: 0.3719 - val_loss: 3.0097 - val_accuracy: 0.4162\n",
      "Epoch 5/400\n",
      "277/277 - 2s - loss: 2.9527 - accuracy: 0.3855 - val_loss: 2.9328 - val_accuracy: 0.4183\n",
      "Epoch 6/400\n",
      "277/277 - 2s - loss: 2.8783 - accuracy: 0.3981 - val_loss: 2.8634 - val_accuracy: 0.4274\n",
      "Epoch 7/400\n",
      "277/277 - 2s - loss: 2.8122 - accuracy: 0.4016 - val_loss: 2.7975 - val_accuracy: 0.4335\n",
      "Epoch 8/400\n",
      "277/277 - 2s - loss: 2.7427 - accuracy: 0.4182 - val_loss: 2.7374 - val_accuracy: 0.4335\n",
      "Epoch 9/400\n",
      "277/277 - 2s - loss: 2.6865 - accuracy: 0.4152 - val_loss: 2.6820 - val_accuracy: 0.4447\n",
      "Epoch 10/400\n",
      "277/277 - 2s - loss: 2.6278 - accuracy: 0.4240 - val_loss: 2.6284 - val_accuracy: 0.4477\n",
      "Epoch 11/400\n",
      "277/277 - 2s - loss: 2.5765 - accuracy: 0.4361 - val_loss: 2.5802 - val_accuracy: 0.4569\n",
      "Epoch 12/400\n",
      "277/277 - 2s - loss: 2.5305 - accuracy: 0.4413 - val_loss: 2.5337 - val_accuracy: 0.4660\n",
      "Epoch 13/400\n",
      "277/277 - 2s - loss: 2.4738 - accuracy: 0.4564 - val_loss: 2.4868 - val_accuracy: 0.4863\n",
      "Epoch 14/400\n",
      "277/277 - 2s - loss: 2.4220 - accuracy: 0.4771 - val_loss: 2.4411 - val_accuracy: 0.4944\n",
      "Epoch 15/400\n",
      "277/277 - 2s - loss: 2.3789 - accuracy: 0.4804 - val_loss: 2.4011 - val_accuracy: 0.5056\n",
      "Epoch 16/400\n",
      "277/277 - 2s - loss: 2.3413 - accuracy: 0.4914 - val_loss: 2.3586 - val_accuracy: 0.5056\n",
      "Epoch 17/400\n",
      "277/277 - 2s - loss: 2.3027 - accuracy: 0.4906 - val_loss: 2.3196 - val_accuracy: 0.5157\n",
      "Epoch 18/400\n",
      "277/277 - 2s - loss: 2.2526 - accuracy: 0.5058 - val_loss: 2.2831 - val_accuracy: 0.5218\n",
      "Epoch 19/400\n",
      "277/277 - 2s - loss: 2.2199 - accuracy: 0.5149 - val_loss: 2.2461 - val_accuracy: 0.5289\n",
      "Epoch 20/400\n",
      "277/277 - 2s - loss: 2.1832 - accuracy: 0.5216 - val_loss: 2.2139 - val_accuracy: 0.5279\n",
      "Epoch 21/400\n",
      "277/277 - 2s - loss: 2.1453 - accuracy: 0.5299 - val_loss: 2.1778 - val_accuracy: 0.5350\n",
      "Epoch 22/400\n",
      "277/277 - 2s - loss: 2.1205 - accuracy: 0.5259 - val_loss: 2.1477 - val_accuracy: 0.5391\n",
      "Epoch 23/400\n",
      "277/277 - 2s - loss: 2.0774 - accuracy: 0.5405 - val_loss: 2.1156 - val_accuracy: 0.5411\n",
      "Epoch 24/400\n",
      "277/277 - 2s - loss: 2.0493 - accuracy: 0.5380 - val_loss: 2.0869 - val_accuracy: 0.5401\n",
      "Epoch 25/400\n",
      "277/277 - 2s - loss: 2.0213 - accuracy: 0.5438 - val_loss: 2.0570 - val_accuracy: 0.5482\n",
      "Epoch 26/400\n",
      "277/277 - 2s - loss: 1.9815 - accuracy: 0.5443 - val_loss: 2.0325 - val_accuracy: 0.5442\n",
      "Epoch 27/400\n",
      "277/277 - 2s - loss: 1.9527 - accuracy: 0.5506 - val_loss: 2.0042 - val_accuracy: 0.5482\n",
      "Epoch 28/400\n",
      "277/277 - 2s - loss: 1.9302 - accuracy: 0.5538 - val_loss: 1.9770 - val_accuracy: 0.5513\n",
      "Epoch 29/400\n",
      "277/277 - 2s - loss: 1.9012 - accuracy: 0.5598 - val_loss: 1.9536 - val_accuracy: 0.5594\n",
      "Epoch 30/400\n",
      "277/277 - 2s - loss: 1.8769 - accuracy: 0.5624 - val_loss: 1.9333 - val_accuracy: 0.5584\n",
      "Epoch 31/400\n",
      "277/277 - 2s - loss: 1.8440 - accuracy: 0.5719 - val_loss: 1.9054 - val_accuracy: 0.5716\n",
      "Epoch 32/400\n",
      "277/277 - 2s - loss: 1.8268 - accuracy: 0.5729 - val_loss: 1.8863 - val_accuracy: 0.5716\n",
      "Epoch 33/400\n",
      "277/277 - 2s - loss: 1.7992 - accuracy: 0.5745 - val_loss: 1.8642 - val_accuracy: 0.5777\n",
      "Epoch 34/400\n",
      "277/277 - 2s - loss: 1.7678 - accuracy: 0.5846 - val_loss: 1.8455 - val_accuracy: 0.5838\n",
      "Epoch 35/400\n",
      "277/277 - 2s - loss: 1.7477 - accuracy: 0.5860 - val_loss: 1.8243 - val_accuracy: 0.5878\n",
      "Epoch 36/400\n",
      "277/277 - 2s - loss: 1.7319 - accuracy: 0.5834 - val_loss: 1.8074 - val_accuracy: 0.5838\n",
      "Epoch 37/400\n",
      "277/277 - 2s - loss: 1.6995 - accuracy: 0.5929 - val_loss: 1.7897 - val_accuracy: 0.5878\n",
      "Epoch 38/400\n",
      "277/277 - 2s - loss: 1.6864 - accuracy: 0.5955 - val_loss: 1.7725 - val_accuracy: 0.5929\n",
      "Epoch 39/400\n",
      "277/277 - 2s - loss: 1.6678 - accuracy: 0.5982 - val_loss: 1.7552 - val_accuracy: 0.5949\n",
      "Epoch 40/400\n",
      "277/277 - 2s - loss: 1.6581 - accuracy: 0.6031 - val_loss: 1.7369 - val_accuracy: 0.5980\n",
      "Epoch 41/400\n",
      "277/277 - 2s - loss: 1.6342 - accuracy: 0.6045 - val_loss: 1.7236 - val_accuracy: 0.5939\n",
      "Epoch 42/400\n",
      "277/277 - 2s - loss: 1.6068 - accuracy: 0.6113 - val_loss: 1.7067 - val_accuracy: 0.6102\n",
      "Epoch 43/400\n",
      "277/277 - 2s - loss: 1.5921 - accuracy: 0.6126 - val_loss: 1.6889 - val_accuracy: 0.6234\n",
      "Epoch 44/400\n",
      "277/277 - 2s - loss: 1.5742 - accuracy: 0.6154 - val_loss: 1.6782 - val_accuracy: 0.6264\n",
      "Epoch 45/400\n",
      "277/277 - 2s - loss: 1.5561 - accuracy: 0.6190 - val_loss: 1.6623 - val_accuracy: 0.6315\n",
      "Epoch 46/400\n",
      "277/277 - 2s - loss: 1.5409 - accuracy: 0.6234 - val_loss: 1.6487 - val_accuracy: 0.6305\n",
      "Epoch 47/400\n",
      "277/277 - 2s - loss: 1.5290 - accuracy: 0.6264 - val_loss: 1.6368 - val_accuracy: 0.6355\n",
      "Epoch 48/400\n",
      "277/277 - 2s - loss: 1.5149 - accuracy: 0.6298 - val_loss: 1.6203 - val_accuracy: 0.6335\n",
      "Epoch 49/400\n",
      "277/277 - 2s - loss: 1.4832 - accuracy: 0.6358 - val_loss: 1.6085 - val_accuracy: 0.6426\n",
      "Epoch 50/400\n",
      "277/277 - 2s - loss: 1.4700 - accuracy: 0.6392 - val_loss: 1.5985 - val_accuracy: 0.6437\n",
      "Epoch 51/400\n",
      "277/277 - 2s - loss: 1.4607 - accuracy: 0.6374 - val_loss: 1.5859 - val_accuracy: 0.6376\n",
      "Epoch 52/400\n",
      "277/277 - 2s - loss: 1.4453 - accuracy: 0.6424 - val_loss: 1.5775 - val_accuracy: 0.6426\n",
      "Epoch 53/400\n",
      "277/277 - 2s - loss: 1.4236 - accuracy: 0.6489 - val_loss: 1.5662 - val_accuracy: 0.6487\n",
      "Epoch 54/400\n",
      "277/277 - 2s - loss: 1.4145 - accuracy: 0.6506 - val_loss: 1.5516 - val_accuracy: 0.6518\n",
      "Epoch 55/400\n",
      "277/277 - 2s - loss: 1.3899 - accuracy: 0.6579 - val_loss: 1.5435 - val_accuracy: 0.6548\n",
      "Epoch 56/400\n",
      "277/277 - 2s - loss: 1.3911 - accuracy: 0.6567 - val_loss: 1.5314 - val_accuracy: 0.6589\n",
      "Epoch 57/400\n",
      "277/277 - 2s - loss: 1.3669 - accuracy: 0.6639 - val_loss: 1.5194 - val_accuracy: 0.6619\n",
      "Epoch 58/400\n",
      "277/277 - 2s - loss: 1.3601 - accuracy: 0.6630 - val_loss: 1.5132 - val_accuracy: 0.6680\n",
      "Epoch 59/400\n",
      "277/277 - 2s - loss: 1.3506 - accuracy: 0.6670 - val_loss: 1.5027 - val_accuracy: 0.6619\n",
      "Epoch 60/400\n",
      "277/277 - 2s - loss: 1.3321 - accuracy: 0.6719 - val_loss: 1.4939 - val_accuracy: 0.6690\n",
      "Epoch 61/400\n",
      "277/277 - 2s - loss: 1.3183 - accuracy: 0.6727 - val_loss: 1.4882 - val_accuracy: 0.6701\n",
      "Epoch 62/400\n",
      "277/277 - 2s - loss: 1.3060 - accuracy: 0.6740 - val_loss: 1.4800 - val_accuracy: 0.6690\n",
      "Epoch 63/400\n",
      "277/277 - 2s - loss: 1.2920 - accuracy: 0.6802 - val_loss: 1.4740 - val_accuracy: 0.6701\n",
      "Epoch 64/400\n",
      "277/277 - 2s - loss: 1.2827 - accuracy: 0.6806 - val_loss: 1.4626 - val_accuracy: 0.6670\n",
      "Epoch 65/400\n",
      "277/277 - 2s - loss: 1.2834 - accuracy: 0.6834 - val_loss: 1.4565 - val_accuracy: 0.6751\n",
      "Epoch 66/400\n",
      "277/277 - 2s - loss: 1.2582 - accuracy: 0.6832 - val_loss: 1.4526 - val_accuracy: 0.6792\n",
      "Epoch 67/400\n",
      "277/277 - 2s - loss: 1.2510 - accuracy: 0.6899 - val_loss: 1.4433 - val_accuracy: 0.6751\n",
      "Epoch 68/400\n",
      "277/277 - 2s - loss: 1.2464 - accuracy: 0.6903 - val_loss: 1.4377 - val_accuracy: 0.6721\n",
      "Epoch 69/400\n",
      "277/277 - 2s - loss: 1.2371 - accuracy: 0.6916 - val_loss: 1.4313 - val_accuracy: 0.6802\n",
      "Epoch 70/400\n",
      "277/277 - 2s - loss: 1.2223 - accuracy: 0.6937 - val_loss: 1.4262 - val_accuracy: 0.6792\n",
      "Epoch 71/400\n",
      "277/277 - 2s - loss: 1.2075 - accuracy: 0.6991 - val_loss: 1.4150 - val_accuracy: 0.6792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/400\n",
      "277/277 - 2s - loss: 1.1992 - accuracy: 0.6959 - val_loss: 1.4131 - val_accuracy: 0.6802\n",
      "Epoch 73/400\n",
      "277/277 - 2s - loss: 1.1899 - accuracy: 0.6955 - val_loss: 1.4012 - val_accuracy: 0.6883\n",
      "Epoch 74/400\n",
      "277/277 - 2s - loss: 1.1939 - accuracy: 0.6942 - val_loss: 1.4017 - val_accuracy: 0.6853\n",
      "Epoch 75/400\n",
      "277/277 - 2s - loss: 1.1745 - accuracy: 0.7000 - val_loss: 1.3905 - val_accuracy: 0.6832\n",
      "Epoch 76/400\n",
      "277/277 - 2s - loss: 1.1639 - accuracy: 0.7049 - val_loss: 1.3903 - val_accuracy: 0.6812\n",
      "Epoch 77/400\n",
      "277/277 - 2s - loss: 1.1617 - accuracy: 0.7049 - val_loss: 1.3843 - val_accuracy: 0.6812\n",
      "Epoch 78/400\n",
      "277/277 - 2s - loss: 1.1397 - accuracy: 0.7118 - val_loss: 1.3787 - val_accuracy: 0.6863\n",
      "Epoch 79/400\n",
      "277/277 - 2s - loss: 1.1427 - accuracy: 0.7108 - val_loss: 1.3681 - val_accuracy: 0.6863\n",
      "Epoch 80/400\n",
      "277/277 - 2s - loss: 1.1273 - accuracy: 0.7136 - val_loss: 1.3679 - val_accuracy: 0.6802\n",
      "Epoch 81/400\n",
      "277/277 - 2s - loss: 1.1236 - accuracy: 0.7118 - val_loss: 1.3614 - val_accuracy: 0.6893\n",
      "Epoch 82/400\n",
      "277/277 - 2s - loss: 1.1101 - accuracy: 0.7148 - val_loss: 1.3537 - val_accuracy: 0.6843\n",
      "Epoch 83/400\n",
      "277/277 - 2s - loss: 1.1099 - accuracy: 0.7148 - val_loss: 1.3526 - val_accuracy: 0.6893\n",
      "Epoch 84/400\n",
      "277/277 - 2s - loss: 1.0996 - accuracy: 0.7252 - val_loss: 1.3501 - val_accuracy: 0.6893\n",
      "Epoch 85/400\n",
      "277/277 - 2s - loss: 1.0911 - accuracy: 0.7199 - val_loss: 1.3513 - val_accuracy: 0.6893\n",
      "Epoch 86/400\n",
      "277/277 - 2s - loss: 1.0817 - accuracy: 0.7230 - val_loss: 1.3417 - val_accuracy: 0.6883\n",
      "Epoch 87/400\n",
      "277/277 - 2s - loss: 1.0705 - accuracy: 0.7234 - val_loss: 1.3365 - val_accuracy: 0.6924\n",
      "Epoch 88/400\n",
      "277/277 - 2s - loss: 1.0603 - accuracy: 0.7295 - val_loss: 1.3350 - val_accuracy: 0.6924\n",
      "Epoch 89/400\n",
      "277/277 - 2s - loss: 1.0560 - accuracy: 0.7301 - val_loss: 1.3332 - val_accuracy: 0.6832\n",
      "Epoch 90/400\n",
      "277/277 - 2s - loss: 1.0563 - accuracy: 0.7312 - val_loss: 1.3301 - val_accuracy: 0.6985\n",
      "Epoch 91/400\n",
      "277/277 - 2s - loss: 1.0510 - accuracy: 0.7257 - val_loss: 1.3249 - val_accuracy: 0.6934\n",
      "Epoch 92/400\n",
      "277/277 - 2s - loss: 1.0333 - accuracy: 0.7341 - val_loss: 1.3268 - val_accuracy: 0.6954\n",
      "Epoch 93/400\n",
      "277/277 - 2s - loss: 1.0344 - accuracy: 0.7359 - val_loss: 1.3224 - val_accuracy: 0.6914\n",
      "Epoch 94/400\n",
      "277/277 - 2s - loss: 1.0320 - accuracy: 0.7365 - val_loss: 1.3140 - val_accuracy: 0.6944\n",
      "Epoch 95/400\n",
      "277/277 - 2s - loss: 1.0226 - accuracy: 0.7358 - val_loss: 1.3152 - val_accuracy: 0.6964\n",
      "Epoch 96/400\n",
      "277/277 - 2s - loss: 1.0172 - accuracy: 0.7399 - val_loss: 1.3120 - val_accuracy: 0.6954\n",
      "Epoch 97/400\n",
      "277/277 - 2s - loss: 1.0107 - accuracy: 0.7413 - val_loss: 1.3138 - val_accuracy: 0.6944\n",
      "Epoch 98/400\n",
      "277/277 - 2s - loss: 1.0097 - accuracy: 0.7453 - val_loss: 1.3065 - val_accuracy: 0.6964\n",
      "Epoch 99/400\n",
      "277/277 - 2s - loss: 0.9820 - accuracy: 0.7459 - val_loss: 1.3024 - val_accuracy: 0.6985\n",
      "Epoch 100/400\n",
      "277/277 - 2s - loss: 0.9973 - accuracy: 0.7470 - val_loss: 1.3052 - val_accuracy: 0.6944\n",
      "Epoch 101/400\n",
      "277/277 - 2s - loss: 0.9834 - accuracy: 0.7479 - val_loss: 1.3096 - val_accuracy: 0.6934\n",
      "Epoch 102/400\n",
      "277/277 - 2s - loss: 0.9871 - accuracy: 0.7475 - val_loss: 1.2956 - val_accuracy: 0.6995\n",
      "Epoch 103/400\n",
      "277/277 - 2s - loss: 0.9751 - accuracy: 0.7501 - val_loss: 1.2979 - val_accuracy: 0.6934\n",
      "Epoch 104/400\n",
      "277/277 - 2s - loss: 0.9630 - accuracy: 0.7556 - val_loss: 1.2939 - val_accuracy: 0.6995\n",
      "Epoch 105/400\n",
      "277/277 - 2s - loss: 0.9580 - accuracy: 0.7552 - val_loss: 1.2945 - val_accuracy: 0.6934\n",
      "Epoch 106/400\n",
      "277/277 - 2s - loss: 0.9561 - accuracy: 0.7532 - val_loss: 1.2862 - val_accuracy: 0.6995\n",
      "Epoch 107/400\n",
      "277/277 - 2s - loss: 0.9558 - accuracy: 0.7575 - val_loss: 1.2890 - val_accuracy: 0.6964\n",
      "Epoch 108/400\n",
      "277/277 - 2s - loss: 0.9486 - accuracy: 0.7571 - val_loss: 1.2860 - val_accuracy: 0.7036\n",
      "Epoch 109/400\n",
      "277/277 - 2s - loss: 0.9410 - accuracy: 0.7599 - val_loss: 1.2871 - val_accuracy: 0.7036\n",
      "Epoch 110/400\n",
      "277/277 - 2s - loss: 0.9341 - accuracy: 0.7636 - val_loss: 1.2784 - val_accuracy: 0.6975\n",
      "Epoch 111/400\n",
      "277/277 - 2s - loss: 0.9364 - accuracy: 0.7616 - val_loss: 1.2814 - val_accuracy: 0.6975\n",
      "Epoch 112/400\n",
      "277/277 - 2s - loss: 0.9216 - accuracy: 0.7668 - val_loss: 1.2781 - val_accuracy: 0.7025\n",
      "Epoch 113/400\n",
      "277/277 - 2s - loss: 0.9277 - accuracy: 0.7581 - val_loss: 1.2793 - val_accuracy: 0.7005\n",
      "Epoch 114/400\n",
      "277/277 - 2s - loss: 0.9111 - accuracy: 0.7665 - val_loss: 1.2750 - val_accuracy: 0.6944\n",
      "Epoch 115/400\n",
      "277/277 - 2s - loss: 0.9134 - accuracy: 0.7613 - val_loss: 1.2790 - val_accuracy: 0.6944\n",
      "Epoch 116/400\n",
      "277/277 - 2s - loss: 0.9107 - accuracy: 0.7648 - val_loss: 1.2702 - val_accuracy: 0.6985\n",
      "Epoch 117/400\n",
      "277/277 - 2s - loss: 0.8985 - accuracy: 0.7696 - val_loss: 1.2718 - val_accuracy: 0.6985\n",
      "Epoch 118/400\n",
      "277/277 - 2s - loss: 0.8984 - accuracy: 0.7681 - val_loss: 1.2727 - val_accuracy: 0.6995\n",
      "Epoch 119/400\n",
      "277/277 - 2s - loss: 0.9019 - accuracy: 0.7673 - val_loss: 1.2715 - val_accuracy: 0.6954\n",
      "Epoch 120/400\n",
      "277/277 - 2s - loss: 0.8969 - accuracy: 0.7683 - val_loss: 1.2673 - val_accuracy: 0.7025\n",
      "Epoch 121/400\n",
      "277/277 - 2s - loss: 0.8939 - accuracy: 0.7724 - val_loss: 1.2733 - val_accuracy: 0.7015\n",
      "Epoch 122/400\n",
      "277/277 - 2s - loss: 0.8894 - accuracy: 0.7712 - val_loss: 1.2744 - val_accuracy: 0.7005\n",
      "Epoch 123/400\n",
      "277/277 - 2s - loss: 0.8828 - accuracy: 0.7689 - val_loss: 1.2707 - val_accuracy: 0.6964\n",
      "Epoch 124/400\n",
      "277/277 - 2s - loss: 0.8900 - accuracy: 0.7714 - val_loss: 1.2770 - val_accuracy: 0.6975\n",
      "Epoch 125/400\n",
      "277/277 - 2s - loss: 0.8700 - accuracy: 0.7765 - val_loss: 1.2710 - val_accuracy: 0.7036\n",
      "Epoch 126/400\n",
      "277/277 - 2s - loss: 0.8719 - accuracy: 0.7706 - val_loss: 1.2616 - val_accuracy: 0.6975\n",
      "Epoch 127/400\n",
      "277/277 - 2s - loss: 0.8773 - accuracy: 0.7742 - val_loss: 1.2597 - val_accuracy: 0.7015\n",
      "Epoch 128/400\n",
      "277/277 - 2s - loss: 0.8627 - accuracy: 0.7732 - val_loss: 1.2621 - val_accuracy: 0.7025\n",
      "Epoch 129/400\n",
      "277/277 - 2s - loss: 0.8566 - accuracy: 0.7796 - val_loss: 1.2592 - val_accuracy: 0.6985\n",
      "Epoch 130/400\n",
      "277/277 - 2s - loss: 0.8513 - accuracy: 0.7785 - val_loss: 1.2687 - val_accuracy: 0.6975\n",
      "Epoch 131/400\n",
      "277/277 - 2s - loss: 0.8558 - accuracy: 0.7801 - val_loss: 1.2677 - val_accuracy: 0.6975\n",
      "Epoch 132/400\n",
      "277/277 - 2s - loss: 0.8280 - accuracy: 0.7879 - val_loss: 1.2678 - val_accuracy: 0.6975\n",
      "Epoch 133/400\n",
      "277/277 - 2s - loss: 0.8464 - accuracy: 0.7820 - val_loss: 1.2634 - val_accuracy: 0.6964\n",
      "Epoch 134/400\n",
      "277/277 - 2s - loss: 0.8346 - accuracy: 0.7827 - val_loss: 1.2591 - val_accuracy: 0.7005\n",
      "Epoch 135/400\n",
      "277/277 - 2s - loss: 0.8349 - accuracy: 0.7819 - val_loss: 1.2624 - val_accuracy: 0.6985\n",
      "Epoch 136/400\n",
      "277/277 - 2s - loss: 0.8345 - accuracy: 0.7801 - val_loss: 1.2597 - val_accuracy: 0.6934\n",
      "Epoch 137/400\n",
      "277/277 - 2s - loss: 0.8227 - accuracy: 0.7861 - val_loss: 1.2633 - val_accuracy: 0.6995\n",
      "Epoch 138/400\n",
      "277/277 - 2s - loss: 0.8208 - accuracy: 0.7858 - val_loss: 1.2636 - val_accuracy: 0.6964\n",
      "Epoch 139/400\n",
      "277/277 - 2s - loss: 0.8351 - accuracy: 0.7861 - val_loss: 1.2574 - val_accuracy: 0.6934\n",
      "Epoch 140/400\n",
      "277/277 - 2s - loss: 0.8288 - accuracy: 0.7828 - val_loss: 1.2533 - val_accuracy: 0.6985\n",
      "Epoch 141/400\n",
      "277/277 - 2s - loss: 0.8151 - accuracy: 0.7900 - val_loss: 1.2626 - val_accuracy: 0.7005\n",
      "Epoch 142/400\n",
      "277/277 - 2s - loss: 0.8247 - accuracy: 0.7809 - val_loss: 1.2492 - val_accuracy: 0.6995\n",
      "Epoch 143/400\n",
      "277/277 - 2s - loss: 0.8176 - accuracy: 0.7847 - val_loss: 1.2488 - val_accuracy: 0.7056\n",
      "Epoch 144/400\n",
      "277/277 - 2s - loss: 0.8162 - accuracy: 0.7875 - val_loss: 1.2606 - val_accuracy: 0.6954\n",
      "Epoch 145/400\n",
      "277/277 - 2s - loss: 0.8074 - accuracy: 0.7919 - val_loss: 1.2603 - val_accuracy: 0.7015\n",
      "Epoch 146/400\n",
      "277/277 - 2s - loss: 0.8030 - accuracy: 0.7942 - val_loss: 1.2600 - val_accuracy: 0.7015\n",
      "Epoch 147/400\n",
      "277/277 - 2s - loss: 0.8073 - accuracy: 0.7956 - val_loss: 1.2570 - val_accuracy: 0.7015\n",
      "Epoch 148/400\n",
      "277/277 - 2s - loss: 0.7892 - accuracy: 0.7958 - val_loss: 1.2513 - val_accuracy: 0.6995\n",
      "Epoch 149/400\n",
      "277/277 - 2s - loss: 0.7916 - accuracy: 0.7922 - val_loss: 1.2487 - val_accuracy: 0.7025\n",
      "Epoch 150/400\n",
      "277/277 - 2s - loss: 0.7849 - accuracy: 0.7968 - val_loss: 1.2498 - val_accuracy: 0.7036\n",
      "Epoch 151/400\n",
      "277/277 - 2s - loss: 0.7862 - accuracy: 0.7954 - val_loss: 1.2400 - val_accuracy: 0.7025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/400\n",
      "277/277 - 2s - loss: 0.8006 - accuracy: 0.7891 - val_loss: 1.2451 - val_accuracy: 0.6964\n",
      "Epoch 153/400\n",
      "277/277 - 2s - loss: 0.7896 - accuracy: 0.7922 - val_loss: 1.2355 - val_accuracy: 0.6975\n",
      "Epoch 154/400\n",
      "277/277 - 2s - loss: 0.7972 - accuracy: 0.7822 - val_loss: 1.2487 - val_accuracy: 0.7015\n",
      "Epoch 155/400\n",
      "277/277 - 2s - loss: 0.7727 - accuracy: 0.8002 - val_loss: 1.2508 - val_accuracy: 0.7015\n",
      "Epoch 156/400\n",
      "277/277 - 2s - loss: 0.7783 - accuracy: 0.7945 - val_loss: 1.2341 - val_accuracy: 0.7046\n",
      "Epoch 157/400\n",
      "277/277 - 2s - loss: 0.7836 - accuracy: 0.7926 - val_loss: 1.2412 - val_accuracy: 0.6995\n",
      "Epoch 158/400\n",
      "277/277 - 2s - loss: 0.7690 - accuracy: 0.7969 - val_loss: 1.2413 - val_accuracy: 0.6995\n",
      "Epoch 159/400\n",
      "277/277 - 2s - loss: 0.7797 - accuracy: 0.7954 - val_loss: 1.2387 - val_accuracy: 0.7056\n",
      "Epoch 160/400\n",
      "277/277 - 2s - loss: 0.7758 - accuracy: 0.7980 - val_loss: 1.2482 - val_accuracy: 0.7056\n",
      "Epoch 161/400\n",
      "277/277 - 2s - loss: 0.7664 - accuracy: 0.8011 - val_loss: 1.2587 - val_accuracy: 0.7005\n",
      "Epoch 162/400\n",
      "277/277 - 2s - loss: 0.7574 - accuracy: 0.8004 - val_loss: 1.2370 - val_accuracy: 0.7117\n",
      "Epoch 163/400\n",
      "277/277 - 2s - loss: 0.7572 - accuracy: 0.8041 - val_loss: 1.2345 - val_accuracy: 0.7076\n",
      "Epoch 164/400\n",
      "277/277 - 2s - loss: 0.7621 - accuracy: 0.7997 - val_loss: 1.2512 - val_accuracy: 0.7036\n",
      "Epoch 165/400\n",
      "277/277 - 2s - loss: 0.7453 - accuracy: 0.8019 - val_loss: 1.2542 - val_accuracy: 0.7036\n",
      "Epoch 166/400\n",
      "277/277 - 2s - loss: 0.7443 - accuracy: 0.8024 - val_loss: 1.2532 - val_accuracy: 0.7015\n",
      "Epoch 167/400\n",
      "277/277 - 2s - loss: 0.7461 - accuracy: 0.8014 - val_loss: 1.2580 - val_accuracy: 0.7015\n",
      "Epoch 168/400\n",
      "277/277 - 2s - loss: 0.7404 - accuracy: 0.8067 - val_loss: 1.2589 - val_accuracy: 0.7056\n",
      "Epoch 169/400\n",
      "277/277 - 2s - loss: 0.7404 - accuracy: 0.8076 - val_loss: 1.2588 - val_accuracy: 0.7066\n",
      "Epoch 170/400\n",
      "277/277 - 2s - loss: 0.7375 - accuracy: 0.8085 - val_loss: 1.2619 - val_accuracy: 0.7025\n",
      "Epoch 171/400\n",
      "277/277 - 2s - loss: 0.7509 - accuracy: 0.7970 - val_loss: 1.2573 - val_accuracy: 0.7046\n",
      "Epoch 172/400\n",
      "277/277 - 2s - loss: 0.7345 - accuracy: 0.8049 - val_loss: 1.2567 - val_accuracy: 0.7025\n",
      "Epoch 173/400\n",
      "277/277 - 2s - loss: 0.7328 - accuracy: 0.8029 - val_loss: 1.2591 - val_accuracy: 0.7015\n",
      "Epoch 174/400\n",
      "277/277 - 2s - loss: 0.7350 - accuracy: 0.8035 - val_loss: 1.2651 - val_accuracy: 0.7056\n",
      "Epoch 175/400\n",
      "277/277 - 2s - loss: 0.7431 - accuracy: 0.8040 - val_loss: 1.2598 - val_accuracy: 0.7036\n",
      "Epoch 176/400\n",
      "277/277 - 2s - loss: 0.7440 - accuracy: 0.7970 - val_loss: 1.2517 - val_accuracy: 0.7066\n",
      "Epoch 177/400\n",
      "277/277 - 2s - loss: 0.7278 - accuracy: 0.8058 - val_loss: 1.2591 - val_accuracy: 0.7025\n",
      "Epoch 178/400\n",
      "277/277 - 2s - loss: 0.7209 - accuracy: 0.8120 - val_loss: 1.2595 - val_accuracy: 0.7056\n",
      "Epoch 179/400\n",
      "277/277 - 2s - loss: 0.7264 - accuracy: 0.8081 - val_loss: 1.2486 - val_accuracy: 0.7036\n",
      "Epoch 180/400\n",
      "277/277 - 2s - loss: 0.7247 - accuracy: 0.8090 - val_loss: 1.2541 - val_accuracy: 0.7046\n",
      "Epoch 181/400\n",
      "277/277 - 2s - loss: 0.7123 - accuracy: 0.8085 - val_loss: 1.2579 - val_accuracy: 0.7046\n",
      "Epoch 182/400\n",
      "277/277 - 2s - loss: 0.7172 - accuracy: 0.8093 - val_loss: 1.2658 - val_accuracy: 0.6985\n",
      "Epoch 183/400\n",
      "277/277 - 2s - loss: 0.7138 - accuracy: 0.8094 - val_loss: 1.2699 - val_accuracy: 0.7025\n",
      "Epoch 184/400\n",
      "277/277 - 2s - loss: 0.7144 - accuracy: 0.8084 - val_loss: 1.2573 - val_accuracy: 0.7056\n",
      "Epoch 185/400\n",
      "277/277 - 2s - loss: 0.7150 - accuracy: 0.8082 - val_loss: 1.2487 - val_accuracy: 0.7036\n",
      "Epoch 186/400\n",
      "277/277 - 2s - loss: 0.7127 - accuracy: 0.8079 - val_loss: 1.2767 - val_accuracy: 0.7015\n",
      "Epoch 187/400\n",
      "277/277 - 2s - loss: 0.7103 - accuracy: 0.8118 - val_loss: 1.2606 - val_accuracy: 0.7005\n",
      "Epoch 188/400\n",
      "277/277 - 2s - loss: 0.7123 - accuracy: 0.8040 - val_loss: 1.2566 - val_accuracy: 0.7056\n",
      "Epoch 189/400\n",
      "277/277 - 2s - loss: 0.6924 - accuracy: 0.8127 - val_loss: 1.2622 - val_accuracy: 0.7056\n",
      "Epoch 190/400\n",
      "277/277 - 2s - loss: 0.7075 - accuracy: 0.8094 - val_loss: 1.2553 - val_accuracy: 0.7076\n",
      "Epoch 191/400\n",
      "277/277 - 2s - loss: 0.7105 - accuracy: 0.8028 - val_loss: 1.2572 - val_accuracy: 0.7036\n",
      "Epoch 192/400\n",
      "277/277 - 2s - loss: 0.7030 - accuracy: 0.8091 - val_loss: 1.2559 - val_accuracy: 0.7086\n",
      "Epoch 193/400\n",
      "277/277 - 2s - loss: 0.7018 - accuracy: 0.8073 - val_loss: 1.2633 - val_accuracy: 0.7005\n",
      "Epoch 194/400\n",
      "277/277 - 2s - loss: 0.6979 - accuracy: 0.8124 - val_loss: 1.2559 - val_accuracy: 0.7096\n",
      "Epoch 195/400\n",
      "277/277 - 2s - loss: 0.6822 - accuracy: 0.8186 - val_loss: 1.2622 - val_accuracy: 0.7005\n",
      "Epoch 196/400\n",
      "277/277 - 2s - loss: 0.7022 - accuracy: 0.8070 - val_loss: 1.2561 - val_accuracy: 0.7046\n",
      "Epoch 197/400\n",
      "277/277 - 2s - loss: 0.6977 - accuracy: 0.8077 - val_loss: 1.2716 - val_accuracy: 0.7025\n",
      "Epoch 198/400\n",
      "277/277 - 2s - loss: 0.6926 - accuracy: 0.8132 - val_loss: 1.2743 - val_accuracy: 0.6995\n",
      "Epoch 199/400\n",
      "277/277 - 2s - loss: 0.6843 - accuracy: 0.8124 - val_loss: 1.2646 - val_accuracy: 0.7056\n",
      "Epoch 200/400\n",
      "277/277 - 2s - loss: 0.7009 - accuracy: 0.8073 - val_loss: 1.2662 - val_accuracy: 0.7056\n",
      "Epoch 201/400\n",
      "277/277 - 2s - loss: 0.6945 - accuracy: 0.8137 - val_loss: 1.2636 - val_accuracy: 0.7096\n",
      "Epoch 202/400\n",
      "277/277 - 2s - loss: 0.6803 - accuracy: 0.8188 - val_loss: 1.2795 - val_accuracy: 0.7036\n",
      "Epoch 203/400\n",
      "277/277 - 2s - loss: 0.6861 - accuracy: 0.8153 - val_loss: 1.2796 - val_accuracy: 0.7066\n",
      "Epoch 204/400\n",
      "277/277 - 2s - loss: 0.6860 - accuracy: 0.8099 - val_loss: 1.2877 - val_accuracy: 0.7056\n",
      "Epoch 205/400\n",
      "277/277 - 2s - loss: 0.6819 - accuracy: 0.8127 - val_loss: 1.2778 - val_accuracy: 0.7066\n",
      "Epoch 206/400\n",
      "277/277 - 2s - loss: 0.6769 - accuracy: 0.8194 - val_loss: 1.2850 - val_accuracy: 0.7066\n",
      "Epoch 207/400\n",
      "277/277 - 2s - loss: 0.6780 - accuracy: 0.8150 - val_loss: 1.2881 - val_accuracy: 0.7076\n",
      "Epoch 208/400\n",
      "277/277 - 2s - loss: 0.6829 - accuracy: 0.8119 - val_loss: 1.2952 - val_accuracy: 0.7056\n",
      "Epoch 209/400\n",
      "277/277 - 2s - loss: 0.6700 - accuracy: 0.8154 - val_loss: 1.2933 - val_accuracy: 0.7005\n",
      "Epoch 210/400\n",
      "277/277 - 2s - loss: 0.6671 - accuracy: 0.8163 - val_loss: 1.2862 - val_accuracy: 0.7005\n",
      "Epoch 211/400\n",
      "277/277 - 2s - loss: 0.6794 - accuracy: 0.8102 - val_loss: 1.2820 - val_accuracy: 0.7036\n",
      "Epoch 212/400\n",
      "277/277 - 2s - loss: 0.6639 - accuracy: 0.8213 - val_loss: 1.2842 - val_accuracy: 0.7056\n",
      "Epoch 213/400\n",
      "277/277 - 2s - loss: 0.6692 - accuracy: 0.8203 - val_loss: 1.2916 - val_accuracy: 0.7005\n",
      "Epoch 214/400\n",
      "277/277 - 2s - loss: 0.6588 - accuracy: 0.8180 - val_loss: 1.2904 - val_accuracy: 0.7015\n",
      "Epoch 215/400\n",
      "277/277 - 2s - loss: 0.6610 - accuracy: 0.8211 - val_loss: 1.2922 - val_accuracy: 0.7036\n",
      "Epoch 216/400\n",
      "277/277 - 2s - loss: 0.6595 - accuracy: 0.8205 - val_loss: 1.2935 - val_accuracy: 0.7046\n",
      "Epoch 217/400\n",
      "277/277 - 2s - loss: 0.6593 - accuracy: 0.8189 - val_loss: 1.2977 - val_accuracy: 0.7056\n",
      "Epoch 218/400\n",
      "277/277 - 2s - loss: 0.6708 - accuracy: 0.8168 - val_loss: 1.2844 - val_accuracy: 0.7086\n",
      "Epoch 219/400\n",
      "277/277 - 2s - loss: 0.6647 - accuracy: 0.8212 - val_loss: 1.2935 - val_accuracy: 0.7066\n",
      "Epoch 220/400\n",
      "277/277 - 2s - loss: 0.6638 - accuracy: 0.8204 - val_loss: 1.3022 - val_accuracy: 0.7066\n",
      "Epoch 221/400\n",
      "277/277 - 2s - loss: 0.6608 - accuracy: 0.8177 - val_loss: 1.2846 - val_accuracy: 0.7107\n",
      "Epoch 222/400\n",
      "277/277 - 2s - loss: 0.6690 - accuracy: 0.8160 - val_loss: 1.2924 - val_accuracy: 0.7107\n",
      "Epoch 223/400\n",
      "277/277 - 2s - loss: 0.6459 - accuracy: 0.8252 - val_loss: 1.3007 - val_accuracy: 0.7025\n",
      "Epoch 224/400\n",
      "277/277 - 2s - loss: 0.6517 - accuracy: 0.8237 - val_loss: 1.3027 - val_accuracy: 0.7096\n",
      "Epoch 225/400\n",
      "277/277 - 2s - loss: 0.6583 - accuracy: 0.8197 - val_loss: 1.3035 - val_accuracy: 0.7036\n",
      "Epoch 226/400\n",
      "277/277 - 2s - loss: 0.6574 - accuracy: 0.8178 - val_loss: 1.3028 - val_accuracy: 0.7005\n",
      "Epoch 227/400\n",
      "277/277 - 2s - loss: 0.6600 - accuracy: 0.8155 - val_loss: 1.3110 - val_accuracy: 0.6985\n",
      "Epoch 228/400\n",
      "277/277 - 2s - loss: 0.6520 - accuracy: 0.8170 - val_loss: 1.3073 - val_accuracy: 0.7015\n",
      "Epoch 229/400\n",
      "277/277 - 2s - loss: 0.6549 - accuracy: 0.8197 - val_loss: 1.3038 - val_accuracy: 0.6975\n",
      "Epoch 230/400\n",
      "277/277 - 2s - loss: 0.6467 - accuracy: 0.8200 - val_loss: 1.3059 - val_accuracy: 0.6995\n",
      "Epoch 231/400\n",
      "277/277 - 2s - loss: 0.6436 - accuracy: 0.8205 - val_loss: 1.2950 - val_accuracy: 0.7096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/400\n",
      "277/277 - 2s - loss: 0.6533 - accuracy: 0.8155 - val_loss: 1.3005 - val_accuracy: 0.7066\n",
      "Epoch 233/400\n",
      "277/277 - 2s - loss: 0.6407 - accuracy: 0.8198 - val_loss: 1.3147 - val_accuracy: 0.7025\n",
      "Epoch 234/400\n",
      "277/277 - 2s - loss: 0.6493 - accuracy: 0.8222 - val_loss: 1.3156 - val_accuracy: 0.7036\n",
      "Epoch 235/400\n",
      "277/277 - 2s - loss: 0.6427 - accuracy: 0.8250 - val_loss: 1.3020 - val_accuracy: 0.6985\n",
      "Epoch 236/400\n",
      "277/277 - 2s - loss: 0.6369 - accuracy: 0.8221 - val_loss: 1.3102 - val_accuracy: 0.7036\n",
      "Epoch 237/400\n",
      "277/277 - 2s - loss: 0.6358 - accuracy: 0.8241 - val_loss: 1.3222 - val_accuracy: 0.6975\n",
      "Epoch 238/400\n",
      "277/277 - 2s - loss: 0.6395 - accuracy: 0.8252 - val_loss: 1.3235 - val_accuracy: 0.6985\n",
      "Epoch 239/400\n",
      "277/277 - 2s - loss: 0.6413 - accuracy: 0.8220 - val_loss: 1.3274 - val_accuracy: 0.7005\n",
      "Epoch 240/400\n",
      "277/277 - 2s - loss: 0.6430 - accuracy: 0.8251 - val_loss: 1.3193 - val_accuracy: 0.7015\n",
      "Epoch 241/400\n",
      "277/277 - 2s - loss: 0.6400 - accuracy: 0.8246 - val_loss: 1.3164 - val_accuracy: 0.7025\n",
      "Epoch 242/400\n",
      "277/277 - 2s - loss: 0.6293 - accuracy: 0.8261 - val_loss: 1.3046 - val_accuracy: 0.7096\n",
      "Epoch 243/400\n",
      "277/277 - 2s - loss: 0.6402 - accuracy: 0.8204 - val_loss: 1.3109 - val_accuracy: 0.7086\n",
      "Epoch 244/400\n",
      "277/277 - 2s - loss: 0.6355 - accuracy: 0.8223 - val_loss: 1.2975 - val_accuracy: 0.7096\n",
      "Epoch 245/400\n",
      "277/277 - 2s - loss: 0.6267 - accuracy: 0.8230 - val_loss: 1.3085 - val_accuracy: 0.7076\n",
      "Epoch 246/400\n",
      "277/277 - 2s - loss: 0.6200 - accuracy: 0.8295 - val_loss: 1.3071 - val_accuracy: 0.7036\n",
      "Epoch 247/400\n",
      "277/277 - 2s - loss: 0.6390 - accuracy: 0.8234 - val_loss: 1.3046 - val_accuracy: 0.7086\n",
      "Epoch 248/400\n",
      "277/277 - 2s - loss: 0.6307 - accuracy: 0.8256 - val_loss: 1.3184 - val_accuracy: 0.6975\n",
      "Epoch 249/400\n",
      "277/277 - 2s - loss: 0.6397 - accuracy: 0.8241 - val_loss: 1.3325 - val_accuracy: 0.7015\n",
      "Epoch 250/400\n",
      "277/277 - 2s - loss: 0.6185 - accuracy: 0.8238 - val_loss: 1.3207 - val_accuracy: 0.6964\n",
      "Epoch 251/400\n",
      "277/277 - 2s - loss: 0.6253 - accuracy: 0.8238 - val_loss: 1.3149 - val_accuracy: 0.7066\n",
      "Epoch 252/400\n",
      "277/277 - 2s - loss: 0.6256 - accuracy: 0.8232 - val_loss: 1.3118 - val_accuracy: 0.7036\n",
      "Epoch 253/400\n",
      "277/277 - 2s - loss: 0.6182 - accuracy: 0.8305 - val_loss: 1.3227 - val_accuracy: 0.7025\n",
      "Epoch 254/400\n",
      "277/277 - 2s - loss: 0.6262 - accuracy: 0.8233 - val_loss: 1.3378 - val_accuracy: 0.6985\n",
      "Epoch 255/400\n",
      "277/277 - 2s - loss: 0.6285 - accuracy: 0.8263 - val_loss: 1.3264 - val_accuracy: 0.7046\n",
      "Epoch 256/400\n",
      "277/277 - 2s - loss: 0.6315 - accuracy: 0.8258 - val_loss: 1.3263 - val_accuracy: 0.7086\n",
      "Epoch 257/400\n",
      "277/277 - 2s - loss: 0.6169 - accuracy: 0.8269 - val_loss: 1.3192 - val_accuracy: 0.7015\n",
      "Epoch 258/400\n",
      "277/277 - 2s - loss: 0.6184 - accuracy: 0.8275 - val_loss: 1.3370 - val_accuracy: 0.7015\n",
      "Epoch 259/400\n",
      "277/277 - 2s - loss: 0.6221 - accuracy: 0.8267 - val_loss: 1.3270 - val_accuracy: 0.7086\n",
      "Epoch 260/400\n",
      "277/277 - 2s - loss: 0.6236 - accuracy: 0.8270 - val_loss: 1.3368 - val_accuracy: 0.7025\n",
      "Epoch 261/400\n",
      "277/277 - 2s - loss: 0.6141 - accuracy: 0.8317 - val_loss: 1.3284 - val_accuracy: 0.7005\n",
      "Epoch 262/400\n",
      "277/277 - 2s - loss: 0.6175 - accuracy: 0.8246 - val_loss: 1.3295 - val_accuracy: 0.7036\n",
      "Epoch 263/400\n",
      "277/277 - 2s - loss: 0.6225 - accuracy: 0.8229 - val_loss: 1.3288 - val_accuracy: 0.6944\n",
      "Epoch 264/400\n",
      "277/277 - 2s - loss: 0.6115 - accuracy: 0.8284 - val_loss: 1.3313 - val_accuracy: 0.7005\n",
      "Epoch 265/400\n",
      "277/277 - 2s - loss: 0.6114 - accuracy: 0.8269 - val_loss: 1.3264 - val_accuracy: 0.7046\n",
      "Epoch 266/400\n",
      "277/277 - 2s - loss: 0.6135 - accuracy: 0.8251 - val_loss: 1.3392 - val_accuracy: 0.6985\n",
      "Epoch 267/400\n",
      "277/277 - 2s - loss: 0.6011 - accuracy: 0.8310 - val_loss: 1.3397 - val_accuracy: 0.7036\n",
      "Epoch 268/400\n",
      "277/277 - 2s - loss: 0.6022 - accuracy: 0.8273 - val_loss: 1.3365 - val_accuracy: 0.7005\n",
      "Epoch 269/400\n",
      "277/277 - 2s - loss: 0.6117 - accuracy: 0.8267 - val_loss: 1.3437 - val_accuracy: 0.6985\n",
      "Epoch 270/400\n",
      "277/277 - 2s - loss: 0.6198 - accuracy: 0.8264 - val_loss: 1.3522 - val_accuracy: 0.7015\n",
      "Epoch 271/400\n",
      "277/277 - 2s - loss: 0.5989 - accuracy: 0.8337 - val_loss: 1.3461 - val_accuracy: 0.6964\n",
      "Epoch 272/400\n",
      "277/277 - 2s - loss: 0.6110 - accuracy: 0.8258 - val_loss: 1.3520 - val_accuracy: 0.7015\n",
      "Epoch 273/400\n",
      "277/277 - 2s - loss: 0.6049 - accuracy: 0.8269 - val_loss: 1.3557 - val_accuracy: 0.7005\n",
      "Epoch 274/400\n",
      "277/277 - 2s - loss: 0.6057 - accuracy: 0.8295 - val_loss: 1.3396 - val_accuracy: 0.7056\n",
      "Epoch 275/400\n",
      "277/277 - 2s - loss: 0.5902 - accuracy: 0.8313 - val_loss: 1.3447 - val_accuracy: 0.7066\n",
      "Epoch 276/400\n",
      "277/277 - 2s - loss: 0.5980 - accuracy: 0.8312 - val_loss: 1.3478 - val_accuracy: 0.6985\n",
      "Epoch 277/400\n",
      "277/277 - 2s - loss: 0.6037 - accuracy: 0.8300 - val_loss: 1.3503 - val_accuracy: 0.7005\n",
      "Epoch 278/400\n",
      "277/277 - 2s - loss: 0.5984 - accuracy: 0.8305 - val_loss: 1.3625 - val_accuracy: 0.7056\n",
      "Epoch 279/400\n",
      "277/277 - 2s - loss: 0.6075 - accuracy: 0.8257 - val_loss: 1.3569 - val_accuracy: 0.6964\n",
      "Epoch 280/400\n",
      "277/277 - 2s - loss: 0.5917 - accuracy: 0.8361 - val_loss: 1.3534 - val_accuracy: 0.6975\n",
      "Epoch 281/400\n",
      "277/277 - 2s - loss: 0.5967 - accuracy: 0.8322 - val_loss: 1.3624 - val_accuracy: 0.6954\n",
      "Epoch 282/400\n",
      "277/277 - 2s - loss: 0.6103 - accuracy: 0.8276 - val_loss: 1.3425 - val_accuracy: 0.7025\n",
      "Epoch 283/400\n",
      "277/277 - 2s - loss: 0.6131 - accuracy: 0.8278 - val_loss: 1.3506 - val_accuracy: 0.7005\n",
      "Epoch 284/400\n",
      "277/277 - 2s - loss: 0.6067 - accuracy: 0.8285 - val_loss: 1.3540 - val_accuracy: 0.7005\n",
      "Epoch 285/400\n",
      "277/277 - 2s - loss: 0.5996 - accuracy: 0.8307 - val_loss: 1.3596 - val_accuracy: 0.6985\n",
      "Epoch 286/400\n",
      "277/277 - 2s - loss: 0.5847 - accuracy: 0.8328 - val_loss: 1.3558 - val_accuracy: 0.7005\n",
      "Epoch 287/400\n",
      "277/277 - 2s - loss: 0.6098 - accuracy: 0.8294 - val_loss: 1.3627 - val_accuracy: 0.6975\n",
      "Epoch 288/400\n",
      "277/277 - 2s - loss: 0.5880 - accuracy: 0.8355 - val_loss: 1.3657 - val_accuracy: 0.6904\n",
      "Epoch 289/400\n",
      "277/277 - 2s - loss: 0.5905 - accuracy: 0.8334 - val_loss: 1.3831 - val_accuracy: 0.6924\n",
      "Epoch 290/400\n",
      "277/277 - 2s - loss: 0.5900 - accuracy: 0.8291 - val_loss: 1.3715 - val_accuracy: 0.6964\n",
      "Epoch 291/400\n",
      "277/277 - 2s - loss: 0.5886 - accuracy: 0.8315 - val_loss: 1.3685 - val_accuracy: 0.7015\n",
      "Epoch 292/400\n",
      "277/277 - 2s - loss: 0.5843 - accuracy: 0.8348 - val_loss: 1.3615 - val_accuracy: 0.7025\n",
      "Epoch 293/400\n",
      "277/277 - 2s - loss: 0.6001 - accuracy: 0.8267 - val_loss: 1.3604 - val_accuracy: 0.6964\n",
      "Epoch 294/400\n",
      "277/277 - 2s - loss: 0.5893 - accuracy: 0.8335 - val_loss: 1.3738 - val_accuracy: 0.6975\n",
      "Epoch 295/400\n",
      "277/277 - 2s - loss: 0.5779 - accuracy: 0.8371 - val_loss: 1.3682 - val_accuracy: 0.7005\n",
      "Epoch 296/400\n",
      "277/277 - 2s - loss: 0.5951 - accuracy: 0.8322 - val_loss: 1.3778 - val_accuracy: 0.6944\n",
      "Epoch 297/400\n",
      "277/277 - 2s - loss: 0.5766 - accuracy: 0.8350 - val_loss: 1.3790 - val_accuracy: 0.6964\n",
      "Epoch 298/400\n",
      "277/277 - 2s - loss: 0.5912 - accuracy: 0.8338 - val_loss: 1.3860 - val_accuracy: 0.6995\n",
      "Epoch 299/400\n",
      "277/277 - 2s - loss: 0.5761 - accuracy: 0.8360 - val_loss: 1.3826 - val_accuracy: 0.6954\n",
      "Epoch 300/400\n",
      "277/277 - 2s - loss: 0.5771 - accuracy: 0.8379 - val_loss: 1.3704 - val_accuracy: 0.7015\n",
      "Epoch 301/400\n",
      "277/277 - 2s - loss: 0.5845 - accuracy: 0.8365 - val_loss: 1.3763 - val_accuracy: 0.7015\n",
      "Epoch 302/400\n",
      "277/277 - 2s - loss: 0.5913 - accuracy: 0.8329 - val_loss: 1.3796 - val_accuracy: 0.6964\n",
      "Epoch 303/400\n",
      "277/277 - 2s - loss: 0.5938 - accuracy: 0.8311 - val_loss: 1.3741 - val_accuracy: 0.7015\n",
      "Epoch 304/400\n",
      "277/277 - 2s - loss: 0.5873 - accuracy: 0.8324 - val_loss: 1.3840 - val_accuracy: 0.7036\n",
      "Epoch 305/400\n",
      "277/277 - 2s - loss: 0.5959 - accuracy: 0.8260 - val_loss: 1.3911 - val_accuracy: 0.6924\n",
      "Epoch 306/400\n",
      "277/277 - 2s - loss: 0.5870 - accuracy: 0.8326 - val_loss: 1.3818 - val_accuracy: 0.6924\n",
      "Epoch 307/400\n",
      "277/277 - 2s - loss: 0.5931 - accuracy: 0.8290 - val_loss: 1.3826 - val_accuracy: 0.6995\n",
      "Epoch 308/400\n",
      "277/277 - 2s - loss: 0.5808 - accuracy: 0.8312 - val_loss: 1.3834 - val_accuracy: 0.7015\n",
      "Epoch 309/400\n",
      "277/277 - 2s - loss: 0.5848 - accuracy: 0.8331 - val_loss: 1.3712 - val_accuracy: 0.7005\n",
      "Epoch 310/400\n",
      "277/277 - 2s - loss: 0.5773 - accuracy: 0.8363 - val_loss: 1.3691 - val_accuracy: 0.7056\n",
      "Epoch 311/400\n",
      "277/277 - 2s - loss: 0.5759 - accuracy: 0.8346 - val_loss: 1.3782 - val_accuracy: 0.6975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 312/400\n",
      "277/277 - 2s - loss: 0.5750 - accuracy: 0.8363 - val_loss: 1.3786 - val_accuracy: 0.7005\n",
      "Epoch 313/400\n",
      "277/277 - 2s - loss: 0.5924 - accuracy: 0.8268 - val_loss: 1.3836 - val_accuracy: 0.7015\n",
      "Epoch 314/400\n",
      "277/277 - 2s - loss: 0.5694 - accuracy: 0.8386 - val_loss: 1.3858 - val_accuracy: 0.6995\n",
      "Epoch 315/400\n",
      "277/277 - 2s - loss: 0.5801 - accuracy: 0.8364 - val_loss: 1.3880 - val_accuracy: 0.6995\n",
      "Epoch 316/400\n",
      "277/277 - 2s - loss: 0.5705 - accuracy: 0.8379 - val_loss: 1.3857 - val_accuracy: 0.7015\n",
      "Epoch 317/400\n",
      "277/277 - 2s - loss: 0.5701 - accuracy: 0.8395 - val_loss: 1.3843 - val_accuracy: 0.7025\n",
      "Epoch 318/400\n",
      "277/277 - 2s - loss: 0.5625 - accuracy: 0.8380 - val_loss: 1.3935 - val_accuracy: 0.6964\n",
      "Epoch 319/400\n",
      "277/277 - 2s - loss: 0.5698 - accuracy: 0.8359 - val_loss: 1.3841 - val_accuracy: 0.6944\n",
      "Epoch 320/400\n",
      "277/277 - 2s - loss: 0.5751 - accuracy: 0.8331 - val_loss: 1.3943 - val_accuracy: 0.6944\n",
      "Epoch 321/400\n",
      "277/277 - 2s - loss: 0.5805 - accuracy: 0.8347 - val_loss: 1.4021 - val_accuracy: 0.6964\n",
      "Epoch 322/400\n",
      "277/277 - 2s - loss: 0.5772 - accuracy: 0.8368 - val_loss: 1.3949 - val_accuracy: 0.6995\n",
      "Epoch 323/400\n",
      "277/277 - 2s - loss: 0.5715 - accuracy: 0.8420 - val_loss: 1.3960 - val_accuracy: 0.7056\n",
      "Epoch 324/400\n",
      "277/277 - 2s - loss: 0.5868 - accuracy: 0.8316 - val_loss: 1.3851 - val_accuracy: 0.7015\n",
      "Epoch 325/400\n",
      "277/277 - 2s - loss: 0.5669 - accuracy: 0.8390 - val_loss: 1.3876 - val_accuracy: 0.6995\n",
      "Epoch 326/400\n",
      "277/277 - 2s - loss: 0.5774 - accuracy: 0.8329 - val_loss: 1.3748 - val_accuracy: 0.6995\n",
      "Epoch 327/400\n",
      "277/277 - 2s - loss: 0.5756 - accuracy: 0.8334 - val_loss: 1.3929 - val_accuracy: 0.6944\n",
      "Epoch 328/400\n",
      "277/277 - 2s - loss: 0.5757 - accuracy: 0.8364 - val_loss: 1.3792 - val_accuracy: 0.7005\n",
      "Epoch 329/400\n",
      "277/277 - 2s - loss: 0.5755 - accuracy: 0.8361 - val_loss: 1.4004 - val_accuracy: 0.6985\n",
      "Epoch 330/400\n",
      "277/277 - 2s - loss: 0.5761 - accuracy: 0.8364 - val_loss: 1.4009 - val_accuracy: 0.6944\n",
      "Epoch 331/400\n",
      "277/277 - 2s - loss: 0.5681 - accuracy: 0.8380 - val_loss: 1.3937 - val_accuracy: 0.6975\n",
      "Epoch 332/400\n",
      "277/277 - 2s - loss: 0.5763 - accuracy: 0.8351 - val_loss: 1.4063 - val_accuracy: 0.6944\n",
      "Epoch 333/400\n",
      "277/277 - 2s - loss: 0.5770 - accuracy: 0.8328 - val_loss: 1.3958 - val_accuracy: 0.6954\n",
      "Epoch 334/400\n",
      "277/277 - 2s - loss: 0.5630 - accuracy: 0.8372 - val_loss: 1.4135 - val_accuracy: 0.6975\n",
      "Epoch 335/400\n",
      "277/277 - 2s - loss: 0.5700 - accuracy: 0.8345 - val_loss: 1.4042 - val_accuracy: 0.6954\n",
      "Epoch 336/400\n",
      "277/277 - 2s - loss: 0.5725 - accuracy: 0.8362 - val_loss: 1.4204 - val_accuracy: 0.6904\n",
      "Epoch 337/400\n",
      "277/277 - 2s - loss: 0.5733 - accuracy: 0.8351 - val_loss: 1.4039 - val_accuracy: 0.6934\n",
      "Epoch 338/400\n",
      "277/277 - 2s - loss: 0.5620 - accuracy: 0.8390 - val_loss: 1.4012 - val_accuracy: 0.6975\n",
      "Epoch 339/400\n",
      "277/277 - 2s - loss: 0.5746 - accuracy: 0.8309 - val_loss: 1.4058 - val_accuracy: 0.7005\n",
      "Epoch 340/400\n",
      "277/277 - 2s - loss: 0.5729 - accuracy: 0.8347 - val_loss: 1.4005 - val_accuracy: 0.6995\n",
      "Epoch 341/400\n",
      "277/277 - 2s - loss: 0.5616 - accuracy: 0.8363 - val_loss: 1.3935 - val_accuracy: 0.7005\n",
      "Epoch 342/400\n",
      "277/277 - 2s - loss: 0.5664 - accuracy: 0.8387 - val_loss: 1.3978 - val_accuracy: 0.7005\n",
      "Epoch 343/400\n",
      "277/277 - 2s - loss: 0.5774 - accuracy: 0.8289 - val_loss: 1.4055 - val_accuracy: 0.6964\n",
      "Epoch 344/400\n",
      "277/277 - 2s - loss: 0.5538 - accuracy: 0.8432 - val_loss: 1.3963 - val_accuracy: 0.6985\n",
      "Epoch 345/400\n",
      "277/277 - 2s - loss: 0.5621 - accuracy: 0.8388 - val_loss: 1.4016 - val_accuracy: 0.6985\n",
      "Epoch 346/400\n",
      "277/277 - 2s - loss: 0.5683 - accuracy: 0.8329 - val_loss: 1.4037 - val_accuracy: 0.6954\n",
      "Epoch 347/400\n",
      "277/277 - 2s - loss: 0.5612 - accuracy: 0.8379 - val_loss: 1.3999 - val_accuracy: 0.6964\n",
      "Epoch 348/400\n",
      "277/277 - 2s - loss: 0.5727 - accuracy: 0.8356 - val_loss: 1.4160 - val_accuracy: 0.6975\n",
      "Epoch 349/400\n",
      "277/277 - 2s - loss: 0.5725 - accuracy: 0.8415 - val_loss: 1.4175 - val_accuracy: 0.6964\n",
      "Epoch 350/400\n",
      "277/277 - 2s - loss: 0.5625 - accuracy: 0.8368 - val_loss: 1.4213 - val_accuracy: 0.6985\n",
      "Epoch 351/400\n",
      "277/277 - 2s - loss: 0.5559 - accuracy: 0.8405 - val_loss: 1.4265 - val_accuracy: 0.6954\n",
      "Epoch 352/400\n",
      "277/277 - 2s - loss: 0.5671 - accuracy: 0.8350 - val_loss: 1.4175 - val_accuracy: 0.6964\n",
      "Epoch 353/400\n",
      "277/277 - 2s - loss: 0.5633 - accuracy: 0.8366 - val_loss: 1.4328 - val_accuracy: 0.6954\n",
      "Epoch 354/400\n",
      "277/277 - 2s - loss: 0.5655 - accuracy: 0.8401 - val_loss: 1.4318 - val_accuracy: 0.6944\n",
      "Epoch 355/400\n",
      "277/277 - 2s - loss: 0.5626 - accuracy: 0.8353 - val_loss: 1.4380 - val_accuracy: 0.6964\n",
      "Epoch 356/400\n",
      "277/277 - 2s - loss: 0.5582 - accuracy: 0.8352 - val_loss: 1.4220 - val_accuracy: 0.7036\n",
      "Epoch 357/400\n",
      "277/277 - 2s - loss: 0.5564 - accuracy: 0.8335 - val_loss: 1.4401 - val_accuracy: 0.6954\n",
      "Epoch 358/400\n",
      "277/277 - 2s - loss: 0.5591 - accuracy: 0.8399 - val_loss: 1.4248 - val_accuracy: 0.6985\n",
      "Epoch 359/400\n",
      "277/277 - 2s - loss: 0.5513 - accuracy: 0.8405 - val_loss: 1.4224 - val_accuracy: 0.6954\n",
      "Epoch 360/400\n",
      "277/277 - 2s - loss: 0.5567 - accuracy: 0.8396 - val_loss: 1.4188 - val_accuracy: 0.6995\n",
      "Epoch 361/400\n",
      "277/277 - 2s - loss: 0.5568 - accuracy: 0.8417 - val_loss: 1.4337 - val_accuracy: 0.6893\n",
      "Epoch 362/400\n",
      "277/277 - 2s - loss: 0.5501 - accuracy: 0.8408 - val_loss: 1.4337 - val_accuracy: 0.6904\n",
      "Epoch 363/400\n",
      "277/277 - 2s - loss: 0.5625 - accuracy: 0.8338 - val_loss: 1.4177 - val_accuracy: 0.6995\n",
      "Epoch 364/400\n",
      "277/277 - 2s - loss: 0.5511 - accuracy: 0.8424 - val_loss: 1.4212 - val_accuracy: 0.6985\n",
      "Epoch 365/400\n",
      "277/277 - 2s - loss: 0.5551 - accuracy: 0.8408 - val_loss: 1.4312 - val_accuracy: 0.6914\n",
      "Epoch 366/400\n",
      "277/277 - 2s - loss: 0.5724 - accuracy: 0.8350 - val_loss: 1.4291 - val_accuracy: 0.6964\n",
      "Epoch 367/400\n",
      "277/277 - 2s - loss: 0.5471 - accuracy: 0.8412 - val_loss: 1.4345 - val_accuracy: 0.6914\n",
      "Epoch 368/400\n",
      "277/277 - 2s - loss: 0.5507 - accuracy: 0.8425 - val_loss: 1.4226 - val_accuracy: 0.6985\n",
      "Epoch 369/400\n",
      "277/277 - 2s - loss: 0.5622 - accuracy: 0.8368 - val_loss: 1.4301 - val_accuracy: 0.6964\n",
      "Epoch 370/400\n",
      "277/277 - 2s - loss: 0.5545 - accuracy: 0.8386 - val_loss: 1.4189 - val_accuracy: 0.6944\n",
      "Epoch 371/400\n",
      "277/277 - 2s - loss: 0.5541 - accuracy: 0.8413 - val_loss: 1.4336 - val_accuracy: 0.7025\n",
      "Epoch 372/400\n",
      "277/277 - 2s - loss: 0.5524 - accuracy: 0.8396 - val_loss: 1.4253 - val_accuracy: 0.7015\n",
      "Epoch 373/400\n",
      "277/277 - 2s - loss: 0.5547 - accuracy: 0.8368 - val_loss: 1.4414 - val_accuracy: 0.6954\n",
      "Epoch 374/400\n",
      "277/277 - 2s - loss: 0.5465 - accuracy: 0.8403 - val_loss: 1.4357 - val_accuracy: 0.6944\n",
      "Epoch 375/400\n",
      "277/277 - 2s - loss: 0.5583 - accuracy: 0.8360 - val_loss: 1.4325 - val_accuracy: 0.6924\n",
      "Epoch 376/400\n",
      "277/277 - 2s - loss: 0.5557 - accuracy: 0.8400 - val_loss: 1.4544 - val_accuracy: 0.6924\n",
      "Epoch 377/400\n",
      "277/277 - 2s - loss: 0.5473 - accuracy: 0.8395 - val_loss: 1.4439 - val_accuracy: 0.6924\n",
      "Epoch 378/400\n",
      "277/277 - 2s - loss: 0.5532 - accuracy: 0.8410 - val_loss: 1.4427 - val_accuracy: 0.6964\n",
      "Epoch 379/400\n",
      "277/277 - 2s - loss: 0.5489 - accuracy: 0.8427 - val_loss: 1.4425 - val_accuracy: 0.6975\n",
      "Epoch 380/400\n",
      "277/277 - 2s - loss: 0.5529 - accuracy: 0.8404 - val_loss: 1.4506 - val_accuracy: 0.6975\n"
     ]
    }
   ],
   "source": [
    "subclases = [20, 30, 40]\n",
    "resolutions = [24]#, 32]#, 48]\n",
    "\n",
    "for j, num_classes in enumerate(subclases):\n",
    "    base_labels = all_labels[:num_classes]\n",
    "    for i,res in enumerate(resolutions):\n",
    "        training, training_labels = load_data(res, base_labels, 'train', 1, False)\n",
    "        model = prepare_model(res, num_classes, 1)\n",
    "        model_name = 'models/' + model_type + '-' + str(num_classes) + '-' + str(res) + '.h5'\n",
    "        train(model, training, training_labels, res, num_classes, 2)\n",
    "        model.save(model_name)\n",
    "        test, test_labels = load_data(res, base_labels, 'test', 1.0, False)\n",
    "        test_loss, test_acc = model.evaluate(\n",
    "            prepare_data(test, num_classes),  \n",
    "            test_labels, \n",
    "            verbose=2\n",
    "        )\n",
    "        print('\\nTest accuracy for ' + str(num_classes) + ' classes width res ' + str(res) + ':', test_acc)\n",
    "        print_confusion_matrix(test, test_labels, base_labels)\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('models/dense-20-24')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 20\n",
    "res = 24\n",
    "base_labels = all_labels[:num_classes]\n",
    "test, test_labels = load_data(res, base_labels, 'test', 1.0, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 - 0s - loss: 0.6880 - accuracy: 0.8295\n",
      "\n",
      "Test accuracy for 20 classes width res 24: 0.8294509053230286\n",
      "WARNING:tensorflow:From <ipython-input-6-0ef4a1b1e249>:3: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "Confusion Matrix\n",
      "[[94  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0]\n",
      " [ 1 37  8  1  0  0  1  1  0  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  1 93  0  0  0  0  0  3  0  0  0  0  0  0  0  1  0  2  0]\n",
      " [ 0  0  0 14  1  0  0  1  2  0  0  0  1  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0 88  3  0  0  1  0  0  3  0  3  0  0  1  0  0  1]\n",
      " [ 0  0  0  1  1 72  0  0  1  5  1  0  0  0  1  2  0  4  0 12]\n",
      " [ 0  0  0  0  0  0 12  2  2  0  0  0  0  0  0  0  0  2  2  0]\n",
      " [ 4  0  2  1  0  1  0 83  5  0  0  1  0  0  0  0  3  0  0  0]\n",
      " [ 0  0  6  1  1  1  0  0 89  0  0  0  0  0  0  0  0  1  0  1]\n",
      " [ 0  0  1  0  2  1  0  0  0 14  0  0  0  0  0  1  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  2  0  2  0  6  0  0  0  0  8  0  1  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0 14  0  4  0  0  1  0  0  0]\n",
      " [ 0  0  2  0  2  0  0  0  0  0  0  0 78  0  3  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  3  0 16  0  1  0  0  0  0]\n",
      " [ 0  0  1  0  1  0  0  0  0  0  0  0  6  0 76  2  0  0  0  0]\n",
      " [ 0  0  1  0  4  3  0  1  2  0  1  0  0  0  0  7  0  0  0  1]\n",
      " [ 0  0  1  0  1  0  1  0  1  0  0  0  0  0  0  1 95  0  0  0]\n",
      " [ 8  0  3  4  0  0  0  0  4  0  0  1  0  0  0  0  0 79  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  1 16  0]\n",
      " [ 0  0  0  0  3  1  0  0  1  0  0  0  0  0  0  1  0  0  0 14]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.88      0.94      0.91       100\n",
      "     bathtub       0.97      0.74      0.84        50\n",
      "         bed       0.77      0.93      0.84       100\n",
      "       bench       0.64      0.70      0.67        20\n",
      "   bookshelf       0.83      0.88      0.85       100\n",
      "      bottle       0.88      0.72      0.79       100\n",
      "        bowl       0.75      0.60      0.67        20\n",
      "         car       0.94      0.83      0.88       100\n",
      "       chair       0.77      0.89      0.82       100\n",
      "        cone       0.74      0.70      0.72        20\n",
      "         cup       0.75      0.30      0.43        20\n",
      "     curtain       0.64      0.70      0.67        20\n",
      "        desk       0.92      0.91      0.91        86\n",
      "        door       0.70      0.80      0.74        20\n",
      "     dresser       0.94      0.88      0.91        86\n",
      "  flower_pot       0.30      0.35      0.33        20\n",
      "   glass_box       0.91      0.95      0.93       100\n",
      "      guitar       0.87      0.79      0.83       100\n",
      "    keyboard       0.76      0.80      0.78        20\n",
      "        lamp       0.48      0.70      0.57        20\n",
      "\n",
      "    accuracy                           0.83      1202\n",
      "   macro avg       0.77      0.76      0.75      1202\n",
      "weighted avg       0.84      0.83      0.83      1202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(\n",
    "            prepare_data(test, num_classes),  \n",
    "            test_labels, \n",
    "            verbose=2\n",
    "        )\n",
    "print('\\nTest accuracy for ' + str(num_classes) + ' classes width res ' + str(res) + ':', test_acc)\n",
    "print_confusion_matrix(test, test_labels, base_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(img, expected = '', predicted = ''):\n",
    "    fig = plt.figure(figsize=[10,10])\n",
    "    ax = fig.gca(projection='3d')\n",
    "    cube1 = (img[:,:,:] >= 1)\n",
    "    ax.voxels(cube1, facecolors=\"blue\")\n",
    "    plt.title('Expected: {}\\n Predicted: {}'.format(expected, predicted), y=-0.01)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not len(test):\n",
    "    test, test_labels = load_data(dim, base_labels, 'test', 100)\n",
    "test_loss, test_acc = model.evaluate(test,  test_labels, verbose=2)\n",
    "p = model.predict(training)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = random.randint(0, len(training))\n",
    "\n",
    "predicted_index = np.argmax(p[index])\n",
    "expected = base_labels[int(training_labels[index])]\n",
    "predicted = base_labels[predicted_index]\n",
    "draw(test[index], expected, predicted)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "base_labels = all_labels[:num_classes]\n",
    "num_classes = num_classes\n",
    "res = 24\n",
    "training, training_labels = load_data(res, base_labels, 'train', 1, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training))\n",
    "model = prepare_model(res, num_classes, 1)\n",
    "train(model, training, training_labels, res, num_classes, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base_labels)\n",
    "test, test_labels = load_data(res, base_labels, 'test', 1.0, True)\n",
    "print(len(test))\n",
    "test_loss, test_acc = model.evaluate(\n",
    "    test,  \n",
    "    test_labels, \n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(test)\n",
    "for index in range(len(p)):\n",
    "    predicted_index = np.argmax(p[index])\n",
    "    expected = base_labels[int(test_labels[index])]\n",
    "    predicted = base_labels[predicted_index]\n",
    "    if expected != predicted:\n",
    "        draw(test[index], expected, predicted)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
