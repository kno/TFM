{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipynb in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
      "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.6/dist-packages (3.51.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2) (2.4.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from progressbar2) (1.14.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipynb sklearn progressbar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.utils import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(imgs, labels):\n",
    "    fig, axs = plt.subplots(1, len(imgs), figsize=(15, 3), sharey=True, subplot_kw=dict(projection='3d'))\n",
    "    for i in range(len(imgs)):\n",
    "        cube1 = (imgs[i][:,:,:] >= 1)\n",
    "        axs[i].voxels(cube1, facecolors=\"blue\")\n",
    "        axs[i].set_title(labels[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Histogram:\n",
    "    def __init__(self, histX, histY, histZ, label):\n",
    "        self.histX = histX\n",
    "        self.histY = histY\n",
    "        self.histZ = histZ\n",
    "        self.label = label\n",
    "        \n",
    "    @classmethod\n",
    "    def load(self, filename):\n",
    "        with open(filename + '.pkl', 'rb') as input:\n",
    "            return pickle.load(input)\n",
    "    \n",
    "    def save(self, filename):\n",
    "        with open(filename + '.pkl', 'wb') as output:\n",
    "            pickle.dump(self, output, pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    def draw(self):\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 3), sharey=True)\n",
    "        axs[0].bar(range(res), self.histX)\n",
    "        axs[0].set_title(self.label + ' X')\n",
    "        axs[1].bar(range(res), self.histY)\n",
    "        axs[1].set_title('Y')\n",
    "        axs[2].bar(range(res), self.histZ)\n",
    "        axs[2].set_title('Z')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_histogram(obj, label, res):\n",
    "    objy = np.moveaxis(obj, [0, 1, 2], [1, 0, 2])\n",
    "    objz = np.moveaxis(obj, [0, 1, 2], [1, 2, 0])\n",
    "    #calculate the histogram in 3 axis\n",
    "    histx = np.zeros(res, dtype=int)\n",
    "    histy = np.zeros(res)\n",
    "    histz = np.zeros(res)\n",
    "    for i in range(res):\n",
    "        ox = obj[i].reshape([res * res])\n",
    "        histx[i] = ox[ox == 1].size\n",
    "\n",
    "        oy = objy[i].reshape([res * res])\n",
    "        histy[i] = oy[oy == 1].size\n",
    "\n",
    "        oz = objz[i].reshape([res * res])\n",
    "        histz[i] = oz[oz == 1].size\n",
    "    return Histogram(histx, histy, histz, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_histogram(histograms):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 3), sharey=True)\n",
    "    axs[0].bar(range(res), histograms.histX)\n",
    "    axs[0].set_title(label + ' X')\n",
    "    axs[1].bar(range(res), histograms.histY)\n",
    "    axs[1].set_title('Y')\n",
    "    axs[2].bar(range(res), histograms.histZ)\n",
    "    axs[2].set_title('Z')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate and save histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (39 of 39) |########################| Elapsed Time: 0:00:19 ETA:  00:00:00"
     ]
    }
   ],
   "source": [
    "bar2 = progressbar.ProgressBar(max_value=len(all_labels)-1)\n",
    "\n",
    "for i, label in enumerate(all_labels):\n",
    "    bar2.update(i)\n",
    "    training, training_labels = load_data(res, [label], 'train', 1, 0, False)\n",
    "    for j in range(len(training)):\n",
    "        histograms = calculate_histogram(training[j], label, res)\n",
    "        histograms.save('histograms/train-' + histograms.label)\n",
    "    test, testlabels = load_data(res, [label], 'test', 1, False, False)\n",
    "    for j in range(len(test)):\n",
    "        histograms = calculate_histogram(test[j], label, res)\n",
    "        histograms.save('histograms/test-' + histograms.label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, training_labels = load_data(res, all_labels, 'train', 1, 0, False)\n",
    "test, test_labels = load_data(res, all_labels, 'test', 1, 0, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, res, num_classes, verbosity):\n",
    "        self.prepare_model(res, num_classes, verbosity)\n",
    "        \n",
    "    def prepare_model(self, res, num_classes, verbosity = 0):\n",
    "        pass\n",
    "    \n",
    "    def train(self, training, training_labels, res, num_classes, verbosity = 0, log = False, epochs = None):\n",
    "        log_dir = \"logs/fit/\" + str(res) + '-' + str(num_classes) + '-' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        if verbosity == 1 and log:\n",
    "            print(\"Log file \" + log_dir)\n",
    "        if log:\n",
    "            tensorboard_callbacks = [tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)]\n",
    "        else:\n",
    "            tensorboard_callbacks = None\n",
    "\n",
    "        validation_split = 0.1\n",
    "        if epochs == None:\n",
    "            epochs = 2 * num_classes\n",
    "\n",
    "        self.model.fit(\n",
    "            prepare_data(training, num_classes, res), \n",
    "            training_labels, \n",
    "            epochs=epochs,\n",
    "            verbose=verbosity,\n",
    "            callbacks=tensorboard_callbacks,\n",
    "            validation_split=validation_split\n",
    "    )\n",
    "    \n",
    "    def evaluate(self, test, test_labels, verbose):\n",
    "        return self.model.evaluate(\n",
    "            test,\n",
    "            test_labels, \n",
    "            verbose=2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConv3D(Model):\n",
    "\n",
    "    def __init__(self, res, num_classes, verbosity):\n",
    "        super().__init__(res, num_classes, verbosity)\n",
    "    \n",
    "    def prepare_model(res, num_classes, verbosity = 0):\n",
    "        self.model = keras.Sequential([\n",
    "            keras.layers.Conv3D(\n",
    "                    res, \n",
    "                    kernel_size=(6),\n",
    "                    strides=(2),\n",
    "                    activation='relu', \n",
    "                    kernel_initializer='he_uniform', \n",
    "                    data_format=\"channels_last\",\n",
    "                    input_shape=(res, res, res, 1)\n",
    "                ),        \n",
    "            keras.layers.Conv3D(\n",
    "                    res, \n",
    "                    kernel_size=(5),\n",
    "                    strides=(2),\n",
    "                    activation='relu', \n",
    "                    kernel_initializer='he_uniform'\n",
    "                ),        \n",
    "            #keras.layers.Conv3D(\n",
    "            #        res, \n",
    "            #        kernel_size=(2),\n",
    "            #        activation='relu', \n",
    "            #        kernel_initializer='he_uniform'\n",
    "            #    ),        \n",
    "\n",
    "            #keras.layers.MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(res/2, activation='relu'),\n",
    "            keras.layers.Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        learning_rate = 0.0001\n",
    "\n",
    "        self.model.compile(optimizer=keras.optimizers.Adam(lr=learning_rate),\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        if (verbosity == 1):\n",
    "            print(model.summary())\n",
    "\n",
    "    def prepare_data(data, num_classes, res):\n",
    "        return data.reshape(len(data), res, res, res, 1)\n",
    "    model_type = 'conv3d'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelDense(Model): \n",
    "    \n",
    "    def __init__(self, res, num_classes, verbosity):\n",
    "        super().__init__(res, num_classes, verbosity)\n",
    "\n",
    "    def prepare_model(self, res, num_classes, verbosity = 0):\n",
    "        self.model = keras.Sequential([\n",
    "            keras.layers.Flatten(input_shape=(res, res, res)),\n",
    "            keras.layers.Dense(res*2, activation='relu'),\n",
    "            keras.layers.Dense(res/2, activation='sigmoid'),\n",
    "            keras.layers.Dropout(.2, input_shape=(2,)),\n",
    "            keras.layers.Dense(40, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        learning_rate = 0.0001\n",
    "\n",
    "        self.model.compile(optimizer=keras.optimizers.Adam(lr=learning_rate),\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        if (verbosity == 1):\n",
    "            print(self.model.summary())\n",
    "            \n",
    "    def prepare_data(self, data, num_classes, res):\n",
    "        return data\n",
    "    model_type = 'dense'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_37 (Flatten)         (None, 13824)             0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 48)                663600    \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 12)                588       \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 40)                520       \n",
      "=================================================================\n",
      "Total params: 664,708\n",
      "Trainable params: 664,708\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "276/276 - 2s - loss: 3.4584 - accuracy: 0.0949 - val_loss: 3.8418 - val_accuracy: 0.0204\n",
      "Epoch 2/10\n",
      "276/276 - 1s - loss: 3.2267 - accuracy: 0.2372 - val_loss: 3.9107 - val_accuracy: 0.0224\n",
      "Epoch 3/10\n",
      "276/276 - 2s - loss: 3.0932 - accuracy: 0.3318 - val_loss: 3.9930 - val_accuracy: 0.0316\n",
      "Epoch 4/10\n",
      "276/276 - 2s - loss: 2.9833 - accuracy: 0.3866 - val_loss: 4.1050 - val_accuracy: 0.0296\n",
      "Epoch 5/10\n",
      "276/276 - 1s - loss: 2.8847 - accuracy: 0.4167 - val_loss: 4.2298 - val_accuracy: 0.0224\n",
      "Epoch 6/10\n",
      "276/276 - 2s - loss: 2.7988 - accuracy: 0.4436 - val_loss: 4.3051 - val_accuracy: 0.0214\n",
      "Epoch 7/10\n",
      "276/276 - 2s - loss: 2.7091 - accuracy: 0.4606 - val_loss: 4.3996 - val_accuracy: 0.0204\n",
      "Epoch 8/10\n",
      "276/276 - 2s - loss: 2.6337 - accuracy: 0.4624 - val_loss: 4.5020 - val_accuracy: 0.0275\n",
      "Epoch 9/10\n",
      "276/276 - 2s - loss: 2.5623 - accuracy: 0.4677 - val_loss: 4.5691 - val_accuracy: 0.0275\n",
      "Epoch 10/10\n",
      "276/276 - 2s - loss: 2.4977 - accuracy: 0.4786 - val_loss: 4.6658 - val_accuracy: 0.0316\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(all_labels)\n",
    "model = ModelDense(res, num_classes, 1)\n",
    "model.train(training, training_labels, res, num_classes, 2, False, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 - 0s - loss: 2.8710 - accuracy: 0.3777\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(\n",
    "    model.prepare_data(test, num_classes, res),  \n",
    "    test_labels, \n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
